<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.8/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.8/ http://www.mediawiki.org/xml/export-0.8.xsd" version="0.8" xml:lang="en">
  <siteinfo>
    <sitename>QuABaseBD - Quality Architecture at Scale for Big Data</sitename>
    <base>http://quabase.sei.cmu.edu/mediawiki/index.php/Main_Page</base>
    <generator>MediaWiki 1.21.2</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">QuABase</namespace>
      <namespace key="5" case="first-letter">QuABase talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="102" case="first-letter">Property</namespace>
      <namespace key="103" case="first-letter">Property talk</namespace>
      <namespace key="106" case="first-letter">Form</namespace>
      <namespace key="107" case="first-letter">Form talk</namespace>
      <namespace key="108" case="first-letter">Concept</namespace>
      <namespace key="109" case="first-letter">Concept talk</namespace>
      <namespace key="170" case="first-letter">Filter</namespace>
      <namespace key="171" case="first-letter">Filter talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>Neo4j</title>
    <ns>0</ns>
    <id>96</id>
    <revision>
      <id>2729</id>
      <parentid>2710</parentid>
      <timestamp>2015-04-28T14:36:02Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="548">{{SQLDatabase ParserMain
|Overview=Neo4j is an open-source graph database, implemented in Java,

Neo4j version 1.0 was released in February, 2010. The community edition of the database is licensed under the free GNU General Public License (GPL) v3. The additional modules, such as online backup and high availability, are licensed under the free Affero General Public License (AGPL) v3. The database, with the additional modules, is also available under a commercial license, in a dual license model.
|Model=Graph
|DBURL= http://neo4j.com/
|DBVersion=2.3
}}</text>
      <sha1>fmrxab6fw6owm0itakcdo2bkt4uut78</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Riak</title>
    <ns>0</ns>
    <id>97</id>
    <revision>
      <id>2731</id>
      <parentid>2712</parentid>
      <timestamp>2015-04-28T14:36:58Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="513">{{SQLDatabase ParserMain
|Overview=Riak is a distributed key-value data store that offers high availability, fault tolerance, and scalability. In addition to the open-source version, it comes in a supported enterprise version and a cloud storage version.

Riak implements the principles from Amazon's Dynamo paper. Written in Erlang, Riak has fault tolerant data replication and automatic data distribution across the cluster for performance and resilience.
|Model=Key-Value
|DBURL=http://basho.com/riak/
|DBVersion=2.0
}}</text>
      <sha1>ncqlpb7qlswtzu49l7uccstfnfybi9r</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Cassandra</title>
    <ns>0</ns>
    <id>99</id>
    <revision>
      <id>2725</id>
      <parentid>2705</parentid>
      <timestamp>2015-04-28T14:33:40Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="444">{{SQLDatabase ParserMain
|Overview=Cassandra is a column-store database, originally developed at Facebook to support the &quot;Inbox Search&quot; feature. It has since evolved considerably, and is now an Apache project.

Cassandra's data model offers  column indexes with the performance of log-structured updates, strong support for denormalization and materialized views, and built-in caching.
|Model=Column
|DBURL=http://cassandra.apache.org/
|DBVersion=2.0
}}</text>
      <sha1>5v669mbkincxmof69p7c5dd78zc1ru5</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>MongoDB</title>
    <ns>0</ns>
    <id>100</id>
    <revision>
      <id>2727</id>
      <parentid>2708</parentid>
      <timestamp>2015-04-28T14:35:00Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="1030">{{SQLDatabase ParserMain
|Overview=MongoDB (from &quot;humongous&quot;) is a cross-platform document-oriented database. MongoDB eschews the traditional table-based relational database structure in favor of JSON-like documents with dynamic schemas (MongoDB calls the format BSON), making the integration of data in certain types of applications easier and faster. Released under a combination of the GNU Affero General Public License and the Apache License, MongoDB is free and open-source software.

First developed by the software company 10gen (now MongoDB Inc.) in October 2007 as a component of a planned platform as a service product, the company shifted to an open source development model in 2009, with 10gen offering commercial support and other services. Since then, MongoDB has been adopted as backend software by a number of major websites and services, including Brave Collective, Craigslist, eBay, Foursquare, SourceForge, Viacom, and the New York Times, among others.
|Model=Document
|DBURL=https://www.mongodb.org/
|DBVersion=2.6.9
}}</text>
      <sha1>9p592bb8lh5qh0truaihecndy5q5emx</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>VoltDB</title>
    <ns>0</ns>
    <id>101</id>
    <revision>
      <id>2723</id>
      <parentid>2713</parentid>
      <timestamp>2015-04-28T14:32:25Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="708">{{SQLDatabase ParserMain
|Overview=VoltDB is an in-memory database designed by several well-known database system researchers, including A.M. Turing Award winner Michael Stonebraker (who was involved in Ingres and POSTGRES), Sam Madden, and Daniel Abadi. It is an ACID-compliant RDBMS which uses a shared nothing architecture. It includes both enterprise and community editions. The community edition is licensed under the GNU Affero General Public License. Additional features in the commercially licensed VoltDB Enterprise version include durability, high availability, and Export integrations. VoltDB implements the design of the academic H-Store project.
|Model=NewSQL
|DBURL=https://voltdb.com/
|DBVersion=5.0
}}</text>
      <sha1>nbzldhj9yq6kupgengy3v076a51keub</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>FoundationDB</title>
    <ns>0</ns>
    <id>102</id>
    <revision>
      <id>2730</id>
      <parentid>2711</parentid>
      <timestamp>2015-04-28T14:36:32Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="346">{{SQLDatabase ParserMain
|Overview=FoundationDB is multi-model, meaning you can store many types data all in a single database. All data is stored, distributed, and replicated in the Key-Value Store component, and new functionality, like a SQL Layer, is layered on top of its simple API.
|Model=Key-Value
|DBURL=https://foundationdb.com/
|DBVersion=3.0
}}</text>
      <sha1>r9bd988pw0jfizy9edxa2ismlby2hfl</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>CouchDB</title>
    <ns>0</ns>
    <id>260</id>
    <revision>
      <id>2728</id>
      <parentid>2707</parentid>
      <timestamp>2015-04-28T14:35:38Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="528">{{SQLDatabase ParserMain
|Overview=Apache CouchDB, commonly referred to as CouchDB, is an open source database that focuses on ease of use and on being &quot;a database that completely embraces the web&quot;. 
It is a NoSQL database that uses JSON to store data, JavaScript as its query language using MapReduce, and HTTP for an API. 
One of its distinguishing features is multi-master replication. CouchDB was first released in 2005 and later became an Apache project in 2008.  
|Model=Document
|DBURL=http://couchdb.apache.org/
|DBVersion=1.6
}}</text>
      <sha1>9qbtwbp6dtyio0w09udvhk822dl21pd</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>HBase</title>
    <ns>0</ns>
    <id>324</id>
    <revision>
      <id>2726</id>
      <parentid>2706</parentid>
      <timestamp>2015-04-28T14:34:35Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="388">{{SQLDatabase ParserMain
|Overview=HBase is an open source, non-relational, distributed database modeled after Google's BigTable and written in Java. It is developed as part of Apache Software Foundation's Apache Hadoop project and runs on top of HDFS (Hadoop Distributed Filesystem), providing BigTable-like capabilities for Hadoop 
|Model=Column
|DBURL=http://hbase.apache.org/
|DBVersion=1.0
}}</text>
      <sha1>hm7ib3kgfai522v3gcclp2pu1zllu2z</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Accumulo</title>
    <ns>0</ns>
    <id>332</id>
    <revision>
      <id>2724</id>
      <parentid>2698</parentid>
      <timestamp>2015-04-28T14:33:04Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="625">{{SQLDatabase ParserMain
|Overview=Apache Accumulo is based on Google's BigTable design and is built on top of Apache Hadoop, Zookeeper, and Thrift. Apache Accumulo features a few novel improvements on the BigTable design in the form of cell-based access control and a server-side programming mechanism that can modify key/value pairs at various points in the data management process.

A commercial version of Accumulo with extensions is available from sqrrl - http://sqrrl.com/product/accumulo/ - and we include some sqrrl features in the descriptions in this wiki.
|Model=Column
|DBURL=https://accumulo.apache.org/
|DBVersion=1.5
}}</text>
      <sha1>3tqu2jz4gynufj2zwadvl0r27edkt2k</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Oracle NoSQL</title>
    <ns>0</ns>
    <id>533</id>
    <revision>
      <id>2951</id>
      <timestamp>2015-08-24T23:43:55Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <comment>Created page with &quot;{{SQLDatabase ParserMain |Overview=The Oracle NoSQL SQLDatabase is a distributed key-value store. It is designed to provide highly reliable, scalable and available data storage across a d...&quot;</comment>
      <text xml:space="preserve" bytes="655">{{SQLDatabase ParserMain
|Overview=The Oracle NoSQL SQLDatabase is a distributed key-value store. It is designed to provide highly reliable, scalable and available data storage across a distributed collection of storage nodes.

Data is stored as key-value pairs, which are written to  storage node(s) based on the hashed value of the primary key. Storage nodes can be replicated to ensure high availability, rapid failover in the event of  a node failure and load balancing of queries. Applications are written using a Java/C API to read and write data.
|Model=Key-Value
|DBURL=http://www.oracle.com/us/products/database/nosql/overview/index.html
|DBVersion=3.3.4
}}</text>
      <sha1>0q0fjgsidjhy8lzgyprb7aniv2dr1s7</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>OrientDB</title>
    <ns>0</ns>
    <id>541</id>
    <revision>
      <id>3044</id>
      <timestamp>2016-03-30T16:30:32Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <comment>Created page with &quot;{{SQLDatabase ParserMain |Overview=OrientDB is a 2nd Generation Distributed Graph SQLDatabase with the flexibility of Documents in one product with an Open Source commercial friendly lice...&quot;</comment>
      <text xml:space="preserve" bytes="1005">{{SQLDatabase ParserMain
|Overview=OrientDB is a 2nd Generation Distributed Graph SQLDatabase with the flexibility of Documents in one product with an Open Source commercial friendly license (Apache 2 license). First generation Graph Databases lack the features that Big Data demands: multi-master replication, sharding and more flexibility for modern complex use cases.

OrientDB is incredibly fast: it can store 220,000 records per second on common hardware. Even for a Document based database, the relationships are managed as in Graph Databases with direct connections among records. You can traverse parts of or entire trees and graphs of records in a few milliseconds. Supports schema-less, schema-full and schema-mixed modes. Has a strong security profiling system based on user and roles and supports SQL amongst the query languages. Thanks to the SQL layer, it's straightforward to use for those skilled in the relational database world.
|Model=Graph
|DBURL=http://orientdb.com/orientdb/
|DBVersion=2.1.13
}}</text>
      <sha1>1j26j2bs2jkcde51293yrof3wi1pkr6</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Couchbase</title>
    <ns>0</ns>
    <id>550</id>
    <revision>
      <id>3054</id>
      <timestamp>2016-03-30T17:01:50Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <comment>Created page with &quot;{{SQLDatabase ParserMain |Overview=Couchbase Server is a distributed NoSQL database engineered for performance, scalability, and availability. It enables developers to build applicatio...&quot;</comment>
      <text xml:space="preserve" bytes="323">{{SQLDatabase ParserMain
|Overview=Couchbase Server is a distributed NoSQL database engineered for performance, scalability, and availability. It enables developers to build applications easier and faster by leveraging the power of SQL with the flexibility of JSON.
|Model=Document
|DBURL=http://www.couchbase.com/
|DBVersion=4.1
}}</text>
      <sha1>n0ppkupwtdeq41vmr8jmx8z5oo0bagu</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Redis</title>
    <ns>0</ns>
    <id>559</id>
    <revision>
      <id>3063</id>
      <timestamp>2016-03-30T17:17:14Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <comment>Created page with &quot;{{SQLDatabase ParserMain |Overview=Redis is an open source (BSD licensed), in-memory data structure store, used as database, cache and message broker. It supports data structures such ...&quot;</comment>
      <text xml:space="preserve" bytes="574">{{SQLDatabase ParserMain
|Overview=Redis is an open source (BSD licensed), in-memory data structure store, used as database, cache and message broker. It supports data structures such as strings, hashes, lists, sets, sorted sets with range queries, bitmaps, hyperloglogs and geospatial indexes with radius queries. Redis has built-in replication, Lua scripting, LRU eviction, transactions and different levels of on-disk persistence, and provides high availability via Redis Sentinel and automatic partitioning with Redis Cluster.
|Model=Key-Value
|DBURL=redis.io
|DBVersion=3.0.7
}}</text>
      <sha1>acfes4moeelgr94ozk4l2ivlun6dtee</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Amazon DynamoDB</title>
    <ns>0</ns>
    <id>568</id>
    <revision>
      <id>3295</id>
      <parentid>3294</parentid>
      <timestamp>2016-04-13T23:58:31Z</timestamp>
      <contributor>
        <username>Ccis</username>
        <id>62</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contributions/Ccis|Ccis]] ([[User talk:Ccis|talk]]) to last revision by [[User:Igorton|Igorton]]</comment>
      <text xml:space="preserve" bytes="492">{{SQLDatabase ParserMain
|Overview=Amazon DynamoDB is a fast and flexible NoSQL database service for all applications that need consistent, single-digit millisecond latency at any scale. It is a fully managed cloud database and supports both document and key-value store models. Its flexible data model and reliable performance make it a great fit for mobile, web, gaming, ad tech, IoT, and many other applications. 
|Model=Key-Value
|DBURL=https://aws.amazon.com/dynamodb/
|DBVersion=Cloud Service
}}</text>
      <sha1>j5ro0gwg1lbp0t23svd04gqbclkpx99</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Riak Consistency Features</title>
    <ns>0</ns>
    <id>115</id>
    <revision>
      <id>2634</id>
      <parentid>2370</parentid>
      <timestamp>2015-04-17T20:52:03Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="2403">{{Consistency Features
|SQLDatabase=Riak
|Object-Level isolation on updates=not supported - conflicts allowed
|Const Object Isolation URL=http://docs.basho.com/riak/latest/dev/using/conflict-resolution/
|ACID transactions in single database=not supported
|Const ACID Trans URL=http://docs.basho.com/riak/latest/theory/concepts/Eventual-Consistency/
|Distributed ACID transactions=not supported
|Const Distributed Trans URL=http://docs.basho.com/riak/latest/theory/concepts/Eventual-Consistency/
|Updates applied to transaction log before returning from write=supported
|Const Log Writes URL=http://basho.com/riaks-config-behaviors-part-2/
|Specify Quorum Reads/Writes=in the client
|Const Quorum URL=http://basho.com/riaks-config-behaviors-part-2/
|Specify number of replicas to write to=specified in the client
|Const Replica Write URL=http://basho.com/riaks-config-behaviors-part-2/
|Behaviour when write cannot complete on specified number of replicas=hinted handoffs: writes are applied later when a replica recovers
|Const Write Replica Fail URL=http://basho.com/riaks-config-behaviors-part-2/
|Writes configured to never fail=not supported
|Specify number of replicas to read from=specified in the client
|Const Replica Read URL=http://basho.com/riaks-config-behaviors-part-2/
|Read from replica master only=not applicable - peer to peer
|Object level timestamps to detect conflicts=supported
|Const Timestamps URL=http://docs.basho.com/riak/latest/dev/using/conflict-resolution/
|Efficient protocol to rapidly propagate updates across replicas (minimize inconsistency window)=fixed
}}
Riak's strong consistency feature is currently an open-source-only feature and is not yet commercially supported. It's capabilities are not reflected in this page. See http://docs.basho.com/riak/latest/ops/advanced/strong-consistency/ for details. 

After N (the replicas value), the two most commonly-discussed parameters in Riak overviews are R and W. These are the number of vnodes which must respond to a read (R) or write (W) request before the request is considered successful and a response is sent to the requesting client. The request will be sent to all N vnodes that are known to be currently responsible for the data, and the coordinating node which is handling the request on behalf of the client will wait for all N vnodes to reply, but the client will be informed of a result after R or W responses.</text>
      <sha1>1ug6ak99wbkpijrz1vjynkgqglyqbg9</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>MongoDB Consistency Features</title>
    <ns>0</ns>
    <id>127</id>
    <revision>
      <id>2629</id>
      <parentid>2383</parentid>
      <timestamp>2015-04-17T20:02:13Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="4278">{{Consistency Features
|SQLDatabase=MongoDB
|Object-Level isolation on updates=supported
|Const Object Isolation URL=http://docs.mongodb.org/manual/faq/concurrency/
|ACID transactions in single database=not supported
|Const ACID Trans URL=http://docs.mongodb.org/manual/tutorial/perform-two-phase-commits/
|Distributed ACID transactions=not supported
|Const Distributed Trans URL=http://docs.mongodb.org/manual/tutorial/perform-two-phase-commits/
|Updates applied to transaction log before returning from write=supported
|Const Log Writes URL=http://docs.mongodb.org/manual/reference/write-concern/
|Specify Quorum Reads/Writes=not supported
|Const Quorum URL=http://docs.mongodb.org/manual/applications/replication/
|Specify number of replicas to write to=specified in the client
|Const Replica Write URL=http://docs.mongodb.org/manual/applications/replication/
|Behaviour when write cannot complete on specified number of replicas=no rollback: write returns replication error
|Const Write Replica Fail URL=http://docs.mongodb.org/manual/reference/write-concern/#wc-wtimeout
|Writes configured to never fail=not supported
|Specify number of replicas to read from=not supported
|Const Replica Read URL=http://docs.mongodb.org/manual/core/read-preference/
|Read from replica master only=specified in the client
|Const Master Read URL=http://docs.mongodb.org/manual/core/read-preference/
|Object level timestamps to detect conflicts=not applicable: master-slave
|Efficient protocol to rapidly propagate updates across replicas (minimize inconsistency window)=fixed
|Const Protocol URL=http://docs.mongodb.org/meta-driver/latest/legacy/mongodb-wire-protocol/
}}
MongoDB uses a readers-writer lock that allows concurrent reads access to a database but gives exclusive access to a single write operation. MongoDB allows clients to read documents inserted or modified before it commits these modifications to disk, regardless of write concern level or journaling configuration. As a result, applications may observe two classes of behaviors, namely:

For systems with multiple concurrent readers and writers, MongoDB will allow clients to read the results of a write operation before the write operation returns.
If the mongod terminates before the journal commits, even if a write returns successfully, queries may have read data that will not exist after the mongod restarts.

Other database systems refer to these isolation semantics as read uncommitted. For all inserts and updates, MongoDB modifies each document in isolation: clients never see documents in intermediate states. For multi-document operations, MongoDB does not provide any multi-document transactions or isolation.

The MongoDB Wire Protocol is a simple socket-based, request-response style protocol. Clients communicate with the database server through a regular TCP/IP socket.

Operations on a single document are always atomic with MongoDB databases; however, operations that involve multiple documents, which are often referred to as “multi-document transactions”, are not atomic. Since documents can be fairly complex and contain multiple “nested” documents, single-document atomicity provides the necessary support for many practical use cases.

To guarantee consistency for reads from secondary members, you can configure the client and driver to ensure that write operations succeed on all members before completing successfully. This is known as 'write concerns' and the setting 'majority' ensures (n/2)+1 replicas are updated for a write. There is no corresponding read concern setting to support quorum-based reads and writes.

wtimeout causes write operations to return with an error after the specified limit, even if the required write concern will eventually succeed. When these write operations return, MongoDB does not undo successful data modifications performed before the write concern exceeded the wtimeout time limit. If you do not specify the wtimeout option and the level of write concern is unachievable, the write operation will block indefinitely. Specifying a wtimeout value of 0 is equivalent to a write concern without the wtimeout option.

The default write concern for MongoDB provides acknowledgment of write operations on a standalone mongod or the primary in a replica set.</text>
      <sha1>cswfq0qdg3578rcayg9816x5g0f53zz</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Cassandra Consistency Features</title>
    <ns>0</ns>
    <id>174</id>
    <revision>
      <id>2367</id>
      <parentid>2323</parentid>
      <timestamp>2015-01-27T19:49:12Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="3473">{{Consistency Features
|SQLDatabase=Cassandra
|Object-Level isolation on updates=supported
|Const Object Isolation URL=http://www.datastax.com/documentation/cassandra/2.1/cassandra/dml/dml_about_transactions_c.html
|ACID transactions in single database=lightweight transactions (e.g. compare and set)
|Const ACID Trans URL=http://www.datastax.com/documentation/cassandra/2.1/cassandra/dml/dml_ltwt_transaction_c.html
|Distributed ACID transactions=not supported
|Const Distributed Trans URL=http://www.datastax.com/documentation/cassandra/2.1/cassandra/dml/dml_about_transactions_c.html
|Updates applied to transaction log before returning from write=supported
|Const Log Writes URL=http://www.datastax.com/documentation/cassandra/2.1/cassandra/dml/dml_write_path_c.html
|Specify Quorum Reads/Writes=in the client
|Const Quorum URL=http://www.datastax.com/documentation/cassandra/2.1/cassandra/dml/dml_config_consistency_c.html
|Specify number of replicas to write to=specified in the client
|Const Replica Write URL=http://www.datastax.com/docs/1.1/dml/data_consistency
|Behaviour when write cannot complete on specified number of replicas=hinted handoffs: writes are applied later when a replica recovers
|Const Write Replica Fail URL=http://www.datastax.com/documentation/cassandra/2.1/cassandra/dml/dml_about_hh_c.html
|Writes configured to never fail=supported
|Const Write Never Fail URL=http://www.datastax.com/documentation/cassandra/2.1/cassandra/dml/dml_config_consistency_c.html
|Specify number of replicas to read from=specified in the client
|Const Replica Read URL=http://www.datastax.com/docs/1.1/dml/data_consistency
|Read from replica master only=not applicable - peer to peer
|Object level timestamps to detect conflicts=supported
|Const Timestamps URL=http://www.datastax.com/dev/blog/why-cassandra-doesnt-need-vector-clocks
|Efficient protocol to rapidly propagate updates across replicas (minimize inconsistency window)=fixed
|Const Protocol URL=http://www.datastax.com/documentation/cassandra/2.0/cassandra/architecture/architectureGossipAbout_c.html
}}
Cassandra always writes to all replicas of the partition key, even replicas in other data centers. The consistency level determines only the number of replicas that need to acknowledge the write success to the client application. Typically, a client specifies a consistency level that is less than the replication factor specified by the keyspace. This practice ensures that the coordinating server node reports the write successful even if some replicas are down or otherwise not responsive to the write.

Consistency levels in Cassandra can be configured to manage availability versus data accuracy. You can configure consistency on a cluster, data center, or individual I/O operation basis. Consistency among participating nodes can be set globally and also controlled on a per-operation basis (for example insert or update) using Cassandra’s drivers and client libraries.

If it is an absolute requirement that a write never fail, you may also consider a write consistency level of ANY. Note that if all replica nodes are down at write time, an ANY write will not be readable until the replica nodes for that row key have recovered.

Cassandra addresses the problem that vector clocks were designed to solve by breaking up documents/objects/rows into units of data that can be updated and merged independently. This allows Cassandra to offer improved performance and simpler application design.</text>
      <sha1>j67a1by1qyhkqhe5k2gd30cwd32vjx9</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Neo4j Consistency Features</title>
    <ns>0</ns>
    <id>315</id>
    <revision>
      <id>2377</id>
      <parentid>2375</parentid>
      <timestamp>2015-01-27T20:11:00Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="2169">{{Consistency Features
|SQLDatabase=Neo4j
|Object-Level isolation on updates=supported
|Const Object Isolation URL=http://neo4j.com/docs/stable/transactions.html
|ACID transactions in single database=supported
|Const ACID Trans URL=http://neo4j.com/docs/stable/transactions.html
|Distributed ACID transactions=supported
|Const Distributed Trans URL=http://www.coderanch.com/t/642235/neo/databases/Neo-SQL-combination-work
|Updates applied to transaction log before returning from write=supported
|Const Log Writes URL=http://digitalstain.blogspot.com/2010/10/neo4j-internals-transactions-part-1.html
|Specify Quorum Reads/Writes=not relevant
|Specify number of replicas to write to=not applicable: master-slave
|Behaviour when write cannot complete on specified number of replicas=not applicable
|Writes configured to never fail=not supported
|Specify number of replicas to read from=not applicable: master-slave
|Read from replica master only=specified in the application configuration (eg Web load balancer)
|Const Master Read URL=http://neo4j.com/docs/stable/ha-rest-info.html
|Object level timestamps to detect conflicts=not applicable: master-slave
|Efficient protocol to rapidly propagate updates across replicas (minimize inconsistency window)=configurable
|Const Protocol URL=http://neo4j.com/docs/stable/ha-how.html
}}
All database operations that access the graph, indexes, or the schema must be performed in a transaction.

The default isolation level is READ_COMMITTED.

Data retrieved by traversals is not protected from modification by other transactions.

Non-repeatable reads may occur (i.e., only write locks are acquired and held until the end of the transaction). 

One can manually acquire write locks on nodes and relationships to achieve higher level of isolation (SERIALIZABLE).

Locks are acquired at the Node and Relationship level.

Deadlock detection is built into the core transaction management.

Neo4j is ACID-compliant and can participate in XA transactions with supported JDBC connections and/or any other XA resource (JMS connections...)

Slaves can also be configured to pull updates asynchronously by setting the ha.pull_interval option.</text>
      <sha1>qz0uor19ttzdtz5wnsty0r9lm7ozy0s</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>CouchDB Consistency Features</title>
    <ns>0</ns>
    <id>316</id>
    <revision>
      <id>2384</id>
      <parentid>2302</parentid>
      <timestamp>2015-01-27T20:16:29Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="4092">{{Consistency Features
|SQLDatabase=CouchDB
|Object-Level isolation on updates=Multi-Version Concurrency Control (MVCC)
|Const Object Isolation URL=http://guide.couchdb.org/draft/consistency.html
|ACID transactions in single database=not supported
|Const ACID Trans URL=http://bradley-holt.com/2011/07/addressing-the-nosql-criticism/
|Distributed ACID transactions=not supported
|Const Distributed Trans URL=http://guide.couchdb.org/draft/consistency.html
|Updates applied to transaction log before returning from write=supported
|Const Log Writes URL=http://bradley-holt.com/2011/07/addressing-the-nosql-criticism/
|Specify Quorum Reads/Writes=not supported
|Specify number of replicas to write to=not supported
|Behaviour when write cannot complete on specified number of replicas=no rollback: write returns replication error
|Writes configured to never fail=not supported
|Specify number of replicas to read from=not supported
|Read from replica master only=specified in the client
|Object level timestamps to detect conflicts=supported
|Const Timestamps URL=http://docs.couchdb.org/en/1.6.1/intro/consistency.html
|Efficient protocol to rapidly propagate updates across replicas (minimize inconsistency window)=fixed
}}
CouchDB read operations use a Multi-Version Concurrency Control (MVCC), and updates create a new document version. This removes the need to lock objects. CouchDB is ACID compliant - within a CouchDB server, for a single document update, CouchDB has the properties of atomicity, consistency, isolation, and durability (ACID). You can’t have transactions across document boundaries. You can’t have transactions across multiple servers 

If you want the best possible guarantee of durability, you can change CouchDB’s delayed_commits configuration option from true (the default) to false. Basically, this will cause CouchDB to do an explicit fsync after each operation (which is very expensive and slow). Note that operating systems, virtual machines, and hard drives often lie about fsync, so you really need to research more about how your particular system works if you’re concerned about durability. If you think your write speeds are too good to be true, they probably are.
If you leave delayed commits on, CouchDB has the option of setting a batch=ok parameter when creating or updating a document. This will queue up batches of documents in memory and write them to disk when a predetermined threshold has been reached (or when triggered by the user). In this case, CouchDB will respond with an HTTP response code of 202 Accepted, rather than the normal 201 Created, so that the client is informed about the reduced integrity guarantee.

Replication across databases is configured in a point-to-point fashion at the database level. Clients can effectively connect to any replica they have permission to access.

If a replica is not available, changes are logged and applied as soon as the replica is visible.

CouchDB’s replication system comes with automatic conflict detection and resolution. When CouchDB detects that a document has been changed in both databases, it flags this document as being in conflict, much like they would be in a regular version control system. This isn’t as troublesome as it might first sound. When two versions of a document conflict during replication, the winning version is saved as the most recent version in the document’s history. Instead of throwing the losing version away, as you might expect, CouchDB saves this as a previous version in the document’s history, so that you can access it if you need to. This happens automatically and consistently, so both databases will make exactly the same choice.

It is up to you to handle conflicts in a way that makes sense for your application. You can leave the chosen document versions in place, revert to the older version, or try to merge the two versions and save the result.

BigCouch, a CouchDB extension, does have quorum reads and writes and can be used to build a replicated, elastic cluster. We have not considered BigCouch capabilities in this description.</text>
      <sha1>7ffdcl7zwd7ybw9kv9scx63m47fq1td</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>HBase Consistency Features</title>
    <ns>0</ns>
    <id>325</id>
    <revision>
      <id>2382</id>
      <parentid>2283</parentid>
      <timestamp>2015-01-27T20:15:33Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="3027">{{Consistency Features
|SQLDatabase=HBase
|Object-Level isolation on updates=supported
|Const Object Isolation URL=http://hbase.apache.org/acid-semantics.html
|ACID transactions in single database=lightweight transactions (e.g. compare and set)
|Const ACID Trans URL=http://hbase.apache.org/acid-semantics.html
|Distributed ACID transactions=not supported
|Const Distributed Trans URL=http://hbase.apache.org/acid-semantics.html
|Updates applied to transaction log before returning from write=supported
|Const Log Writes URL=http://hbase.apache.org/acid-semantics.html
|Specify Quorum Reads/Writes=not supported
|Const Quorum URL=http://hbase.apache.org/book/arch.timelineconsistent.reads.html
|Specify number of replicas to write to=not supported
|Const Replica Write URL=http://hbase.apache.org/book/arch.timelineconsistent.reads.html
|Behaviour when write cannot complete on specified number of replicas=a rollback at all replicas
|Const Write Replica Fail URL=http://hbase.apache.org/book/arch.timelineconsistent.reads.html
|Writes configured to never fail=not supported
|Const Write Never Fail URL=http://hbase.apache.org/book/arch.timelineconsistent.reads.html
|Specify number of replicas to read from=not supported
|Const Replica Read URL=http://hbase.apache.org/book/arch.timelineconsistent.reads.html
|Read from replica master only=specified in the database configuration
|Const Master Read URL=http://hbase.apache.org/book/arch.timelineconsistent.reads.html
|Object level timestamps to detect conflicts=supported
|Const Timestamps URL=http://hbase.apache.org/book/arch.timelineconsistent.reads.html
|Efficient protocol to rapidly propagate updates across replicas (minimize inconsistency window)=fixed
|Const Protocol URL=http://hbase.apache.org/book/arch.timelineconsistent.reads.html
}}
All rows returned via any access API will consist of a complete row that existed at some point in the table's history.

All mutations are atomic within a row. Any put will either wholely succeed or wholely fail. The checkAndPut API happens atomically like the typical compareAndSet (CAS) operation found in many hardware architectures.

All visible data is also durable data. That is to say, a read will never return data that has not been made durable on disk. Any operation that returns a &quot;success&quot; code (eg does not throw an exception) will be made durable.

For achieving high availability for reads, HBase provides a feature called “region replication”. In this model, for each region of a table, there will be multiple replicas that are opened in different region servers. By default, the region replication is set to 1, so only a single region replica is deployed. In case the table has region replication = 1, or in a table with region replicas but the reads are done with this consistency, the read is always performed by the primary regions,

Async WAL replication feature is being implemented in Phase 2 of issue HBASE-10070. Before this, region replicas will only be updated with flushed data files from the primary</text>
      <sha1>0ecvq3it7aw893vn61juzzgp7vlabhh</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Accumulo Consistency Features</title>
    <ns>0</ns>
    <id>333</id>
    <revision>
      <id>2381</id>
      <parentid>2218</parentid>
      <timestamp>2015-01-27T20:15:06Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="4275">{{Consistency Features
|SQLDatabase=Accumulo
|Object-Level isolation on updates=supported
|Const Object Isolation URL=https://accumulo.apache.org/1.6/accumulo_user_manual.html#_writing_data
|ACID transactions in single database=lightweight transactions (e.g. compare and set)
|Const ACID Trans URL=https://accumulo.apache.org/1.6/accumulo_user_manual.html#_conditionalwriter
|Distributed ACID transactions=not supported
|Const Distributed Trans URL=https://www.safaribooksonline.com/library/view/accumulo/9781491947098/ch01.html
|Updates applied to transaction log before returning from write=supported
|Const Log Writes URL=https://accumulo.apache.org/1.6/accumulo_user_manual.html
|Specify Quorum Reads/Writes=not supported
|Const Quorum URL=https://www.safaribooksonline.com/library/view/accumulo/9781491947098/ch01.html
|Specify number of replicas to write to=not supported
|Const Replica Write URL=https://www.safaribooksonline.com/library/view/accumulo/9781491947098/ch01.html
|Behaviour when write cannot complete on specified number of replicas=no rollback: write returns replication error
|Const Write Replica Fail URL=https://www.safaribooksonline.com/library/view/accumulo/9781491947098/ch01.html
|Writes configured to never fail=not supported
|Const Write Never Fail URL=https://www.safaribooksonline.com/library/view/accumulo/9781491947098/ch03.html
|Specify number of replicas to read from=not supported
|Const Replica Read URL=https://www.safaribooksonline.com/library/view/accumulo/9781491947098/ch01.html
|Read from replica master only=specified in the database configuration
|Const Master Read URL=https://www.safaribooksonline.com/library/view/accumulo/9781491947098/ch01.html
|Object level timestamps to detect conflicts=not applicable: master-slave
|Const Timestamps URL=https://accumulo.apache.org/1.6/accumulo_user_manual.html#_versioning_iterators_and_timestamps
|Efficient protocol to rapidly propagate updates across replicas (minimize inconsistency window)=fixed
|Const Protocol URL=https://www.safaribooksonline.com/library/view/accumulo/9781491947098/ch01.html
}}
When a write arrives at a TabletServer it is written to a Write-Ahead Log and then inserted into a sorted data structure in memory called a MemTable. When the MemTable reaches a certain size the TabletServer writes out the sorted key-value pairs to a file in HDFS called Indexed Sequential Access Method (ISAM) file. This process is called a minor compaction. A new MemTable is then created and the fact of the compaction is recorded in the Write-Ahead Log.

Accumulo tablets are assigned to exactly one Tablet Server at a time. This allows one server to manage all the reads and writes for a particular range of keys, allowing reads and write to be highly consistent, as no synchronization has to occur between Tablet Servers. When a client writes a piece of information to a row, clients reading that row immediately afterward will see the new information.

Tablet Servers host a set of tablets and are responsible for all the writes and reads for those tablets. Clients connect directly to Tablet Servers to read and write data. Tablet Servers may host hundreds or even thousands of tablets, each consisting of about 1 GB of data or more. Tablet Servers store data written to these tablets in memory and in files in HDFS, and handle scanning data for clients, applying any additional filtering or processing the clients request.

The only transactions allowed by Accumulo are inserts, deletes, or updates to multiple values within a single row. These transactions are atomic, consistent, isolated and durable. But a set of updates to multiple rows in the same table, or rows in different tables do not have these guarantees.

Accumulo relies on HDFS to provide persistent storage, replication, and fault tolerance. The Accumulo client automatically handles errors related to the automatic failover from one TabletServer to another. This frees up the application designer to focus on the logic of the application rather than having to write the code to retry inserts.
Unlike some NoSQL databases, Accumulo assumes you do care to know that your Mutations have been successfully applied. If for some reason a Mutation fails, the Accumulo client will throw a MutationsRejectedException.</text>
      <sha1>gw2hpk8oy638rl8t1e4c4tmznl20vjl</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>FoundationDB Consistency Features</title>
    <ns>0</ns>
    <id>340</id>
    <revision>
      <id>2679</id>
      <parentid>2371</parentid>
      <timestamp>2015-04-23T20:17:58Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="3286">{{Consistency Features
|SQLDatabase=FoundationDB
|Object-Level isolation on updates=supported
|Const Object Isolation URL=https://foundationdb.com/layers/sql/documentation/Concepts/features.html
|ACID transactions in single database=supported
|Const ACID Trans URL=https://foundationdb.com/layers/sql/documentation/Concepts/features.html
|Distributed ACID transactions=not supported
|Const Distributed Trans URL=https://foundationdb.com/key-value-store/documentation/developer-guide.html
|Updates applied to transaction log before returning from write=supported
|Const Log Writes URL=https://foundationdb.com/key-value-store/documentation/developer-guide.html
|Specify Quorum Reads/Writes=in the database configuration
|Const Quorum URL=https://foundationdb.com/key-value-store/documentation/configuration.html#choosing-a-redundancy-mode
|Specify number of replicas to write to=specified in the database configuration
|Const Replica Write URL=https://foundationdb.com/key-value-store/documentation/configuration.html#choosing-a-redundancy-mode
|Behaviour when write cannot complete on specified number of replicas=a rollback at all replicas
|Const Write Replica Fail URL=https://foundationdb.com/key-value-store/documentation/configuration.html#choosing-a-redundancy-mode
|Writes configured to never fail=not supported
|Const Write Never Fail URL=https://foundationdb.com/key-value-store/documentation/developer-guide.html#transactions-in-foundationdb
|Specify number of replicas to read from=not supported
|Read from replica master only=not applicable - peer to peer
|Object level timestamps to detect conflicts=supported
|Const Timestamps URL=https://foundationdb.com/key-value-store/documentation/developer-guide.html#transaction-basics
|Efficient protocol to rapidly propagate updates across replicas (minimize inconsistency window)=fixed
}}
The SQL Layer is a fault tolerant and scalable RDBMS for OLTP workloads developed on top of the FoundationDB Key-Value Store. It was written from scratch to provide robust SQL capabilities in a distributed environment. FoundationDB manages state, distributed across cluster machines, in a consistent and fault tolerant way. As a result the SQL Layer is stateless and can be easily scaled.

FoundationDB provides concurrency control via transactions, allowing multiple clients to concurrently read and write data in the database with strong guarantees about how they affect each other. Specifically, FoundationDB provides global, ACID transactions with serializable isolation using optimistic concurrency. All reads and modifications of key-value pairs in FoundationDB are done within the context of a transaction. A transaction is a small unit of work that is both reliably performed and logically independent of other transactions.

FoundationDB implements ACID properties using multiversion concurrency control (MVCC) for reads and optimistic concurrency for writes. As a result, neither reads nor writes are blocked by other readers or writers. Instead, conflicting transactions will fail at commit time and will usually be retried by the client. FoundationDB does not support long-running transactions, currently defined as those lasting over five seconds. The reasons for this design limitation relate to multiversion concurrency control.</text>
      <sha1>l1m1smncnhz377lcupyvaup7maznhxs</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>VoltDB Consistency Features</title>
    <ns>0</ns>
    <id>356</id>
    <revision>
      <id>2372</id>
      <parentid>2266</parentid>
      <timestamp>2015-01-27T19:53:48Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="3710">{{Consistency Features
|SQLDatabase=VoltDB
|Object-Level isolation on updates=supported
|Const Object Isolation URL=http://voltdb.com/blog/what-voltdb-stored-procedures
|ACID transactions in single database=supported
|Const ACID Trans URL=http://docs.voltdb.com/UsingVoltDB/ChapAppDesign.php
|Distributed ACID transactions=not supported
|Const Distributed Trans URL=https://forum.voltdb.com/showthread.php?1241-Jboss-connection-config-for-voltdb
|Updates applied to transaction log before returning from write=supported
|Const Log Writes URL=http://docs.voltdb.com/UsingVoltDB/ChapCmdLog.php
|Specify Quorum Reads/Writes=not relevant
|Specify number of replicas to write to=specified in the database configuration
|Const Replica Write URL=http://voltdb.com/blog/scaling-voltdb-clustered-database
|Behaviour when write cannot complete on specified number of replicas=not applicable
|Writes configured to never fail=not supported
|Specify number of replicas to read from=not supported
|Read from replica master only=not applicable - peer to peer
|Object level timestamps to detect conflicts=not applicable: single threaded
|Efficient protocol to rapidly propagate updates across replicas (minimize inconsistency window)=fixed
}}
VoltDB supports complex multi-SQL statement ACID transactions. The transactional system in VoltDB supports serializable isolation, complete multistatement atomicity and roll-back, and strong durability guarantees.

In VoltDB, a stored procedure and a transaction are one and the same. The stored procedure succeeds or rolls back as a whole. it is the responsibility of the application developer to ensure that the SQL queries within the stored procedure are actually single-partitioned. VoltDB does not warn you about SELECT or DELETE statements that will return incomplete results. VoltDB does generate a runtime error if you attempt to INSERT a row that does not belong in the current partition.

Command logging provides a more complete solution to the durability and availability of your VoltDB database. Command logging keeps a record of every transaction (that is, stored procedure) as it is executed. Then, if the servers fail for any reason, the database can restore the last snapshot and &quot;replay&quot; the subsequent logs to re-establish the database contents in their entirety. The key to command logging is that it logs the invocations, not the consequences, of the transactions. A single stored procedure can include many individual SQL statements and each SQL statement can modify hundreds or thousands of table rows. By recording only the invocation, the command logs are kept to a bare minimum, limiting the impact the disk I/O will have on performance.

If the command logs are being written asynchronously (which is the default), results are returned to the client applications as soon as the transactions are completed. This allows the transactions to execute uninterrupted. However, with asynchronous logging there is always the possibility that a catastrophic event (such as a power failure) could cause the cluster to fail. In that case, any transactions completed since the last write and before the failure would be lost. The smaller the frequency, the less data that could be lost. This is how you &quot;dial up&quot; the amount of durability you want using the configuration options for command logging. In some cases, no loss of data is acceptable. For those situations, it is best to use synchronous logging. When you select synchronous logging, no results are returned to the client applications until those transactions are written to the log. In other words, the results for all of the transactions since the last write are held on the server until the next write occurs.</text>
      <sha1>jfpb5loa4f2bbqle6qrlqkzb2l5ivko</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Oracle NoSQL Consistency Features</title>
    <ns>0</ns>
    <id>536</id>
    <revision>
      <id>2962</id>
      <parentid>2959</parentid>
      <timestamp>2015-08-25T03:32:05Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="1772">{{Consistency Features
|SQLDatabase=Oracle NoSQL
|Object-Level isolation on updates=supported
|Const Object Isolation URL=http://docs.oracle.com/cd/NOSQL/html/GettingStartedGuide/values.html
|ACID transactions in single database=supported
|Const ACID Trans URL=http://www.oracle.com/technetwork/database/nosqldb/overview/nosql-transactions-497227.html
|Distributed ACID transactions=not supported
|Updates applied to transaction log before returning from write=supported
|Const Log Writes URL=http://www.oracle.com/technetwork/database/nosqldb/overview/nosql-transactions-497227.html
|Specify Quorum Reads/Writes=in the client
|Const Quorum URL=http://docs.oracle.com/cd/NOSQL/html/GettingStartedGuideTables/durability.html
|Specify number of replicas to write to=specified in the client
|Const Replica Write URL=http://docs.oracle.com/cd/NOSQL/html/GettingStartedGuideTables/durability.html
|Behaviour when write cannot complete on specified number of replicas=a rollback at all replicas
|Const Write Replica Fail URL=http://docs.oracle.com/cd/NOSQL/html/GettingStartedGuideTables/storewrites.html
|Specify number of replicas to read from=not applicable: master-slave
|Read from replica master only=specified in the client
|Const Master Read URL=http://docs.oracle.com/cd/NOSQL/html/driver_table_javascript/api-reference/global.html
|Object level timestamps to detect conflicts=not applicable: master-slave
|Efficient protocol to rapidly propagate updates across replicas (minimize inconsistency window)=fixed
}}
Oracle NoSQL can execute a sequence of operations as a single atomic unit as long as all the records that are going to be operated upon share the same Major Key Path. By atomic unit, we mean all of the operations will execute successfully, or none of them will.</text>
      <sha1>9i1o1rixqf9cin0g62rlq2o9n7t9bo4</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>OrientDB Consistency Features</title>
    <ns>0</ns>
    <id>542</id>
    <revision>
      <id>3318</id>
      <parentid>3107</parentid>
      <timestamp>2016-05-02T18:07:49Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="2069">{{Consistency Features
|SQLDatabase=OrientDB
|Object-Level isolation on updates=Multi-Version Concurrency Control (MVCC)
|Const Object Isolation URL=http://orientdb.com/docs/last/Transactions.html#optimistic-transaction
|ACID transactions in single database=supported
|Const ACID Trans URL=http://orientdb.com/docs/last/Transactions.html#transactions
|Distributed ACID transactions=not supported
|Updates applied to transaction log before returning from write=supported
|Const Log Writes URL=http://orientdb.com/docs/last/Paginated-Local-Storage.html#write-ahead-operation-log-wal
|Specify Quorum Reads/Writes=in both the database and data center configuration
|Const Quorum URL=http://orientdb.com/docs/last/Distributed-Architecture.html#split-brain-network-problem
|Specify number of replicas to write to=specified in the database configuration
|Const Replica Write URL=http://orientdb.com/docs/last/Distributed-Configuration.html#default-distributed-db-config-json
|Behaviour when write cannot complete on specified number of replicas=a rollback at all replicas
|Const Write Replica Fail URL=http://orientdb.com/docs/last/Distributed-Architecture.html#distributed-transactions
|Specify number of replicas to read from=specified in the database configuration
|Const Replica Read URL=http://orientdb.com/docs/last/Distributed-Configuration.html#default-distributed-db-config-json
|Read from replica master only=not applicable - peer to peer
|Const Master Read URL=http://orientdb.com/docs/last/Replication.html#replication
|Object level timestamps to detect conflicts=not supported
}}

OrientDB can be configured to use transactions or not:
http://orientdb.com/docs/last/Graph-Consistency.html

A failed write will only roll-back if the quorum is not met:
http://orientdb.com/docs/last/Distributed-Architecture.html#distributed-transactions

Object level timestamps: OrientDB doesn't directly support timestamp conflict resolution, however: &quot;it's possible to inject custom logic by writing a Java class&quot; (http://orientdb.com/docs/2.0/orientdb.wiki/SQL-Alter-SQLDatabase.html</text>
      <sha1>kkgm3qat2yxutvcc0gnu3yqx9i025xl</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Couchbase Consistency Features</title>
    <ns>0</ns>
    <id>551</id>
    <revision>
      <id>3304</id>
      <parentid>3259</parentid>
      <timestamp>2016-04-25T17:45:50Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="3097">{{Consistency Features
|SQLDatabase=Couchbase
|Object-Level isolation on updates=Multi-Version Concurrency Control (MVCC)
|Const Object Isolation URL=https://en.wikipedia.org/wiki/List_of_databases_using_MVCC
|ACID transactions in single database=lightweight transactions (e.g. compare and set)
|Const ACID Trans URL=http://blog.couchbase.com/couchbase-101-q-and-a
|Distributed ACID transactions=not supported
|Updates applied to transaction log before returning from write=supported
|Const Log Writes URL=http://developer.couchbase.com/documentation/server/4.0/developer-guide/durability.html
|Specify Quorum Reads/Writes=not supported
|Const Quorum URL=http://developer.couchbase.com/documentation/server/4.0/developer-guide/durability.html
|Specify number of replicas to write to=specified in the client
|Const Replica Write URL=http://developer.couchbase.com/documentation/server/4.0/developer-guide/durability.html
|Behaviour when write cannot complete on specified number of replicas=no rollback: write returns replication error
|Const Write Replica Fail URL=http://developer.couchbase.com/documentation/server/4.0/developer-guide/durability.html
|Specify number of replicas to read from=not supported
|Read from replica master only=specified in the client
|Const Master Read URL=http://developer.couchbase.com/documentation/server/4.0/architecture/data-service-core-data-access.html
|Object level timestamps to detect conflicts=not supported
|Const Timestamps URL=http://stackoverflow.com/questions/25154573/couchbase-replication-handling
}}
Applications may specify requirements for durability to the Couchbase client to wait until the item has also been persisted and replicated. This ensures greater durability of your data against failure in certain edge cases, such as a slow network or storage media. Operations performed using the durability requirement options will appear as failures to the application if the modification could not be successfully stored to disk and/or replicated to replica nodes. Upon receiving such a failure response, the application may retry the operation or mark it as a failure. In any event, the application will never be under the mistaken assumption that the modification was performed when it fact it was lost inside one of the aforementioned queues.

When retrieving data using a key, Couchbase Server database engine provides full consistency (sometimes referred to as read-your-own-write semantics) by ensuring access to the master vBucket or optionally allowing access to eventually consistent replica vBuckets for reads (also known as replica reads).

Replication of data in CouchBase between nodes is entirely peer-to-peer based so reading from master only is not a feature that peer-to-peer databases provide.

A key in couchbase is hashed to a vbucket(shard). That vbucket only ever lives on one node in the cluster so there is only ever one writable copy of the data. When two clients write to the same key, the client that wrote last will &quot;win&quot;. The couchbase SDK do expose a number of operations to help with this, such as &quot;add()&quot; and &quot;cas()&quot;.</text>
      <sha1>cl6mmhcvoxp46hu2yllcwwzwqz7tew5</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Redis Consistency Features</title>
    <ns>0</ns>
    <id>560</id>
    <revision>
      <id>3297</id>
      <parentid>3281</parentid>
      <timestamp>2016-04-20T19:31:03Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="4170">{{Consistency Features
|SQLDatabase=Redis
|Object-Level isolation on updates=supported
|Const Object Isolation URL=http://redis.io/topics/transactions
|ACID transactions in single database=lightweight transactions (e.g. compare and set)
|Const ACID Trans URL=http://redis.io/topics/transactions
|Distributed ACID transactions=not supported
|Const Distributed Trans URL=http://redis.io/topics/cluster-tutorial
|Updates applied to transaction log before returning from write=supported
|Const Log Writes URL=http://redis.io/topics/persistence
|Specify Quorum Reads/Writes=not supported
|Const Quorum URL=http://redis.io/topics/replication
|Specify number of replicas to write to=specified in the database configuration
|Const Replica Write URL=http://redis.io/topics/replication#allow-writes-only-with-n-attached-replicas
|Behaviour when write cannot complete on specified number of replicas=no rollback: write returns replication error
|Const Write Replica Fail URL=http://redis.io/topics/replication#allow-writes-only-with-n-attached-replicas
|Specify number of replicas to read from=not applicable: master-slave
|Const Replica Read URL=http://redis.io/topics/replication
|Read from replica master only=specified in the client
|Const Master Read URL=http://redis.io/commands/readonly
|Object level timestamps to detect conflicts=not applicable: master-slave
|Const Timestamps URL=http://redis.io/topics/cluster-tutorial
}}
All the commands in a Redis transaction are serialized and executed sequentially. It can never happen that a request issued by another client is served in the middle of the execution of a Redis transaction. This guarantees that the commands are executed as a single isolated operation.

Either all of the commands or none are processed, so a Redis transaction is also atomic. The EXEC command triggers the execution of all the commands in the transaction, so if a client loses the connection to the server in the context of a transaction before calling the MULTI command none of the operations are performed, instead if the EXEC command is called, all the operations are performed. When using the append-only file Redis makes sure to use a single write(2) syscall to write the transaction on disk. However if the Redis server crashes or is killed by the system administrator in some hard way it is possible that only a partial number of operations are registered. Redis will detect this condition at restart, and will exit with an error. Using the redis-check-aof tool it is possible to fix the append only file that will remove the partial transaction so that the server can start again.

Redis provides a different range of persistence options: The RDB persistence performs point-in-time snapshots of your dataset at specified intervals; the AOF persistence logs every write operation received by the server, that will be played again at server startup, reconstructing the original dataset. Commands are logged using the same format as the Redis protocol itself, in an append-only fashion. Redis is able to rewrite the log on background when it gets too big.

Starting with Redis 2.8, it is possible to configure a Redis master to accept write queries only if at least N slaves are currently connected to the master. This is how the feature works: Redis slaves ping the master every second, acknowledging the amount of replication stream processed. Redis masters will remember the last time it received a ping from every slave. The user can configure a minimum number of slaves that have a lag not greater than a maximum number of seconds. If there are at least N slaves, with a lag less than M seconds, then the write will be accepted.

Normally slave nodes will redirect clients to the authoritative master for the hash slot involved in a given command, however clients can use slaves in order to scale reads using the READONLY command.
READONLY tells a Redis Cluster slave node that the client is willing to read possibly stale data and is not interested in running write queries. When the connection is in readonly mode, the cluster will send a redirection to the client only if the operation involves keys not served by the slave's master node.</text>
      <sha1>cuoipgrc2cdgy4712ofl34hi5xj6amw</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Amazon DynamoDB Consistency Features</title>
    <ns>0</ns>
    <id>569</id>
    <revision>
      <id>3311</id>
      <parentid>3134</parentid>
      <timestamp>2016-04-27T21:06:25Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="3727">{{Consistency Features
|SQLDatabase=Amazon DynamoDB
|Object-Level isolation on updates=supported
|Const Object Isolation URL=https://aws.amazon.com/dynamodb/faqs/#What_is_DynamoDB
|ACID transactions in single database=not supported
|Const ACID Trans URL=https://github.com/awslabs/dynamodb-transactions/blob/master/DESIGN.md
|Distributed ACID transactions=not supported
|Const Distributed Trans URL=https://github.com/awslabs/dynamodb-transactions/blob/master/DESIGN.md
|Updates applied to transaction log before returning from write=supported
|Const Log Writes URL=http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Introduction.html
|Specify Quorum Reads/Writes=in the client
|Const Quorum URL=http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf
|Specify number of replicas to write to=not supported
|Const Replica Write URL=http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf
|Behaviour when write cannot complete on specified number of replicas=hinted handoffs: writes are applied later when a replica recovers
|Const Write Replica Fail URL=https://en.wikipedia.org/wiki/Dynamo_(storage_system)
|Specify number of replicas to read from=specified in the client
|Const Replica Read URL=http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf
|Read from replica master only=not applicable - peer to peer
|Object level timestamps to detect conflicts=supported
|Const Timestamps URL=http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf
}}
Amazon DynamoDB supports fast in-place updates. You can increment or decrement a numeric attribute in a row using a single API call. Similarly, you can atomically add or remove to sets, lists, or maps. http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/WorkingWithItems.html
--------------------------------------------------------------------------------
While Amazon DynamoDB tackles the core problems of database scalability, management, performance, and reliability, it does not have all the functionality of a relational database. It does not support complex relational queries (e.g. joins) or complex transactions. However, DynamoDB provides the tools (especially optimistic concurrency control) so that an application can achieve these properties and have full ACID transactions.
-----------------------------------------------------------------------------------
DynamoDB automatically spreads the data and traffic for your tables over a sufficient number of servers to handle your throughput and storage requirements, while maintaining consistent and fast performance. All of your data is stored on solid state disks (SSDs) and automatically replicated across multiple Availability Zones in an AWS region, providing built-in high availability and data durability.
---------------------------------------------------------------------------------------
Specify Quorum Reads/Writes 
It's not explicitly mentioned that we can specify the quorum read/writes, however, the  client allows us to specify the read and write capacity units which controls strong and eventual consistency.

Eventually Consistent Reads

When you read data from a DynamoDB table, the response might not reflect the results of a recently completed write operation. The response might include some stale data. However, if you repeat your read request after a short time, the response should return the latest data.

Strongly Consistent Reads

When you request a strongly consistent read, DynamoDB returns a response with the most up-to-date data, reflecting the updates from all prior write operations that were successful. Note that a strongly consistent read might not be available in the case of a network delay or outage.</text>
      <sha1>738srmuunxphlvn2uag8pf0jsnleowt</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Riak Data Model Features</title>
    <ns>0</ns>
    <id>154</id>
    <revision>
      <id>2429</id>
      <parentid>1147</parentid>
      <timestamp>2015-02-03T21:51:30Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="1412">{{Data Model
|SQLDatabase=Riak
|Data Model=Key-Value
|Data Model URL=http://en.wikipedia.org/wiki/Riak
|Enforced Schema=not required
|Data Schema URL=http://basho.com/riak-vs-cassandra/
|Opaque Data Objects (need application interpretation)=not required
|Data Opaque Objects URL=http://basho.com/distributed-data-types-riak-2-0/
|Hierarchical Data Objects (e.g. sub objects)=not supported
|Automatically Allocated Keys=supported
|Data Autokey URL=http://docs.basho.com/riak/latest/dev/using/basics/
|Composite Keys=not supported
|Secondary Indexes=supported
|Data 2i URL=http://docs.basho.com/riak/latest/dev/using/2i/
|Query by Key Ranges=supported
|Data Key Range URL=http://docs.basho.com/riak/latest/dev/using/2i/
|Query by Partial Keys=not supported
|Query by Non-keyed Values=not supported
|Map Reduce API=builtin
|Data Map Reduce URL=http://docs.basho.com/riak/latest/dev/using/mapreduce/
|Indexed Text Search=support in a plug-in (e.g. Solr)
|Data Text Search URL=http://docs.basho.com/riak/latest/dev/using/search/
}}
Riak is a straight Key/Value store. Riak’s schemaless design has zero restrictions on data type, so an object can be a JSON document at one moment and a JPEG at the next.

Secondary indexing (2i) in Riak gives developers the ability to tag an object stored in Riak, at write time, with one or more queryable values.

Secondary indexes allow querying by exact match or range on one index</text>
      <sha1>ec20i6rrutrd9ds0x13i0pfj9g4w0gs</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Cassandra Data Model Features</title>
    <ns>0</ns>
    <id>155</id>
    <revision>
      <id>2325</id>
      <parentid>1172</parentid>
      <timestamp>2015-01-22T21:08:16Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="3048">{{Data Model
|SQLDatabase=Cassandra
|Data Model=Column
|Data Model URL=http://www.datastax.com/docs/0.8/ddl/column_family
|Enforced Schema=required
|Data Schema URL=http://www.datastax.com/documentation/cql/3.1/cql/ddl/ddl_music_service_c.html
|Opaque Data Objects (need application interpretation)=not required
|Hierarchical Data Objects (e.g. sub objects)=supported
|Data Hierarchy URL=http://www.datastax.com/documentation/cql/3.1/cql/cql_intro_c.html
|Automatically Allocated Keys=not supported
|Composite Keys=supported
|Data Composite Key URL=http://www.datastax.com/documentation/cql/3.1/cql/ddl/ddl_compound_keys_c.html
|Secondary Indexes=supported
|Data 2i URL=http://www.datastax.com/documentation/cql/3.1/cql/ddl/ddl_when_use_index_c.html
|Query by Key Ranges=supported
|Data Key Range URL=http://planetcassandra.org/blog/flite-breaking-down-the-cql-where-clause/
|Query by Partial Keys=supported
|Data Partial Key URL=http://planetcassandra.org/blog/composite-keys-in-apache-cassandra/
|Query by Non-keyed Values=not supported
|Map Reduce API=integrated with an external framework
|Data Map Reduce URL=http://planetcassandra.org/blog/composite-keys-in-apache-cassandra/
|Indexed Text Search=support in a plug-in (e.g. Solr)
|Data Text Search URL=http://www.datastax.com/what-we-offer/products-services/datastax-enterprise/apache-solr
}}
CQL requires a schema definition. CQL provides an API to Cassandra that is simpler than the Thrift API for new applications. The Thrift API and legacy versions of CQL expose the internal storage structure of Cassandra. CQL adds an abstraction layer that hides implementation details of this structure and provides native syntaxes for collections and other common encodings.

In Cassandra, you define column families. Column families can (and should) define metadata about the columns, but the actual columns that make up a row are determined by the client application. Each row can have a different set of columns.

A compound primary key includes the partition key. The partition key determines which node stores the data. A compound primary key also includes one or more additional columns that determine per-partition clustering. Cassandra uses the first column name in the primary key definition as the partition key.

Cassandra's built-in indexes are best on a table having many rows that contain the indexed value. The more unique values that exist in a particular column, the more overhead you will have, on average, to query and maintain the index. For example, suppose you had a playlists table with a billion songs and wanted to look up songs by the artist. Many songs will share the same column value for artist. The artist column is a good candidate for an index.

In CQL, if you want to select a single row, you must know all of the composite-keys. You can however query a compound key using only the partition key. 

With DataStax Enterprise, you can search  data that’s stored in Cassandra via built-in integration with Apache Solr™, the popular Java-based open source search engine.</text>
      <sha1>ikhg4ib53qnlgwggqfqx0lb3cn6y8pn</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Neo4j Data Model Features</title>
    <ns>0</ns>
    <id>175</id>
    <revision>
      <id>2386</id>
      <parentid>2385</parentid>
      <timestamp>2015-01-27T21:12:20Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="1936">{{Data Model
|SQLDatabase=Neo4j
|Data Model=Graph
|Data Model URL=http://neo4j.com/docs/stable/graphdb-neo4j.html
|Enforced Schema=not required
|Data Schema URL=http://neo4j.com/docs/stable/graphdb-neo4j-schema.html
|Opaque Data Objects (need application interpretation)=not required
|Data Opaque Objects URL=http://neo4j.com/docs/stable/graphdb-neo4j-nodes.html
|Hierarchical Data Objects (e.g. sub objects)=supported
|Automatically Allocated Keys=not supported
|Composite Keys=not supported
|Secondary Indexes=supported
|Data 2i URL=http://neo4j.com/docs/stable/graphdb-neo4j-schema.html#graphdb-neo4j-schema-indexes
|Query by Key Ranges=supported
|Data Key Range URL=http://neo4j.com/docs/stable/query-where.html
|Query by Partial Keys=supported
|Data Partial Key URL=http://neo4j.com/docs/stable/query-where.html#_regular_expressions
|Query by Non-keyed Values=supported
|Map Reduce API=not supported
|Indexed Text Search=support in a plug-in (e.g. Solr)
|Data Text Search URL=http://neo4j.com/docs/stable/indexing-lucene-extras.html
}}
The fundamental units that form a graph are nodes and relationships. In Neo4j, both nodes and relationships can contain properties.

Nodes are often used to represent entities, but depending on the domain relationships may be used for that purpose as well. Hierarchical data structures are inherently supported in graph databases.

Apart from properties and relationships, nodes can also be labeled with zero or more labels. Neo4J does not require a unique primary key. An application can give any node or relationship a key that it considers to be primary. 

Performance is gained by creating indexes, which improve the speed of looking up nodes in the database. Once you’ve specified which properties to index, Neo4j will make sure your indexes are kept up to date as your graph evolves. Any operation that looks up nodes by the newly indexed properties will see a significant performance boost</text>
      <sha1>ffn0ukufhnmhe6r7xlflzan9tnkg33w</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>CouchDB Data Model Features</title>
    <ns>0</ns>
    <id>262</id>
    <revision>
      <id>2457</id>
      <parentid>2428</parentid>
      <timestamp>2015-02-09T21:15:55Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="1476">{{Data Model
|SQLDatabase=CouchDB
|Data Model=Document
|Data Model URL=http://docs.couchdb.org/en/1.6.1/intro/overview.html
|Enforced Schema=not required
|Data Schema URL=http://guide.couchdb.org/draft/why.html
|Opaque Data Objects (need application interpretation)=not required
|Data Opaque Objects URL=http://docs.couchdb.org/en/1.6.1/intro/overview.html
|Hierarchical Data Objects (e.g. sub objects)=supported
|Automatically Allocated Keys=supported
|Data Autokey URL=http://docs.couchdb.org/en/1.6.1/intro/tour.html
|Composite Keys=supported
|Secondary Indexes=supported
|Data 2i URL=http://sitr.us/2009/06/30/database-queries-the-couchdb-way.html
|Query by Key Ranges=supported
|Data Key Range URL=http://wiki.apache.org/couchdb/HTTP_view_API
|Query by Partial Keys=not supported
|Query by Non-keyed Values=not supported
|Map Reduce API=builtin
|Data Map Reduce URL=http://wiki.apache.org/couchdb/Introduction_to_CouchDB_views
|Indexed Text Search=support in a plug-in (e.g. Solr)
|Data Text Search URL=https://github.com/rnewson/couchdb-lucene/
}}
CouchDB documents are stored in JSON format,  supporting arrays and dictionaries to represent collections of data

CoucbDB supports materialized views that are built incrementally using a Mapreduce like function. Views are re-built upon access by default. A stale flag turns off this default behavior.

CouchDB stores data to disk by “append-only” files. As the files continue to grow, they require occasional compaction.</text>
      <sha1>kuvv9ugoyr9233llo3lbdua7075htbm</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>MongoDB Data Model Features</title>
    <ns>0</ns>
    <id>317</id>
    <revision>
      <id>2421</id>
      <parentid>1967</parentid>
      <timestamp>2015-02-03T17:47:38Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="3015">{{Data Model
|SQLDatabase=MongoDB
|Data Model=Document
|Data Model URL=http://www.mongodb.org/about/
|Enforced Schema=not required
|Data Schema URL=http://docs.mongodb.org/manual/data-modeling/
|Opaque Data Objects (need application interpretation)=not required
|Data Opaque Objects URL=http://docs.mongodb.org/manual/core/data-modeling-introduction/
|Hierarchical Data Objects (e.g. sub objects)=supported
|Data Hierarchy URL=http://docs.mongodb.org/manual/core/data-modeling-introduction/
|Automatically Allocated Keys=supported
|Data Autokey URL=http://docs.mongodb.org/manual/reference/glossary/
|Composite Keys=not supported
|Data Composite Key URL=http://docs.mongodb.org/manual/core/index-compound/#index-type-compound
|Secondary Indexes=supported
|Data 2i URL=http://docs.mongodb.org/manual/core/crud-introduction/
|Query by Key Ranges=supported
|Data Key Range URL=http://docs.mongodb.org/manual/tutorial/query-documents/
|Query by Partial Keys=supported
|Data Partial Key URL=http://docs.mongodb.org/manual/core/index-compound/
|Query by Non-keyed Values=supported
|Data Query Scan URL=http://docs.mongodb.org/manual/tutorial/query-documents/
|Map Reduce API=builtin
|Data Map Reduce URL=http://docs.mongodb.org/manual/core/map-reduce/
|Indexed Text Search= proprietary (database-specific)
|Data Text Search URL=http://docs.mongodb.org/manual/core/index-text/
}}
Data in MongoDB has a flexible schema. Unlike SQL databases, where you must determine and declare a table’s schema before inserting data, MongoDB’s collections do not enforce document structure. This flexibility facilitates the mapping of documents to an entity or an object. Each document can match the data fields of the represented entity, even if the data has substantial variation. In practice, however, the documents in a collection share a similar structure.

Embedded documents capture relationships between data by storing related data in a single document structure. MongoDB documents make it possible to embed document structures as sub-documents in a field or array within a document. These denormalized data models allow applications to retrieve and manipulate related data in a single database operation.

MongoDB supports compound indexes, where a single index structure holds references to multiple fields [1] within a collection’s documents.

MongoDB provides a number of different index types. You can create indexes on any field or embedded field within a document or sub-document. You can create single field indexes or compound indexes. MongoDB also supports indexes of arrays, called multi-key indexes, as well as indexes on geospatial data.

Map-reduce is a data processing paradigm for condensing large volumes of data into useful aggregated results. For map-reduce operations, MongoDB provides the mapReduce database command.

MongoDB provides text indexes to support text search of string content in documents of a collection.

text indexes can include any field whose value is a string or an array of string elem</text>
      <sha1>n15e722fv3ciial26q3jy36fe32xffe</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>HBase Data Model Features</title>
    <ns>0</ns>
    <id>326</id>
    <revision>
      <id>2412</id>
      <parentid>2410</parentid>
      <timestamp>2015-02-03T15:20:27Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="2243">{{Data Model
|SQLDatabase=HBase
|Data Model=Column
|Data Model URL=http://www-01.ibm.com/software/data/infosphere/hadoop/hbase/
|Enforced Schema=not required
|Data Schema URL=http://hbase.apache.org/book.html#schema
|Opaque Data Objects (need application interpretation)=not required
|Hierarchical Data Objects (e.g. sub objects)=not supported
|Data Hierarchy URL=http://hbase.apache.org/book.html#supported.datatypes
|Automatically Allocated Keys=not supported
|Composite Keys=supported
|Data Composite Key URL=http://www.flurry.com/2012/06/12/137492485#.VNDkEGjF98E
|Secondary Indexes=not supported
|Data 2i URL=http://hbase.apache.org/book.html#secondary.indexes
|Query by Key Ranges=supported
|Data Key Range URL=http://www.cloudera.com/content/cloudera/en/documentation/core/v5-2-x/topics/admin_hbase_scanning.html
|Query by Partial Keys=supported
|Data Partial Key URL=http://www.cloudera.com/content/cloudera/en/documentation/core/v5-2-x/topics/admin_hbase_filtering.html?scroll=xd_583c10bfdbd326ba-7dae4aa6-147c30d0933--7c9e
|Query by Non-keyed Values=supported
|Data Query Scan URL=http://hbase.apache.org/book.html#secondary.indexes
|Map Reduce API=builtin
|Data Map Reduce URL=http://hbase.apache.org/book.html#mapreduce
|Indexed Text Search=support in a plug-in (e.g. Solr)
|Data Text Search URL=http://ngdata.github.io/hbase-indexer/
}}
HBase is a column-oriented database management system that runs on top of HDFS.

HBASE does not natively support secondary indexes, although they can be built in seperate tables using map-reduce jobs. 

Depending on the query use case, it may be appropriate to use client.filter. In this case, no secondary index is created - it is effectively a table scan.

A Scan fetches zero or more rows of a table. By default, a Scan reads the entire table from start to end. You can limit your Scan results in several different ways, which affect the Scan's load in terms of IO, network, or both, as well as processing load on the client side. You can specify a key range using a startrow and stoprow. A PrefixFilter takes a single argument, a prefix of a row key. It returns only those key-values present in a row that start with the specified row prefix, thus supporting compoung and partial key queries.</text>
      <sha1>oyfsi894paw7ai2hzn4z91di1quh11i</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Accumulo Data Model Features</title>
    <ns>0</ns>
    <id>334</id>
    <revision>
      <id>2401</id>
      <parentid>2400</parentid>
      <timestamp>2015-01-28T21:50:01Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="1847">{{Data Model
|SQLDatabase=Accumulo
|Data Model=Column
|Data Model URL=http://en.wikipedia.org/wiki/Apache_Accumulo
|Enforced Schema=not required
|Data Schema URL=http://accumulo.apache.org/user_manual_1.3-incubating/Table_Design.html
|Opaque Data Objects (need application interpretation)=not required
|Data Opaque Objects URL=http://accumulo.apache.org/user_manual_1.3-incubating/Accumulo_Design.html
|Hierarchical Data Objects (e.g. sub objects)=not supported
|Automatically Allocated Keys=not supported
|Composite Keys=not supported
|Secondary Indexes=supported
|Data 2i URL=http://accumulo.apache.org/1.6/accumulo_user_manual.html#_indexing
|Query by Key Ranges=supported
|Data Key Range URL=http://accumulo.apache.org/1.6/accumulo_user_manual.html#_reading_data
|Query by Partial Keys=not supported
|Query by Non-keyed Values=supported
|Data Query Scan URL=https://www.safaribooksonline.com/library/view/accumulo/9781491947098/ch01.html
|Map Reduce API=builtin
|Data Map Reduce URL=http://accumulo.apache.org/1.6/accumulo_user_manual.html#_mapreduce
|Indexed Text Search=not supported
}}
Accumulo provides a richer data model than simple key-value stores, but is not a fully relational database. Data is represented as key-value pairs. All elements of the Key and the Value are represented as byte arrays except for Timestamp, which is a Long.

In order to support lookups via more than one attribute of an entity, additional indexes can be built. 

Accumulo tables can be used as the source and destination of MapReduce jobs. To use an Accumulo table with a MapReduce job (specifically with the new Hadoop API as of version 0.20), configure the job parameters to use the AccumuloInputFormat and AccumuloOutputFormat.

Full text seacrh is supported in the Sqrr Enterprise technology that is built on Accumulo (http://sqrrl.com/product/accumulo/)</text>
      <sha1>gvjhy5rlm9hu7vfsh5cef61okwupkoq</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>FoundationDB Data Model Features</title>
    <ns>0</ns>
    <id>341</id>
    <revision>
      <id>2453</id>
      <parentid>2117</parentid>
      <timestamp>2015-02-09T16:52:57Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="2010">{{Data Model
|SQLDatabase=FoundationDB
|Data Model=Relational
|Data Model URL=https://foundationdb.com/layers/sql/documentation/Concepts/index.html
|Enforced Schema=required
|Data Schema URL=https://foundationdb.com/layers/sql/documentation/Concepts/table.groups.html
|Opaque Data Objects (need application interpretation)=not required
|Hierarchical Data Objects (e.g. sub objects)=supported
|Data Hierarchy URL=https://foundationdb.com/layers/sql/documentation/Concepts/table.groups.html
|Automatically Allocated Keys=supported
|Data Autokey URL=https://foundationdb.com/layers/sql/documentation/SQL/ddl/create.table.html
|Composite Keys=supported
|Data Composite Key URL=https://foundationdb.com/layers/sql/documentation/SQL/ddl/create.table.html
|Secondary Indexes=supported
|Data 2i URL=https://foundationdb.com/layers/sql/documentation/SQL/ddl/create.index.html
|Query by Key Ranges=supported
|Data Key Range URL=https://foundationdb.com/layers/sql/documentation/SQL/dml/select.html
|Query by Partial Keys=not supported
|Data Partial Key URL=https://foundationdb.com/layers/sql/documentation/SQL/dml/select.html
|Query by Non-keyed Values=not supported
|Data Query Scan URL=https://foundationdb.com/layers/sql/documentation/SQL/dml/select.html
|Map Reduce API=not supported
|Data Map Reduce URL=https://foundationdb.com/key-value-store/white-papers/anti-features
|Indexed Text Search=not supported
|Data Text Search URL=https://foundationdb.com/layers/sql/documentation/SQL/indexes.html#fulltext-index
}}
Full-text indexes are designed to allow users to search within text strings. The FoundationDB SQL layer integrates with the Lucene full-text engine for full-text processing, index maintenance, and querying. Full-text indexes are currently disabled.

Analytic frameworks (eg MapReduce) are outside the scope of the FoundationDB core. However, because the core can use range reads to efficiently scan large swaths of data, analytics can be implemented within a layer, possibly as part of a query language.</text>
      <sha1>1m7mpb6udcgqjq8ix1ow95hho6lx1fc</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>VoltDB Data Model Features</title>
    <ns>0</ns>
    <id>365</id>
    <revision>
      <id>2446</id>
      <timestamp>2015-02-05T22:07:17Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <comment>Created page with &quot;{{Data Model |SQLDatabase=VoltDB |Data Model=Relational |Data Model URL=http://docs.voltdb.com/UsingVoltDB/ChapDesignSchema.php |Enforced Schema=required |Data Schema URL=http://...&quot;</comment>
      <text xml:space="preserve" bytes="1666">{{Data Model
|SQLDatabase=VoltDB
|Data Model=Relational
|Data Model URL=http://docs.voltdb.com/UsingVoltDB/ChapDesignSchema.php
|Enforced Schema=required
|Data Schema URL=http://docs.voltdb.com/UsingVoltDB/ChapOverview.php#IntroWhatIsVoltDB
|Opaque Data Objects (need application interpretation)=not required
|Hierarchical Data Objects (e.g. sub objects)=not supported
|Automatically Allocated Keys=not supported
|Data Autokey URL=http://docs.voltdb.com/UsingVoltDB/ddlref_createtable.php
|Composite Keys=supported
|Data Composite Key URL=http://docs.voltdb.com/UsingVoltDB/SchemaTables.php
|Secondary Indexes=supported
|Data 2i URL=http://docs.voltdb.com/UsingVoltDB/ddlref_createindex.php
|Query by Key Ranges=supported
|Data Key Range URL=http://docs.voltdb.com/UsingVoltDB/sqlref_select.php
|Query by Partial Keys=supported
|Data Partial Key URL=http://docs.voltdb.com/UsingVoltDB/sqlref_select.php
|Query by Non-keyed Values=supported
|Data Query Scan URL=http://docs.voltdb.com/UsingVoltDB/sqlref_select.php
|Map Reduce API=integrated with an external framework
|Data Map Reduce URL=http://voltdb.com/products/hadoop
|Indexed Text Search=not supported
|Data Text Search URL=http://stackoverflow.com/questions/21446176/do-voltdb-or-nuodb-need-elasticsearch
}}
VoltDB is a relational database product. Relational databases consist of tables and columns, with constraints, indexes, and views. VoltDB also uses standard SQL database definition language (DDL) statements to specify the database schema. So designing the schema for a VoltDB database uses the same skills and knowledge as designing a database for Oracle, MySQL, or any other relational database product.</text>
      <sha1>cv7kciinx5gza8bwx1wmxxrxfjswxql</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>OrientDB Data Model Features</title>
    <ns>0</ns>
    <id>543</id>
    <revision>
      <id>3321</id>
      <parentid>3319</parentid>
      <timestamp>2016-05-02T18:47:57Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="1501">{{Data Model
|SQLDatabase=OrientDB
|Data Model=Graph
|Data Model URL=http://orientdb.com/docs/last/Tutorial-Document-and-graph-model.html#multi-model
|Enforced Schema=optional
|Data Schema URL=http://orientdb.com/docs/last/Schema.html
|Opaque Data Objects (need application interpretation)=not required
|Data Opaque Objects URL=http://orientdb.com/docs/last/Concepts.html#documents
|Hierarchical Data Objects (e.g. sub objects)=supported
|Data Hierarchy URL=http://orientdb.com/docs/last/Concepts.html#class
|Automatically Allocated Keys=supported
|Data Autokey URL=http://orientdb.com/docs/last/Tutorial-Record-ID.html#record-id
|Composite Keys=supported
|Data Composite Key URL=http://orientdb.com/docs/last/Indexes.html#indexes-and-composite-keys
|Secondary Indexes=supported
|Data 2i URL=http://orientdb.com/docs/last/Indexes.html#index-types
|Query by Key Ranges=supported
|Data Key Range URL=http://orientdb.com/docs/last/Indexes.html#querying-index-ranges
|Query by Partial Keys=supported
|Data Partial Key URL=http://orientdb.com/docs/last/Indexes.html#partial-match-searches
|Query by Non-keyed Values=supported
|Data Query Scan URL=http://orientdb.com/docs/last/SQL-Where.html
|Map Reduce API=not supported
|Indexed Text Search=support in a plug-in (e.g. Solr)
|Data Text Search URL=http://orientdb.com/docs/last/Full-Text-Index.html
}}
&quot;The OrientDB engine supports Graph, Document, Key/Value, and Object models&quot;
http://orientdb.com/docs/last/Tutorial-Document-and-graph-model.html#multi-model</text>
      <sha1>thlj696735zt2q1kcdzezq2qq48hl4e</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Couchbase Data Model Features</title>
    <ns>0</ns>
    <id>552</id>
    <revision>
      <id>3305</id>
      <parentid>3285</parentid>
      <timestamp>2016-04-25T18:13:32Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="2774">{{Data Model
|SQLDatabase=Couchbase
|Data Model=Document
|Data Model URL=http://developer.couchbase.com/documentation/server/4.1/data-modeling/concepts-data-modeling-intro.html
|Enforced Schema=not required
|Data Schema URL=http://developer.couchbase.com/documentation/server/4.1/data-modeling/concepts-data-modeling-intro.html
|Opaque Data Objects (need application interpretation)=not required
|Data Opaque Objects URL=http://developer.couchbase.com/documentation/server/4.1/data-modeling/concepts-data-modeling-intro.html
|Hierarchical Data Objects (e.g. sub objects)=supported
|Data Hierarchy URL=http://developer.couchbase.com/documentation/server/4.1/data-modeling/concepts-data-modeling-intro.html
|Automatically Allocated Keys=supported
|Data Autokey URL=https://forums.couchbase.com/t/how-to-set-an-auto-increment-id/4892
|Composite Keys=supported
|Data Composite Key URL=http://developer.couchbase.com/documentation/server/4.1/data-modeling/logical-data-modeling.html
|Secondary Indexes=supported
|Data 2i URL=http://developer.couchbase.com/documentation/server/4.0/architecture/global-secondary-indexes.html
|Query by Key Ranges=supported
|Data Key Range URL=http://docs.couchbase.com/couchbase-manual-2.0/#partial-selection-and-key-ranges
|Query by Partial Keys=supported
|Data Partial Key URL=http://docs.couchbase.com/couchbase-manual-2.0/#partial-selection-and-key-ranges
|Query by Non-keyed Values=not supported
|Data Query Scan URL=http://developer.couchbase.com/documentation/server/4.1/developer-guide/retrieving.html
|Map Reduce API=builtin
|Data Map Reduce URL=http://docs.couchbase.com/admin/admin/Views/views-translateSQL.html
|Indexed Text Search=support in a plug-in (e.g. Solr)
|Data Text Search URL=https://github.com/couchbaselabs/cbft
}}
Couchbase documents themselves can contain nested structures (sub-documents). This allows developers to naturally express many-to-many relationships without requiring a “reference table” or “junction table”. It is also expressive for naturally hierarchical data.

Each entity instance is identified by a unique key. The unique key can be a composite of multiple attributes or a surrogate key generated using a counter or a UUID generator. Composite or compound keys can be utilized to represent immutable properties and efficient processing without retrieving values. 

Global secondary index (GSI) is a powerful solution for secondary lookup queries that are required for interactive applications that require low latencies. Global secondary indexes (GSIs) are defined using the CREATE INDEX statement in N1QL. The CREATE INDEX statement supports the use of document attributes, N1QL expressions including functions, and a filter (a WHERE clause to limit the documents being indexed) in the index key.</text>
      <sha1>6w7fnnz3j43jw1b1wokj9lmpoiqsy14</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Redis Data Model Features</title>
    <ns>0</ns>
    <id>561</id>
    <revision>
      <id>3298</id>
      <parentid>3282</parentid>
      <timestamp>2016-04-20T21:09:58Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="2447">{{Data Model
|SQLDatabase=Redis
|Data Model=Key-Value
|Data Model URL=http://redis.io/topics/data-types-intro
|Enforced Schema=not required
|Data Schema URL=http://redis.io/topics/twitter-clone
|Opaque Data Objects (need application interpretation)=not required
|Data Opaque Objects URL=http://redis.io/topics/twitter-clone
|Hierarchical Data Objects (e.g. sub objects)=not supported
|Data Hierarchy URL=http://stackoverflow.com/questions/16094574/alternatives-to-nested-structures-in-redis
|Automatically Allocated Keys=not supported
|Data Autokey URL=http://redis.io/topics/data-types-intro
|Composite Keys=not supported
|Data Composite Key URL=http://redis.io/topics/indexes
|Secondary Indexes=not supported
|Data 2i URL=http://openmymind.net/Data-Modeling-In-Redis/
|Query by Key Ranges=supported
|Data Key Range URL=http://redis.io/topics/indexes#lexicographical-indexes
|Query by Partial Keys=supported
|Data Partial Key URL=http://redis.io/commands/scan#the-match-option
|Query by Non-keyed Values=not supported
|Data Query Scan URL=http://stackoverflow.com/questions/5090781/whats-the-most-efficient-document-oriented-database-engine-to-store-thousands-o
|Map Reduce API=not supported
|Data Map Reduce URL=https://blog.pivotal.io/pivotal/products/making-hadoop-mapreduce-work-with-a-redis-cluster
|Indexed Text Search=not supported
|Data Text Search URL=http://stackoverflow.com/questions/5090781/whats-the-most-efficient-document-oriented-database-engine-to-store-thousands-o
}}
Redis is not a plain key-value store, actually it is a data structures server, supporting different kind of values. What this means is that, while in traditional key-value stores you associated string keys to string values, in Redis the value is not limited to a simple string, but can also hold more complex data structures.

Redis is not a document oriented database. To use the complicated nested data structure, you can serialize your complex objects and store them as strings or you can split your objects in different keys.

Redis is not exactly a key-value store, since values can be complex data structures. However it has an external key-value shell: at API level data is addressed by the key name. It is fair to say that, natively, Redis only offers primary key access.

With Redis you cannot search by any fields of the data structure and would have to implement the index to be able to search. Redis cannot store anything but strings and flat hashes.</text>
      <sha1>62i6twvg777cpngeghwc1or6jk0aw4w</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Amazon DynamoDB Data Model Features</title>
    <ns>0</ns>
    <id>570</id>
    <revision>
      <id>3312</id>
      <parentid>3151</parentid>
      <timestamp>2016-04-27T21:25:01Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="3636">{{Data Model
|SQLDatabase=Amazon DynamoDB
|Data Model=Key-Value
|Data Model URL=https://aws.amazon.com/dynamodb/faqs/#Data_Models_and_APIs
|Enforced Schema=optional
|Data Schema URL=https://aws.amazon.com/dynamodb/faqs/#Data_Models_and_APIs
|Opaque Data Objects (need application interpretation)=not required
|Data Opaque Objects URL=https://aws.amazon.com/dynamodb/faqs/#Data_Models_and_APIs
|Hierarchical Data Objects (e.g. sub objects)=supported
|Data Hierarchy URL=http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DataFormat.html
|Automatically Allocated Keys=not supported
|Data Autokey URL=https://aws.amazon.com/dynamodb/faqs/#Data_Models_and_APIs
|Composite Keys=supported
|Data Composite Key URL=https://aws.amazon.com/dynamodb/faqs/#Data_Models_and_APIs
|Secondary Indexes=supported
|Data 2i URL=https://aws.amazon.com/dynamodb/faqs/#Data_Models_and_APIs
|Query by Key Ranges=supported
|Data Key Range URL=http://docs.pythonboto.org/en/latest/ref/dynamodb.html#boto.dynamodb.layer1.Layer1.query
|Query by Partial Keys=supported
|Data Partial Key URL=http://docs.aws.amazon.com/amazondynamodb/latest/gettingstartedguide/GettingStarted.JsShell.05.html#GettingStarted.JsShell.05.01.A
|Query by Non-keyed Values=supported
|Data Query Scan URL=https://aws.amazon.com/dynamodb/faqs/#Data_Models_and_APIs
|Map Reduce API=integrated with an external framework
|Data Map Reduce URL=http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/EMRforDynamoDB.Walkthrough.html
|Indexed Text Search=support in a plug-in (e.g. Solr)
|Data Text Search URL=http://docs.aws.amazon.com/cloudsearch/latest/developerguide/searching-dynamodb-data.html
}}
The documentation specifies this under FAQ: What types of data structures does DynamoDB support?
DynamoDB supports key-value and document data structures.

Opaque Data Objects (need application interpretation):
http://www.allthingsdistributed.com/2014/10/document-model-dynamodb.html - 
Under 'NoSQL and Flexibility: Document Model' explains that dynamodb supports document data structures. So it is possible to access the nested attributes in JSON document.

Hierarchical Data Objects
The data hierarchy is defined by nested brackets of name-value pairs.

Automatically Allocated Keys
Each table must have a primary key. The primary key can be a single attribute key or a “composite” attribute key that combines two attributes. The attribute(s) you designate as a primary key must exist for every item as primary keys uniquely identify each item within the table.

Compound/Composite Keys
Item: An Item is composed of a primary or composite key and a flexible number of attributes

Secondary Indexes
You can create a Global Secondary Index or Local Secondary Index on any top-level JSON element.
The documentation specifies this under FAQ:Is querying JSON data in DynamoDB any different?

Query by Key Ranges/ Query by Partial Keys/ Query by Non-keyed Values
Using Query API –  Gets one or more items using the table primary key, or from a secondary index using the index key. You can narrow the scope of the query on a table by using comparison operators or expressions. You can also filter the query results using filters on non-key attributes. 
The documentation specifies this under FAQ: What are the APIs?

Map Reduce API
AWS EMR provides a map reduce framework which uses dynamodb as a data source

Indexed Text Search
DynamoDB also integrates with Elasticsearch using the Amazon DynamoDB Logstash Plugin, thus enabling developers to add free-text search for DynamoDB content.
The documentation specifies this under FAQ: What are the benefits of DynamoDB Streams?</text>
      <sha1>buythcx5177zfhi7pmovbm5zz5unkkc</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Riak Query Language Features</title>
    <ns>0</ns>
    <id>172</id>
    <revision>
      <id>2482</id>
      <parentid>2431</parentid>
      <timestamp>2015-03-26T14:39:58Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="1525">{{Query Languages
|SQLDatabase=Riak
|API-based=supported
|QL API URL=http://docs.basho.com/riak/latest/dev/references/apis/
|Declarative=not suppported
|REST/HTTP-based=supported
|QL REST URL=http://docs.basho.com/riak/latest/dev/references/http/
|Languages supported=Java, Python, C/C++, PHP, Ruby, Erlang, Javascript
|QL Languages URL=http://docs.basho.com/riak/latest/dev/using/libraries/
|Cursor-based queries=not suppported
|JOIN-style queries=not suppported
|Complex data types=maps, sets, nested structures
|QL Data Types URL=http://docs.basho.com/riak/2.0.0/dev/using/data-types/
|Restrict number of objects returned by a query=supported
|QL Restrict URL=http://docs.basho.com/riak/latest/dev/using/2i/
|Key matching options=exact
|QL Key Options URL=http://docs.basho.com/riak/latest/dev/using/2i/
|Sorting of query results=ascending
|QL Sort URL=http://docs.basho.com/riak/latest/dev/using/2i/
|Triggers=pre-commit, post-commit
|QL Triggers URL=http://docs.basho.com/riak/latest/dev/using/commit-hooks/
|Expire data values=not suppported
}}
Riak has a rich, full-featured HTTP 1.1 API.

Riak Data Types also include  counters, registers, and flags.

When asking for large result sets, it is often desirable to ask the servers to return chunks of results instead of a firehose. You can do so using max_results=&lt;n&gt;, where n is the number of results you'd like to receive when querying using secondary indexes.

Pre- and post-commit hooks are functions that are invoked before or after an object has been written to Riak.</text>
      <sha1>c0bllnimfeom1q6krsy6jox34i5dfqt</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Cassandra Query Language Features</title>
    <ns>0</ns>
    <id>173</id>
    <revision>
      <id>2330</id>
      <parentid>2326</parentid>
      <timestamp>2015-01-23T15:46:12Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="2262">{{Query Languages
|SQLDatabase=Cassandra
|API-based=supported
|QL API URL=http://www.datastax.com/documentation/cql/3.1/cql/cql_using/about_cql_c.html
|Declarative=supported
|QL Declarative URL=http://nosqlguide.com/column-store/intro-to-cassandra-a-wide-column-store/
|REST/HTTP-based=not suppported
|Languages supported=Java, C#, Python, Ruby, Javascript
|QL Languages URL=https://wiki.apache.org/cassandra/ClientOptions
|Cursor-based queries=supported
|QL Cursors URL=http://www.datastax.com/dev/blog/client-side-improvements-in-cassandra-2-0
|JOIN-style queries=not suppported
|QL Joins URL=http://www.datastax.com/docs/1.1/references/cql/index
|Complex data types=lists, maps, sets, nested structures
|QL Data Types URL=http://www.datastax.com/documentation/cql/3.1/cql/cql_reference/cql_data_types_c.html
|Restrict number of objects returned by a query=supported
|QL Restrict URL=http://www.datastax.com/documentation/cql/3.1/cql/cql_reference/select_r.html
|Key matching options=exact, partial match
|QL Key Options URL=http://www.datastax.com/documentation/cql/3.0/cql/cql_reference/select_r.html
|Sorting of query results=ascending, descending
|QL Sort URL=http://www.datastax.com/documentation/cql/3.0/cql/cql_using/use-columns-sort_t.html
|Triggers=pre-commit
|QL Triggers URL=http://www.datastax.com/documentation/cql/3.1/cql/cql_reference/trigger_r.html
|Expire data values=supported
|QL Expiry URL=http://www.datastax.com/documentation/cql/3.1/cql/cql_using/use_expire_c.html
}}
Cassandra's ParserMain query language is CQL - an SQL look-a-like. It also has the Thrift API-based query approach, although this is legacy.

Using the CQL LIMIT option, you can specify that the query return a limited number of rows.

Data in a column can have an optional expiration period called TTL (time to live). The client request specifies a TTL value, defined in seconds, for the data. TTL data is marked with a tombstone after the requested amount of time has expired. A tombstone exists for gc_grace_seconds. After data is marked with a tombstone, the data is automatically removed during the normal compaction and repair processes.

A trigger can be defined on a table and fires before a requested DML statement occurs, which ensures the atomicity of the transaction.</text>
      <sha1>l9d0wkhurp7i5brg01ysye07rbnctg7</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>MongoDB Query Language Features</title>
    <ns>0</ns>
    <id>258</id>
    <revision>
      <id>2422</id>
      <parentid>1640</parentid>
      <timestamp>2015-02-03T18:49:24Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="1945">{{Query Languages
|SQLDatabase=MongoDB
|API-based=supported
|QL API URL=http://docs.mongodb.org/manual/faq/fundamentals/#does-mongodb-support-sql
|Declarative=not suppported
|QL Declarative URL=http://docs.mongodb.org/manual/faq/fundamentals/#does-mongodb-support-sql
|REST/HTTP-based=not suppported
|QL REST URL=http://docs.mongodb.org/ecosystem/tools/http-interfaces/
|Languages supported=Java, C#, Python, C/C++, Perl, PHP, Ruby, Scala, Javascript
|QL Languages URL=http://docs.mongodb.org/ecosystem/drivers/
|Cursor-based queries=supported
|QL Cursors URL=http://docs.mongodb.org/manual/core/cursors/
|JOIN-style queries=not suppported
|QL Joins URL=http://docs.mongodb.org/manual/reference/database-references/
|Complex data types=arrays
|QL Data Types URL=http://docs.mongodb.org/manual/reference/bson-types/
|Restrict number of objects returned by a query=supported
|QL Restrict URL=http://docs.mongodb.org/manual/reference/method/cursor.limit/
|Key matching options=exact, partial match, regular expressions
|QL Key Options URL=http://docs.mongodb.org/manual/reference/operator/query/regex/
|Sorting of query results=ascending, descending
|QL Sort URL=http://docs.mongodb.org/manual/reference/method/cursor.sort/
|Triggers=not supported
|QL Triggers URL=http://stackoverflow.com/questions/9691316/how-to-listen-for-changes-to-a-mongodb-collection
|Expire data values=supported
|QL Expiry URL=http://docs.mongodb.org/manual/tutorial/expire-data/
}}
The mongod process includes a simple REST interface as a convenience. With no support for insert, update, or remove operations, it is generally used for monitoring, alert scripts, and administrative tasks. For full REST capabilities, consider using an external REST Interface such as Sleepy.Mongoose.

Mongodb provides regular expression capabilities for pattern matching strings in queries. MongoDB uses Perl compatible regular expressions (i.e. “PCRE” ) version 8.30 with UTF-8 support.</text>
      <sha1>gp6mgo4yo1blyl05beucel2q972euag</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>CouchDB Query Language Features</title>
    <ns>0</ns>
    <id>263</id>
    <revision>
      <id>2481</id>
      <parentid>2459</parentid>
      <timestamp>2015-03-26T14:24:29Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="954">{{Query Languages
|SQLDatabase=CouchDB
|API-based=supported
|QL API URL=http://wiki.apache.org/couchdb/HTTP_view_API
|Declarative=not suppported
|REST/HTTP-based=supported
|QL REST URL=http://wiki.apache.org/couchdb/HTTP_view_API
|Languages supported=Java, C/C++, Scala, Javascript
|QL Languages URL=https://cwiki.apache.org/confluence/display/COUCHDB/CouchDB+clients
|Cursor-based queries=not suppported
|JOIN-style queries=not suppported
|Complex data types=maps, nested structures, arrays
|QL Data Types URL=http://guide.couchdb.org/draft/json.html
|Restrict number of objects returned by a query=supported
|QL Restrict URL=http://wiki.apache.org/couchdb/HTTP_view_API
|Key matching options=exact, partial match, regular expressions
|Sorting of query results=ascending, descending
|QL Sort URL=http://wiki.apache.org/couchdb/HTTP_view_API
|Triggers=not supported
|Expire data values=not suppported
}}
Rows are returned in the order of the keys specified.</text>
      <sha1>91ewznkq3xglpbcz1ao1iguzk9fk4e0</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Neo4j Query Language Features</title>
    <ns>0</ns>
    <id>319</id>
    <revision>
      <id>2486</id>
      <parentid>2349</parentid>
      <timestamp>2015-04-01T15:32:32Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="1667">{{Query Languages
|SQLDatabase=Neo4j
|API-based=supported
|QL API URL=http://neo4j.com/docs/stable/tutorials-java-embedded.html
|Declarative=supported
|QL Declarative URL=http://neo4j.com/docs/stable/cypher-introduction.html
|REST/HTTP-based=supported
|QL REST URL=http://neo4j.com/docs/stable/rest-api.html
|Languages supported=Java, C#, Python, PHP, Ruby, Scala, Javascript
|QL Languages URL=http://neo4j.com/developer/language-guides/
|Cursor-based queries=not suppported
|JOIN-style queries=supported
|QL Joins URL=http://neo4j.com/docs/stable/query-sql-match.html
|Complex data types=arrays
|QL Data Types URL=http://neo4j.com/docs/stable/graphdb-neo4j-properties.html
|Restrict number of objects returned by a query=supported
|QL Restrict URL=http://neo4j.com/docs/stable/query-limit.html
|Key matching options=exact, partial match, regular expressions
|QL Key Options URL=http://neo4j.com/docs/stable/query-where.html
|Sorting of query results=ascending, descending
|QL Sort URL=http://neo4j.com/docs/stable/query-order.html
|Triggers=not supported
|Expire data values=not suppported
|QL Expiry URL=http://stackoverflow.com/questions/20710295/is-there-a-way-to-expire-value-in-neo4j-and-change-it-to-default-one
}}
Cypher is a declarative graph query language that allows for expressive and efficient querying and updating of the graph store. 

Also language drivers for Haskell, Clojure, GO.

MATCH clauses can return nodes that are attached to a specific relationship type, and multi-path relationships (e.g distance N) can also be queried. The MATCH clause is analogous to the JOIN in SQL

A shortestPath function will return the shortest path between 2 nodes.</text>
      <sha1>7t6tdlu3utrlrelopo59dmer7zcwimp</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>HBase Query Language Features</title>
    <ns>0</ns>
    <id>327</id>
    <revision>
      <id>2485</id>
      <parentid>2413</parentid>
      <timestamp>2015-04-01T15:21:42Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="2154">{{Query Languages
|SQLDatabase=HBase
|API-based=supported
|QL API URL=http://hbase.apache.org/
|Declarative=not suppported
|REST/HTTP-based=supported
|QL REST URL=http://hbase.apache.org/
|Languages supported=Java, Python, C/C++, PHP, Ruby
|QL Languages URL=http://hbase.apache.org/book.html#c
|Cursor-based queries=not suppported
|JOIN-style queries=not suppported
|Complex data types=none
|QL Data Types URL=http://hbase.apache.org/book.html#supported.datatypes
|Restrict number of objects returned by a query=supported
|QL Restrict URL=http://www.cloudera.com/content/cloudera/en/documentation/core/latest/topics/admin_hbase_filtering.html
|Key matching options=exact, partial match, regular expressions
|QL Key Options URL=http://www.cloudera.com/content/cloudera/en/documentation/core/v5-2-x/topics/admin_hbase_filtering.html?scroll=xd_583c10bfdbd326ba-7dae4aa6-147c30d0933--7c9e
|Sorting of query results=ascending
|Triggers=not supported
|QL Triggers URL=http://hbase.apache.org/book.html#cp
|Expire data values=supported
|QL Expiry URL=http://hbase.apache.org/book.html#ttl
|QL JOINs URL=http://www.smh.com.au
|QL RESTRICT URL=http://www.smh.com.au
}}
HBase supports a &quot;bytes-in/bytes-out&quot; interface via Put and Result, so anything that can be converted to an array of bytes can be stored as a value. Input could be strings, numbers, complex objects, or even images as long as they can rendered as bytes.

HBase supports coprocessors. Coprocessors come in two flavors: Observers and Endpoints. An Observer is similar to a database trigger, an Endpoint can be likened to a stored procedure. Coprocessors are not designed to be used by end users of HBase, but by HBase developers who need to add specialized functionality to HBase. One example of the use of coprocessors is pluggable compaction and scan policies, which are provided as coprocessors in link:HBASE-6427

Apache Thrift is a cross-platform, cross-language development framework. HBase includes a Thrift API and filter language. The Thrift API relies on client and server processes. Documentation about the HBase Thrift API is located at link:http://wiki.apache.org/hadoop/Hbase/ThriftApi.</text>
      <sha1>0p0e9wgvi5q0mgs1v0m2wyjzy6ji094</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Accumulo Query Language Features</title>
    <ns>0</ns>
    <id>335</id>
    <revision>
      <id>2404</id>
      <parentid>2403</parentid>
      <timestamp>2015-01-29T16:18:43Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="2196">{{Query Languages
|SQLDatabase=Accumulo
|API-based=supported
|QL API URL=http://sqrrl.com/product/accumulo/
|Declarative=not suppported
|REST/HTTP-based=not suppported
|Languages supported=Java, Python, PHP, Ruby
|QL Languages URL=https://accumulo.apache.org/1.4/user_manual/Writing_Accumulo_Clients.html#Proxy
|Cursor-based queries=supported
|QL Cursors URL=http://accumulo.apache.org/1.5/apidocs/org/apache/accumulo/core/file/rfile/bcfile/TFile.Reader.Scanner.html
|JOIN-style queries=not suppported
|Complex data types=none
|QL Data Types URL=https://www.safaribooksonline.com/library/view/accumulo/9781491947098/ch01.html
|Restrict number of objects returned by a query=supported
|QL Restrict URL=http://accumulo.apache.org/1.4/apidocs/org/apache/accumulo/core/client/Scanner.html
|Key matching options=exact
|Sorting of query results=ascending
|QL Sort URL=http://accumulo.apache.org/user_manual_1.3-incubating/Accumulo_Design.html#Data_Model
|Triggers=not supported
|Expire data values=supported
|QL Expiry URL=http://accumulo.apache.org/user_manual_1.3-incubating/Table_Configuration.html#Iterators
}}
Accumulo has a native java API and supports Thrift, enabling clients including Python and C# and Ruby to be generated.

Sqrrl Enterprise Sqrrl adds richer search and query capabilities, including full-text keyword search, document search (i.e., JSON document support), a SQL-like queries, and graph search. - See more at: http://sqrrl.com/product/accumulo/#sthash.O4LRpuo9.dpuf

Accumulo sorts keys by element and lexicographically in ascending order.

Values comprise the value part of the key-value pair. As such, they are not sorted. Values are byte arrays that can hold a wide variety of data. 

To configure the AgeOff filter to remove data older than a certain date or a fixed amount of time from the present.

Accumulo allows aggregating iterators to be configured on tables and column families. When an aggregating iterator is set, the iterator is applied across the values associated with any keys that share rowID, column family, and column qualifier. This is similar to the reduce step in MapReduce, which applied some function to all the values associated with a particular key.</text>
      <sha1>nquq1nwd3dhl5rdzyqeblieukat48et</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>FoundationDB Query Language Features</title>
    <ns>0</ns>
    <id>342</id>
    <revision>
      <id>2484</id>
      <parentid>2454</parentid>
      <timestamp>2015-03-26T14:47:04Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="1966">{{Query Languages
|SQLDatabase=FoundationDB
|API-based=supported
|QL API URL=https://foundationdb.com/key-value-store/documentation/developer-guide.html#working-with-the-apis
|Declarative=supported
|QL Declarative URL=https://foundationdb.com/layers/sql/documentation/index.html
|REST/HTTP-based=supported
|QL REST URL=https://foundationdb.com/layers/sql/documentation/REST/rest.api.reference.html
|Languages supported=Java, Python, C/C++, PHP, Ruby, Javascript
|QL Languages URL=https://foundationdb.com/key-value-store/documentation/api-reference.html
|Cursor-based queries=supported
|QL Cursors URL=http://foundationdb.github.io/sql-parser/com/foundationdb/sql/parser/CursorNode.html
|JOIN-style queries=supported
|QL Joins URL=https://foundationdb.com/layers/sql/documentation/Concepts/table.groups.html
|Complex data types=arrays
|QL Data Types URL=https://foundationdb.com/layers/sql/documentation/SQL/datatypes.html
|Restrict number of objects returned by a query=supported
|QL Restrict URL=https://foundationdb.com/layers/sql/documentation/SQL/dml/select.html
|Key matching options=exact, partial match, regular expressions
|QL Key Options URL=https://foundationdb.com/layers/sql/documentation/SQL/dml/select.html
|Sorting of query results=ascending, descending
|QL Sort URL=https://foundationdb.com/layers/sql/documentation/SQL/dml/select.html
|Triggers=not supported
|Expire data values=not suppported
}}
The SQL Layer is a fault-tolerant and scalable open source RDBMS, best suited for applications with high concurrency and short transactional workloads. The SQL Layer stores its data in the FoundationDB Key-Value Store, and translates SQL statements into efficient operations against it. 

FoundationDB supports client APIs for Python, Ruby, Node.js, Java, and C.

The REST API provides a document style interface to SQL Layer data.

Regular expressions are supported for key matching - https://foundationdb.com/layers/sql/documentation/SQL/functions.html</text>
      <sha1>nhdm8zfx6w4qpgb4n8ecmwrdaacufq4</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>VoltDB Query Language Features</title>
    <ns>0</ns>
    <id>366</id>
    <revision>
      <id>2483</id>
      <parentid>2448</parentid>
      <timestamp>2015-03-26T14:45:05Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="1865">{{Query Languages
|SQLDatabase=VoltDB
|API-based=not suppported
|Declarative=supported
|QL Declarative URL=http://docs.voltdb.com/UsingVoltDB/DesignProc.php
|REST/HTTP-based=supported
|QL REST URL=http://docs.voltdb.com/UsingVoltDB/ProgLangJson.php
|Languages supported=Java, C#, Python, C/C++, PHP, Ruby, Erlang, Javascript
|QL Languages URL=http://docs.voltdb.com/UsingVoltDB/ChapOtherClientAPI.php
|Cursor-based queries=not suppported
|JOIN-style queries=supported
|QL Joins URL=http://docs.voltdb.com/UsingVoltDB/sqlref_select.php
|Complex data types=arrays
|QL Data Types URL=http://docs.voltdb.com/UsingVoltDB/ddlref_createtable.php
|Restrict number of objects returned by a query=supported
|QL Restrict URL=http://docs.voltdb.com/UsingVoltDB/sqlref_select.php
|Key matching options=exact, partial match, wildcards
|QL Key Options URL=http://docs.voltdb.com/UsingVoltDB/sqlref_select.php
|Sorting of query results=ascending, descending
|QL Sort URL=http://docs.voltdb.com/UsingVoltDB/sqlref_select.php
|Triggers=not supported
|QL Triggers URL=https://forum.voltdb.com/showthread.php?1234-Triggers-and-Foreign-Key-constraints
|Expire data values=not suppported
}}
You can write VoltDB stored procedures as Java classes to access VoltDB. Within the stored procedure, you access the database using standard SQL syntax, with statements such as SELECT, UPDATE, INSERT, and DELETE. You can also include your own code within the stored procedure to perform calculations on the returned values, to evaluate and execute conditional statements, or to perform many other functions your applications may need.

The JSON interface lets you invoke VoltDB stored procedures and receive their results through HTTP requests. To invoke a stored procedure, you pass VoltDB the procedure name and parameters as a querystring to the HTTP request, using either the GET or POST method.</text>
      <sha1>brn3kkltqe58ufln4uta928b8w1dxot</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>OrientDB Query Language Features</title>
    <ns>0</ns>
    <id>544</id>
    <revision>
      <id>3322</id>
      <parentid>3320</parentid>
      <timestamp>2016-05-02T18:55:36Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="1511">{{Query Languages
|SQLDatabase=OrientDB
|API-based=supported
|QL API URL=http://orientdb.com/docs/last/Programming-Language-Bindings.html
|Declarative=supported
|QL Declarative URL=http://orientdb.com/docs/last/SQL.html
|REST/HTTP-based=supported
|QL REST URL=http://orientdb.com/docs/last/OrientDB-REST.html
|Languages supported=Java, Python, C/C++, Perl, PHP, Ruby, Scala, Javascript
|QL Languages URL=http://orientdb.com/docs/last/Programming-Language-Bindings.html
|Cursor-based queries=supported
|QL Cursors URL=http://stackoverflow.com/questions/24833638/what-is-the-best-way-to-perform-index-ranged-searches-in-orientdb-from-java
|JOIN-style queries=not suppported
|QL Joins URL=http://orientdb.com/docs/last/Tutorial-Relationships.html#relations-in-orientdb
|Complex data types=lists, maps, sets, nested structures
|QL Data Types URL=http://orientdb.com/docs/last/Types.html
|Restrict number of objects returned by a query=supported
|QL Restrict URL=http://orientdb.com/docs/last/Pagination.html
|Key matching options=exact, partial match, wildcards, regular expressions
|QL Key Options URL=http://orientdb.com/docs/last/SQL-Where.html#conditional-operators
|Sorting of query results=ascending, descending
|QL Sort URL=http://orientdb.com/docs/last/Tutorial-SQL.html#-order-by
|Triggers=pre-commit, post-commit
|QL Triggers URL=http://orientdb.com/docs/last/Hook.html
|Expire data values=not suppported
}}

OrientDB's &quot;none&quot; type is referred to as a type of &quot;any&quot; (http://orientdb.com/docs/last/Types.html)</text>
      <sha1>jos5ut0dba5ns5c1ivkumf3ufvgdjbu</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Couchbase Query Language Features</title>
    <ns>0</ns>
    <id>553</id>
    <revision>
      <id>3306</id>
      <parentid>3261</parentid>
      <timestamp>2016-04-25T18:50:23Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="2145">{{Query Languages
|SQLDatabase=Couchbase
|API-based=supported
|QL API URL=http://docs.couchbase.com/admin/admin/rest-intro.html
|Declarative=supported
|QL Declarative URL=http://developer.couchbase.com/documentation/server/4.0/getting-started/first-n1ql-query.html
|REST/HTTP-based=supported
|QL REST URL=http://docs.couchbase.com/admin/admin/rest-intro.html
|Languages supported=Java, C#, Python, C/C++, PHP, Ruby, Javascript
|QL Languages URL=https://en.wikipedia.org/wiki/Couchbase_Server
|Cursor-based queries=not suppported
|JOIN-style queries=supported
|QL Joins URL=http://www.couchbase.com/n1ql
|Complex data types=maps, nested structures, arrays
|QL Data Types URL=http://developer.couchbase.com/documentation/server/4.1/data-modeling/concepts-data-modeling-intro.html
|Restrict number of objects returned by a query=supported
|QL Restrict URL=http://developer.couchbase.com/documentation/mobile/1.2/develop/guides/couchbase-lite/native-api/query/index.html
|Key matching options=exact, partial match, regular expressions
|QL Key Options URL=http://developer.couchbase.com/documentation/server/4.0/n1ql/n1ql-language-reference/patternmatchingfun.html
|Sorting of query results=ascending, descending
|QL Sort URL=http://developer.couchbase.com/documentation/server/4.0/developer-guide/views-querying.html
|Triggers=not supported
|QL Triggers URL=https://forums.couchbase.com/t/triggers-in-couchabse/637
|Expire data values=supported
|QL Expiry URL=http://developer.couchbase.com/documentation/server/4.1/developer-guide/expiry.html
}}
Couchbase has officially supported SDKs for the following programming languages .Net, PHP, Ruby, Python, C, Node.js, Java, and Go.

Couches query workbench is a graphical version of the command line tool. It provides a better way to view and edit complex queries by supporting features such as multi-line formatting, copy and paste, and easy cursor movement.

Documents are stored in Couchbase Server in JSON format, a simple, lightweight notation that is compact and human readable. JSON supports both basic data types like numbers and strings, and complex types such as embedded dictionaries and arrays.</text>
      <sha1>pkrpzmb6epzqd3z0leuqsb74akmr0lj</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Redis Query Language Features</title>
    <ns>0</ns>
    <id>562</id>
    <revision>
      <id>3299</id>
      <parentid>3270</parentid>
      <timestamp>2016-04-20T21:58:10Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="2407">{{Query Languages
|SQLDatabase=Redis
|API-based=supported
|QL API URL=http://redis.io/commands
|Declarative=not suppported
|QL Declarative URL=http://redis.io/commands
|REST/HTTP-based=not suppported
|QL REST URL=http://webd.is/
|Languages supported=Java, C#, Python, C/C++, Perl, PHP, Ruby, Scala, Erlang, Javascript
|QL Languages URL=http://redis.io/clients
|Cursor-based queries=supported
|QL Cursors URL=http://redis.io/commands/scan
|JOIN-style queries=not suppported
|QL Joins URL=http://redis.io/commands/ZUNIONSTORE
|Complex data types=lists, maps, sets
|QL Data Types URL=http://redis.io/topics/data-types
|Restrict number of objects returned by a query=supported
|QL Restrict URL=http://redis.io/commands/scan
|Key matching options=exact, partial match, wildcards
|QL Key Options URL=http://redis.io/commands/KEYS
|Sorting of query results=ascending, descending
|QL Sort URL=http://redis.io/commands/SORT
|Triggers=not supported
|Expire data values=supported
|QL Expiry URL=http://redis.io/commands/expire
}}
With Redis expires you can set a timeout for a key, which is a limited time to live. When the time to live elapses, the key is automatically destroyed, exactly as if the user called the DEL command with the key. They can be set both using seconds or milliseconds precision. However the expire time resolution is always 1 millisecond. Information about expires are replicated and persisted on disk, the time virtually passes when your Redis server remains stopped (this means that Redis saves the date at which a key will expire).

Keyspace notifications allows clients to subscribe to Pub/Sub channels in order to receive events affecting the Redis data set in some way. Because Redis Pub/Sub is fire and forget currently there is no way to use this feature if you application demands reliable notification of events, that is, if your Pub/Sub client disconnects, and reconnects later, all the events delivered during the time the client was disconnected are lost.

Warning: consider KEYS as a command that should only be used in production environments with extreme care. It may ruin performance when it is executed against large databases. This command is intended for debugging and special operations, such as changing your keyspace layout. Don't use KEYS in your regular application code. If you're looking for a way to find keys in a subset of your keyspace, consider using SCAN or sets.</text>
      <sha1>t7ovxr1t2zju34f1hpvmwkyg9dcen7d</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Amazon DynamoDB Query Language Features</title>
    <ns>0</ns>
    <id>571</id>
    <revision>
      <id>3313</id>
      <parentid>3156</parentid>
      <timestamp>2016-04-27T21:35:02Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="3507">{{Query Languages
|SQLDatabase=Amazon DynamoDB
|API-based=supported
|QL API URL=http://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_Welcome.html
|Declarative=not suppported
|QL Declarative URL=https://books.google.com/books?id=UAzNCwAAQBAJ&amp;pg=PA293&amp;lpg=PA293&amp;dq=declarative+query+language+dynamodb&amp;source=bl&amp;ots=hAEQjSGfpR&amp;sig=iKQanjC2FfXKgDqjJRGIyfYJtHo&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwjUnuvptoLMAhVS62MKHTmWC3MQ6AEIHTAA#v=onepage&amp;q=declarative%20query%20language%20dynamodb&amp;f=false
|REST/HTTP-based=supported
|QL REST URL=http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/MakingHTTPRequests.html
|Languages supported=Java, C#, Python, Perl, PHP, Ruby, Erlang, Javascript
|QL Languages URL=https://en.wikipedia.org/wiki/Amazon_DynamoDB
|Cursor-based queries=supported
|QL Cursors URL=http://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_Scan.html
|JOIN-style queries=not suppported
|QL Joins URL=https://aws.amazon.com/dynamodb/faqs/#Getting_Started
|Complex data types=lists, maps, sets, nested structures, arrays
|QL Data Types URL=http://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_AttributeValue.html
|Restrict number of objects returned by a query=supported
|QL Restrict URL=http://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_Scan.html
|Key matching options=exact, partial match
|QL Key Options URL=http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/QueryAndScan.html#FilteringResults
|Sorting of query results=none
|QL Sort URL=http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/WorkingWithTables.html#WorkingWithTables.primary.key
|Triggers=not supported
|QL Triggers URL=http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Streams.Lambda.html
|Expire data values=not suppported
|QL Expiry URL=https://forums.aws.amazon.com/thread.jspa?messageID=332629
}}
Cursor-based queries/ Restrict number of objects returned by a query:
To have DynamoDB return fewer items, you can provide a ScanFilter operation.
http://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_Scan.html

JOIN-style queries:
Amazon DynamoDB tackles the core problems of database scalability, management, performance, and reliability, it does not have all the functionality of a relational database. It does not support complex relational queries (e.g. joins) or complex transactions.
Explained under FAQ- When should I use Amazon DynamoDB vs a relational database engine on Amazon RDS or Amazon EC2?

Key matching options:
DynamoDB provides a way to query by checking if a string or binary start with some substring, and provided the &quot;CONTAINS&quot; and &quot;NOT_CONTAINS&quot; filter when you do &quot;scan&quot;. But it does not support regular expressions.
http://www.masonzhang.com/2013/08/7-reasons-you-should-use-mongodb-over.html

Sorting of query results is only possible for the sort key:
DynamoDB supports two different kinds of primary keys: 
1) Partition Key 
2) Partition Key and Sort Key - All items with the same partition key are stored together, in sorted order by sort key value.

Triggers:
Amazon DynamoDB is integrated with AWS Lambda, so that you can create triggers—pieces of code that quickly and automatically respond to events in DynamoDB Streams. With triggers, you can build applications that react to data modifications in DynamoDB tables.

Expire data values:
There is no direct mechanism to expire data values but it can be achieved by a) Scan the DB, b) fetch the results that match my criteria and c) delete the items.</text>
      <sha1>bg6a1sax536yzcz76ekbto2pnbr6xdq</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Riak Data Distribution Features</title>
    <ns>0</ns>
    <id>187</id>
    <revision>
      <id>2434</id>
      <parentid>2433</parentid>
      <timestamp>2015-02-05T14:46:36Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="2227">{{Data Distribution
|SQLDatabase=Riak
|Data Distribution Architecture=peer-to-peer
|Dist Architecture URL=http://docs.basho.com/riak/latest/theory/comparisons/cassandra/
|Data Distribution Method=consistent hashing
|Dist Distribution URL=http://basho.com/tag/consistent-hashing/
|Automatic Data Rebalancing=new storage triggered, administrative rebalancing tools
|Dist Rebalance URL=http://basho.com/tag/consistent-hashing/
|Physical Data Distribution=single cluster, multiple data centers
|Dist Physical URL=http://docs.basho.com/riakee/latest/cookbooks/Multi-Data-Center-Replication-Architecture/
|Query Architecture=external load balancer required
|Dist Query URL=http://docs.basho.com/riak/latest/ops/advanced/configs/load-balancing-proxy/
|Queries using Non-Shard Key Value=secondary indexes
|Dist NKQuery URL=http://docs.basho.com/riak/latest/dev/using/2i/
|Merging Query Results from Multiple Shards=sorted order, paged from server
|Dist Merge URL=http://docs.basho.com/riak/latest/dev/using/2i/
}}
Riak adopts a fully distributed, peer-to-peer architecture in which any shard can act as a query coordinator.

Riak evenly distributes data across a cluster using consistent hashing. In a Riak cluster, the data space is divided into partitions which are claimed by the servers. When new data is written to the database, these objects are evenly placed around the ring and replicated 3 times (by default). This ensures that your data will always be available, even when nodes fail.

When Multi-Datacenter Replication is implemented, one Riak cluster acts as a primary cluster. The primary cluster handles replication requests from one or more secondary clusters (generally located in datacenters in other regions or countries). If the datacenter with the primary cluster goes down, a secondary cluster can take over as the primary cluster. In this sense, Riak's multi-datacenter capabilities are indeed masterless. Datacenter replication is only available in the enterprise edition.

The ring size, in Riak parlance, is the number of data partitions that comprise the cluster. This quantity impacts the scalability and performance of a cluster and, importantly, it should established before the cluster starts receiving data.</text>
      <sha1>go7glsjj8kjyeya4iqeyaow01yymqpv</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Cassandra Data Distribution Features</title>
    <ns>0</ns>
    <id>253</id>
    <revision>
      <id>2340</id>
      <parentid>2338</parentid>
      <timestamp>2015-01-23T18:29:34Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="2279">{{Data Distribution
|SQLDatabase=Cassandra
|Data Distribution Architecture=peer-to-peer
|Dist Architecture URL=http://www.datastax.com/resources/datasheets/cassandra
|Data Distribution Method=consistent hashing
|Dist Distribution URL=http://www.datastax.com/documentation/cassandra/2.0/cassandra/architecture/architectureDataDistributeHashing_c.html
|Automatic Data Rebalancing=administrative rebalancing tools
|Dist Rebalance URL=http://www.datastax.com/documentation/opscenter/5.0/opsc/online_help/opscRebalancingCluster_t.html
|Physical Data Distribution=single cluster, rack-aware on single cluster, multiple data centers
|Dist Physical URL=http://www.datastax.com/documentation/cassandra/2.0/cassandra/architecture/architectureDataDistributeReplication_c.html
|Query Architecture=distributed coordinator for shard key lookup
|Dist Query URL=http://www.datastax.com/documentation/cassandra/2.1/cassandra/architecture/architectureIntro_c.html
|Queries using Non-Shard Key Value=secondary indexes
|Dist NKQuery URL=http://www.datastax.com/documentation/cql/3.1/cql/ddl/ddl_when_use_index_c.html
|Merging Query Results from Multiple Shards=random order, paged from server
|Dist Merge URL=http://www.datastax.com/documentation/cql/3.1/cql/cql_using/paging_c.html
}}
Cassandra’s “cluster ring”, peer-to-peer architecture, which can include hundreds to thousands of identical nodes, protects from data loss and business disruption because there is no single point of failure. The core of Cassandra’s peer to peer architecture is built on the idea of consistent hashing.

When using the RandomPartitioner or Murmur3Partitioner, Cassandra rows are ordered by the hash of their value and hence the order of rows is not meaningful. Using CQL, you can page through rows even when using the random partitioner or the murmur3 partitioner using the token function.

Client read or write requests can be sent to any node in the cluster. When a client connects to a node with a request, that node serves as the coordinator for that particular client operation. The coordinator acts as a proxy between the client application and the nodes that own the data being requested. The coordinator determines which nodes in the ring should get the request based on how the cluster is configured.</text>
      <sha1>2trk5ghbula4224ju1u80s16gu6ame7</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>CouchDB Data Distribution Features</title>
    <ns>0</ns>
    <id>264</id>
    <revision>
      <id>2460</id>
      <parentid>1992</parentid>
      <timestamp>2015-02-09T21:58:35Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="1414">{{Data Distribution
|SQLDatabase=CouchDB
|Data Distribution Architecture=single database only, master-single slave, master-multiple slaves, peer-to-peer
|Dist Architecture URL=http://docs.basho.com/riak/1.2.0/references/appendices/comparisons/Riak-Compared-to-CouchDB/
|Data Distribution Method=assigned key ranges to nodes
|Dist Distribution URL=http://wiki.apache.org/couchdb/Replication#Filtered_Replication
|Automatic Data Rebalancing=administrative rebalancing tools
|Dist Rebalance URL=http://wiki.apache.org/couchdb/Replication#Filtered_Replication
|Physical Data Distribution=single cluster, multiple data centers
|Query Architecture=direct shard connection only (resolved in client)
|Queries using Non-Shard Key Value=not supported
|Merging Query Results from Multiple Shards=sorted order, not supported
}}
A client connects directly a database which it knows contains the data values it requires. 

Rebalancing is achieved through manually configuring replication and using replication filters.

CouchDB Lounge is an additional package that can build a cluster using consistent hashing. http://guide.couchdb.org/draft/clustering.html. Queries results from consistently hashed nodes can be merged using the Twisted Python Smartproxy. There is work underway to move the behavior to Erlang, which ought to make managing dynamic clusters possible as well as integrating cluster control into the CouchDB runtime.</text>
      <sha1>5xtdgw3rvn85tzsxczipls9b372qzwl</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>MongoDB Data Distribution Features</title>
    <ns>0</ns>
    <id>318</id>
    <revision>
      <id>2425</id>
      <parentid>2424</parentid>
      <timestamp>2015-02-03T19:28:36Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="2650">{{Data Distribution
|SQLDatabase=MongoDB
|Data Distribution Architecture=master-single slave, master-multiple slaves
|Dist Architecture URL=http://docs.mongodb.org/manual/core/replication-introduction/
|Data Distribution Method=assigned key ranges to nodes, hash key
|Dist Distribution URL=http://docs.mongodb.org/manual/core/sharding-introduction/
|Automatic Data Rebalancing=new storage triggered, administrative rebalancing tools, data growth triggered
|Dist Rebalance URL=http://docs.mongodb.org/manual/core/sharding-balancing/
|Physical Data Distribution=single cluster, multiple data centers
|Dist Physical URL=http://docs.mongodb.org/manual/data-center-awareness/
|Query Architecture=distributed coordinator for shard key lookup
|Dist Query URL=http://docs.mongodb.org/manual/core/sharding-introduction/
|Queries using Non-Shard Key Value=non-indexed (scan)
|Dist NKQuery URL=http://docs.mongodb.org/manual/core/sharded-cluster-query-router/
|Merging Query Results from Multiple Shards=sorted order, paged from server
|Dist Merge URL=http://docs.mongodb.org/manual/core/sharded-cluster-query-router/
}}
While there is no explicit support for data center aware data distribution, there are features that can be used to approximate this, such as tag aware sharding and operational segmentation - see http://docs.mongodb.org/manual/data-center-awareness/

The addshard command will add capacity to a cluster and automatically move chunks of data from heavily utilized nodes to the newly added node.

The balancer process is responsible for redistributing the chunks of a sharded collection evenly among the shards for every sharded collection. By default, the balancer process is always enabled. When you add a shard to a sharded cluster, you affect the balance of chunks among the shards of a cluster for all existing sharded collections. The balancer will begin migrating chunks so that the cluster will achieve balance. 

While replica sets provide basic protection against single-instance failure, replica sets whose members are all located in a single facility are susceptible to errors in that facility. Power outages, network interruptions, and natural disasters are all issues that can affect replica sets whose members are colocated. To protect against these classes of failures, deploy a replica set with one or more members in a geographically distinct facility or data center to provide redundancy - http://docs.mongodb.org/manual/tutorial/deploy-geographically-distributed-replica-set/

mongos instances broadcast queries to all shards for the collection unless the mongos can determine which shard or subset of shards stores this data.</text>
      <sha1>2x88vbsgqok16abznlx2a1kfg9w8g6o</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Neo4j Data Distribution Features</title>
    <ns>0</ns>
    <id>320</id>
    <revision>
      <id>2390</id>
      <parentid>2352</parentid>
      <timestamp>2015-01-28T15:28:52Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="1126">{{Data Distribution
|SQLDatabase=Neo4j
|Data Distribution Architecture=single database only, master-single slave, master-multiple slaves
|Dist Architecture URL=http://neo4j.com/docs/stable/ha-architecture.html
|Data Distribution Method=Not relevant (single server only)
|Dist Distribution URL=http://neo4j.com/docs/stable/ha-architecture.html
|Automatic Data Rebalancing=no rebalancing (single server only)
|Dist Rebalance URL=http://neo4j.com/docs/stable/ha-architecture.html
|Physical Data Distribution=single cluster
|Dist Physical URL=http://neo4j.com/docs/stable/ha-architecture.html
|Query Architecture=external load balancer required
|Dist Query URL=https://groups.google.com/forum/#!topic/neo4j/Y0u69wMuiaE
|Queries using Non-Shard Key Value=secondary indexes, non-indexed (scan)
|Dist NKQuery URL=http://neo4j.com/docs/stable/query-schema-index.html
|Merging Query Results from Multiple Shards=not supported
}}
Neo4j stores all data on a single node, and hence sharding for data partitioning is not supported. 

Replication makes it possible to replica a complete master database in its entirity to multiple slave nodes.</text>
      <sha1>gl18waubxhk75t6d8swrn1vt3jd3cng</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>HBase Data Distribution Features</title>
    <ns>0</ns>
    <id>328</id>
    <revision>
      <id>2417</id>
      <parentid>2416</parentid>
      <timestamp>2015-02-03T16:26:18Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="1622">{{Data Distribution
|SQLDatabase=HBase
|Data Distribution Architecture=master-single slave
|Dist Architecture URL=http://netwovenblogs.com/2013/10/10/hbase-overview-of-architecture-and-data-model/
|Data Distribution Method=assigned key ranges to nodes
|Dist Distribution URL=http://hbase.apache.org/book.html#_architecture
|Automatic Data Rebalancing=new storage triggered, data growth triggered
|Dist Rebalance URL=http://hbase.apache.org/book.html#_architecture
|Physical Data Distribution=single cluster, rack-aware on single cluster
|Query Architecture=direct shard connection only (resolved in client)
|Dist Query URL=http://netwovenblogs.com/2013/10/10/hbase-overview-of-architecture-and-data-model/
|Queries using Non-Shard Key Value=non-indexed (scan)
|Dist NKQuery URL=http://www.cloudera.com/content/cloudera/en/documentation/core/v5-2-x/topics/admin_hbase_scanning.html
|Merging Query Results from Multiple Shards=sorted order
}}
Automatic sharding: HBase tables are distributed on the cluster via regions, and regions are automatically split and re-distributed as your data grows. Periodically, and when there are no regions in transition, a load balancer will run and move regions around to balance the cluster’s load. See balancer config for configuring this property.

The mapping of Regions to Region Server is kept in a system table called .META. When trying to read or write data from HBase, the clients read the required Region information from the .META table and directly communicate with the appropriate Region Server. Each Region is identified by the start key (inclusive) and the end key (exclusive)</text>
      <sha1>bsz795xsdsy1nwnzlxz7nm1kh3b82ww</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Accumulo Data Distribution Features</title>
    <ns>0</ns>
    <id>336</id>
    <revision>
      <id>2406</id>
      <parentid>2405</parentid>
      <timestamp>2015-01-29T17:05:13Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="2224">{{Data Distribution
|SQLDatabase=Accumulo
|Data Distribution Architecture=master-single slave, master-multiple slaves
|Dist Architecture URL=http://people.apache.org/~elserj/accumulo_user_manual.html#_replication
|Data Distribution Method=assigned key ranges to nodes
|Dist Distribution URL=http://accumulo.apache.org/1.6/accumulo_user_manual.html#_splitting
|Automatic Data Rebalancing=new storage triggered
|Dist Rebalance URL=http://accumulo.apache.org/1.6/accumulo_user_manual.html#_splitting
|Physical Data Distribution=single cluster, rack-aware on single cluster
|Dist Physical URL=http://www.accumulodata.com/ec2.html
|Query Architecture=direct shard connection only (resolved in client)
|Dist Query URL=https://www.safaribooksonline.com/library/view/accumulo/9781491947098/ch04.html
|Queries using Non-Shard Key Value=not supported
|Merging Query Results from Multiple Shards=random order
|Dist Merge URL=http://accumulo.apache.org/1.6/accumulo_user_manual.html#_batchscanner
}}
When a table is created it has one tablet. As the table grows its initial tablet eventually splits into two tablets. Its likely that one of these tablets will migrate to another tablet server. As the table continues to grow, its tablets will continue to split and be migrated. The decision to automatically split a tablet is based on the size of a tablets files. The size threshold at which a tablet splits is configurable per table. In addition to automatic splitting, a user can manually add split points to a table to create new tablets. Manually splitting a new table can parallelize reads and writes giving better initial performance without waiting for automatic splitting.

It is important to note that the keys returned by a BatchScanner are not in sorted order since the keys streamed are from multiple TabletServers in parallel.

When the client obtains a connection to Accumulo, it reads the available tablet servers from Zookeeper and connects to a tablet server to authenticate. The Connector can then be used to retrieve various types of scanner or writer objects for reading from or writing to Accumulo. It can also be used to retrieve objects that can perform table operations, instance operations, and security operations.</text>
      <sha1>0s49wbzrk1zz51r74udglbmwu3xo0g1</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>FoundationDB Data Distribution Features</title>
    <ns>0</ns>
    <id>343</id>
    <revision>
      <id>2455</id>
      <parentid>2073</parentid>
      <timestamp>2015-02-09T19:14:22Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="1926">{{Data Distribution
|SQLDatabase=FoundationDB
|Data Distribution Architecture=peer-to-peer
|Dist Architecture URL=https://foundationdb.com/key-value-store/versus
|Data Distribution Method=assigned key ranges to nodes
|Dist Distribution URL=https://foundationdb.com/key-value-store/versus
|Automatic Data Rebalancing=new storage triggered, administrative rebalancing tools
|Dist Rebalance URL=https://foundationdb.com/key-value-store/documentation/administration.html#adding-machines-to-a-cluster
|Physical Data Distribution=single cluster, rack-aware on single cluster, multiple data centers
|Dist Physical URL=https://foundationdb.com/key-value-store/documentation/3.0/configuration.html#datacenter-aware-mode
|Query Architecture=direct shard connection only (resolved in client)
|Dist Query URL=https://foundationdb.com/layers/sql/documentation/Concepts/architecture.html
|Queries using Non-Shard Key Value=secondary indexes, non-indexed (scan)
|Dist NKQuery URL=https://foundationdb.com/layers/sql/documentation/SQL/dml/select.html
|Merging Query Results from Multiple Shards=sorted order
|Dist Merge URL=https://foundationdb.com/layers/sql/documentation/SQL/dml/select.html
}}
FoundationDB attempts to replicate data across two datacenters and will stay up with only two available. Data is triple replicated. For maximum availability, you should use five coordination servers: two in two of the datacenters and one in the third datacenter.Multiple-datacenter support in currently is immature.

Rack aware data distribution - https://foundationdb.com/key-value-store/white-papers/fault-tolerance.

The FoundationDB Key-Value client manages all load balancing between the client and the Key-Value cluster. 

FoundationDB has undergone performance testing and tuning with clusters of up to 500 cores/processes. Significantly larger clusters may experience performance bottlenecks leading to sub-linear scaling or related issues.</text>
      <sha1>hf9cb7ajo8npcqbs6r16py4r0k6r9kk</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>VoltDB Data Distribution Features</title>
    <ns>0</ns>
    <id>367</id>
    <revision>
      <id>2489</id>
      <parentid>2488</parentid>
      <timestamp>2015-04-02T19:47:44Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="1522">{{Data Distribution
|SQLDatabase=VoltDB
|Data Distribution Architecture=peer-to-peer
|Dist Architecture URL=http://en.wikipedia.org/wiki/VoltDB
|Data Distribution Method=hash key
|Dist Distribution URL=http://voltdb.com/blog/understanding-voltdb-data-partitioning
|Automatic Data Rebalancing=new storage triggered, administrative rebalancing tools
|Dist Rebalance URL=http://docs.voltdb.com/UsingVoltDB/UpdateHw.php
|Physical Data Distribution=single cluster, multiple data centers
|Dist Physical URL=http://docs.voltdb.com/UsingVoltDB/ChapReplication.php
|Query Architecture=distributed coordinator for shard key lookup
|Dist Query URL=http://docs.voltdb.com/UsingVoltDB/ChapAppDesign.php#DesignAppConnect
|Queries using Non-Shard Key Value=secondary indexes, non-indexed (scan)
|Merging Query Results from Multiple Shards=sorted order
}}
VoltDB is an in-memory database. It is an ACID-compliant RDBMS which uses a shared nothing architecture. It includes both enterprise and community editions. 

SQLDatabase replication involves duplicating the contents of one database cluster (known as the master) to another database cluster (known as the replica). The contents of the replica cluster are completely controlled by the master, which is why this arrangement is sometimes referred to as a master/slave relationship.. SQLDatabase replication can be used for:
-Offloading read-only workloads, such as reporting
-Maintaining a &quot;hot standby&quot; in case of failure
-Protecting against catastrophic events, often called disaster recovery</text>
      <sha1>jzis84lrrtmt56kgkgmxwg16wap5vxu</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>OrientDB Data Distribution Features</title>
    <ns>0</ns>
    <id>545</id>
    <revision>
      <id>3323</id>
      <parentid>3251</parentid>
      <timestamp>2016-05-02T21:02:18Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="1704">{{Data Distribution
|SQLDatabase=OrientDB
|Data Distribution Architecture=peer-to-peer
|Dist Architecture URL=http://orientdb.com/docs/last/Replication.html#replication
|Data Distribution Method=assigned key ranges to nodes
|Dist Distribution URL=http://orientdb.com/docs/last/Replication.html#replication
|Automatic Data Rebalancing=administrative rebalancing tools
|Dist Rebalance URL=http://orientdb.com/docs/last/Distributed-Sharding.html#cluster-locality
|Physical Data Distribution=multiple data centers
|Dist Physical URL=http://orientdb.com/docs/last/Distributed-Sharding.html#multiple-servers-per-cluster
|Query Architecture=distributed coordinator for shard key lookup
|Dist Query URL=http://orientdb.com/docs/last/Distributed-Sharding.html#read-records
|Queries using Non-Shard Key Value=secondary indexes
|Dist NKQuery URL=http://orientdb.com/docs/last/Distributed-Sharding.html#configuration
|Merging Query Results from Multiple Shards=sorted order
|Dist Merge URL=http://orientdb.com/docs/2.0/orientdb.wiki/Distributed-Configuration.html#default-distributed-db-configjson
}}

Auto-Sharding is not supported in the common meaning of Distributed Hash SQLTable (DHT). Selecting the right shard (cluster) is up to the application. This will be addressed by next releases. Sharded Indexes are not supported.

If you want to change permanently the mastership of clusters, rename the cluster with the suffix of the node you want assign as master. Hot change of distributed configuration not available.

If the local node has the requested record, the record is read directly from the storage. If it's not present on local server, a forward is executed to any of the nodes that have the requested record.</text>
      <sha1>p8gjzi13kmw8wev91ox8jn9iyiwsh8y</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Couchbase Data Distribution Features</title>
    <ns>0</ns>
    <id>554</id>
    <revision>
      <id>3307</id>
      <parentid>3292</parentid>
      <timestamp>2016-04-25T19:20:00Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="2138">{{Data Distribution
|SQLDatabase=Couchbase
|Data Distribution Architecture=master-single slave, master-multiple slaves
|Dist Architecture URL=http://developer.couchbase.com/documentation/server/4.0/architecture/high-availability-replication-architecture.html
|Data Distribution Method=hash key
|Dist Distribution URL=http://docs.couchbase.com/admin/admin/Concepts/concept-vBucket.html
|Automatic Data Rebalancing=new storage triggered, administrative rebalancing tools
|Dist Rebalance URL=http://developer.couchbase.com/documentation/server/4.1/clustersetup/rebalance.html
|Physical Data Distribution=multiple data centers
|Dist Physical URL=http://docs.couchbase.com/admin/admin/XDCR/xdcr-intro.html
|Query Architecture=direct shard connection only (resolved in client)
|Dist Query URL=http://developer.couchbase.com/documentation/server/4.1/architecture/core-data-access-vbuckets-bucket-partition.html
|Queries using Non-Shard Key Value=secondary indexes
|Dist NKQuery URL=http://developer.couchbase.com/documentation/server/4.0/architecture/global-secondary-indexes.html
|Merging Query Results from Multiple Shards=random order
|Dist Merge URL=http://developer.couchbase.com/documentation/server/4.0/sdks/java-2.2/documents-retrieving.html
}}
A master or replica node serves as the network storage component of a cluster. For a given partition, only one node can be master in the cluster. If that node fails or becomes unresponsive, the cluster selects a replica node to become the new master.

It's important to actually NOT put a load balancer between the application servers and Couchbase. Because of the key-hash partitioning, data is already automatically distributed across the Couchbase cluster. The app servers will connect and interact with the Couchbase cluster nodes directly and because of the partitioning be already &quot;load balanced&quot; in the sense that they will be doing CRUD operations across the cluster based on the hashing of the keys. The app servers and sdk clients will maintain open connections to each node in the Couchbase cluster, and generally, a single shared connection is all that is needed for each app server.</text>
      <sha1>ek19vq25tj0n2vogin33nojm6jylt65</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Redis Data Distribution Features</title>
    <ns>0</ns>
    <id>563</id>
    <revision>
      <id>3301</id>
      <parentid>3300</parentid>
      <timestamp>2016-04-22T19:54:05Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="2600">{{Data Distribution
|SQLDatabase=Redis
|Data Distribution Architecture=master-single slave, master-multiple slaves
|Dist Architecture URL=http://redis.io/topics/replication
|Data Distribution Method=hash key
|Dist Distribution URL=http://redis.io/topics/cluster-tutorial
|Automatic Data Rebalancing=administrative rebalancing tools
|Dist Rebalance URL=http://redis.io/topics/cluster-tutorial#redis-cluster-data-sharding
|Physical Data Distribution=single cluster, multiple data centers
|Dist Physical URL=http://redis.io/topics/cluster-tutorial
|Query Architecture=direct shard connection only (resolved in client)
|Dist Query URL=http://redis.io/topics/cluster-spec#moved-redirection
|Queries using Non-Shard Key Value=not supported
|Dist NKQuery URL=http://redis.io/topics/partitioning
|Merging Query Results from Multiple Shards=not supported
|Dist Merge URL=http://redis.io/topics/partitioning
}}
Redis replication is a very simple to use and configure master-slave replication that allows slave Redis servers to be exact copies of master servers.  Redis uses asynchronous replication. A master can have multiple slaves. Slaves are able to accept connections from other slaves. 

Redis Cluster provides a way to run a Redis installation where data is automatically sharded across multiple Redis nodes. Redis Cluster also provides some degree of availability during partitions, that is in practical terms the ability to continue the operations when some nodes fail or are not able to communicate.

Redis Cluster is a distributed implementation of Redis with the following goals, in order of importance in the design: High performance and linear scalability up to 1000 nodes. Acceptable degree of write safety: the system tries (in a best-effort way) to retain all the writes originating from clients connected with the majority of the master nodes. 

Redis Cluster implements an hybrid form of query routing, with the help of the client (the request is not directly forwarded from a Redis instance to another, but the client gets redirected to the right node).

A Redis client is free to send queries to every node in the cluster, including slave nodes. The node will analyze the query, and if it is acceptable (that is, only a single key is mentioned in the query, or the multiple keys mentioned are all to the same hash slot) it will lookup what node is responsible for the hash slot where the key or keys belong. If the hash slot is served by the node, the query is simply processed, otherwise the node will check its internal hash slot to node map, and will reply to the client with a MOVED error</text>
      <sha1>gebltr987ccv14pal4mj1q9b7vx3iet</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Amazon DynamoDB Data Distribution Features</title>
    <ns>0</ns>
    <id>572</id>
    <revision>
      <id>3314</id>
      <parentid>3174</parentid>
      <timestamp>2016-04-28T21:33:43Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="2992">{{Data Distribution
|SQLDatabase=Amazon DynamoDB
|Data Distribution Architecture=peer-to-peer
|Dist Architecture URL=http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.Partitions.html
|Data Distribution Method=consistent hashing
|Dist Distribution URL=http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf
|Automatic Data Rebalancing=data growth triggered
|Dist Rebalance URL=http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf
|Physical Data Distribution=multiple data centers
|Dist Physical URL=http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.Partitions.html
|Query Architecture=distributed coordinator for shard key lookup
|Dist Query URL=http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf
|Queries using Non-Shard Key Value=secondary indexes, non-indexed (scan)
|Dist NKQuery URL=http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GSI.html
|Merging Query Results from Multiple Shards=sorted order
|Dist Merge URL=http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/QueryAndScan.html
}}

Data Distribution Method:
Dynamo’s partitioning scheme relies on consistent hashing to distribute the load across multiple storage hosts.
Explained under section 4.2 Partitioning Algorithm - 209

Automatic Data Distribution:
Dynamo uses consistent hashing to partition its key space across its replicas and to ensure uniform load distribution. A uniform key distribution can help us achieve uniform load distribution assuming the access distribution of keys is not highly skewed. In particular, Dynamo’s design assumes that even where there is a significant skew in the access distribution there are enough keys in the popular end of the distribution so that the load of handling popular keys can be spread across the nodes uniformly through partitioning.

Physical Data Distribution:
DynamoDB stores data in partitions. A partition is an allocation of storage for a table, backed by solid-state drives (SSDs) and automatically replicated across multiple Availability Zones within an AWS Region.

Query Architecture(Distributed):
Section 4.3 2nd Para: The list of nodes that is responsible for storing a particular key is called the preference list. The system is designed, so that every node in the system can determine which nodes should be in this list for any particular key. 

Queries using Non-Shard Key Value:
Querying a non-shard key attribute is time consuming and inefficient. To support these requirements, you can create one or more global secondary indexes and issue Query requests against these indexes. 

Merging Query Results from Multiple Shards:
Query results are always sorted by the sort key value. If the data type of the sort key is Number, the results are returned in numeric order; otherwise, the results are returned in order of UTF-8 bytes. By default, the sort order is ascending. To reverse the order, set the ScanIndexForward parameter to false.</text>
      <sha1>clttw5oefclctlbjepx8lp271wkrkhy</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Riak Data Replication Features</title>
    <ns>0</ns>
    <id>203</id>
    <revision>
      <id>2236</id>
      <parentid>2036</parentid>
      <timestamp>2014-12-30T22:10:59Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="2750">{{Data Replication
|SQLDatabase=Riak
|Replication Architecture=peer-to-peer
|Repl Arch URL=http://docs.basho.com/riak/latest/theory/why-riak/
|Replication for Backup=not suppported
|Replication across Data Centers=supported in enterprise version only (data center aware)
|Repl Data Centers URL=http://docs.basho.com/riak/latest/ops/mdc/v2/architecture/
|Replicas Writes=to any replica, to multiple replicas
|Repl Writes URL=http://docs.basho.com/riak/latest/theory/concepts/Eventual-Consistency/
|Replica Reads=from any replica, from multiple replicas
|Repl Reads URL=http://docs.basho.com/riak/latest/theory/concepts/Eventual-Consistency/
|Read Repair=per query
|Read Repair URL=http://docs.basho.com/riak/latest/theory/concepts/Replication/#Read-Repair
|Automatic Replica Failure Detection=supported
|Repl Fail Detect URL=http://docs.basho.com/riak/latest/ops/running/recovery/failure-recovery/#Data-Loss
|Automatic Failover=supported
|Failover URL=http://docs.basho.com/riak/latest/ops/running/recovery/failure-recovery/#Data-Loss
|Automatic New Master Election after Failure=not relevant
|Replica Recovery and Resynchronization=supported- automatic
|Repl Recovery URL=http://docs.basho.com/riak/latest/theory/concepts/glossary/#Hinted-Handoff
}}
Riak uses consistent hashing to replicate data objects across multiple replica nodes (3 by default).

When Multi-Datacenter Replication is implemented, one Riak cluster acts as a primary cluster. The primary cluster handles replication requests from one or more secondary clusters (generally located in datacenters in other regions or countries). If the datacenter with the primary cluster goes down, a secondary cluster can take over as the primary cluster. In this sense, Riak's multi-datacenter capabilities are masterless.

It is important to understand the difference between an error and a failure when writing. A PW=3 write request with only two available primary nodes will result in an error, but the value will still be written to the two surviving primary nodes. By specifying PW=3 the client indicated that 3 primary nodes must respond for the operation to be considered successful, which it wasn't, but there's no way to tell without performing another read whether the operation truly failed.

Once the node is detected as down, other nodes in the cluster will take over its responsibilities temporarily and transmit the updated data to it when it eventually returns to service (also called hinted handoff). Hinted handoff is a technique for dealing with node failure in the Riak cluster in which neighboring nodes temporarily take over storage operations for the failed node. When the failed node returns to the cluster, the updates received by the neighboring nodes are handed off to it.</text>
      <sha1>att3cfn16zrx0k2kzbsgmfr8xb9ij5y</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>MongoDB Data Replication Features</title>
    <ns>0</ns>
    <id>230</id>
    <revision>
      <id>2426</id>
      <parentid>2159</parentid>
      <timestamp>2015-02-03T19:28:51Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="2804">{{Data Replication
|SQLDatabase=MongoDB
|Replication Architecture=master-slave
|Repl Arch URL=http://docs.mongodb.org/manual/core/replication-introduction/
|Replication for Backup=supported
|Repl Backup URL=http://docs.mongodb.org/manual/core/replica-set-hidden-member/
|Replication across Data Centers=supported only by standard replication mechanisms
|Repl Data Centers URL=http://docs.mongodb.org/manual/data-center-awareness/
|Replicas Writes=to master replica only, to multiple replicas, to specified replica (configurable)
|Repl Writes URL=http://docs.mongodb.org/manual/reference/write-concern/
|Replica Reads=from master replica only, from any replica, from specified replica (configurable)
|Repl Reads URL=http://docs.mongodb.org/manual/core/read-preference/
|Read Repair=not relevant
|Automatic Replica Failure Detection=supported
|Repl Fail Detect URL=http://docs.mongodb.org/manual/core/replica-set-high-availability/
|Automatic Failover=supported
|Failover URL=http://docs.mongodb.org/manual/core/replica-set-high-availability/
|Automatic New Master Election after Failure=supported
|Master Election URL=http://docs.mongodb.org/manual/core/replica-set-elections/
|Replica Recovery and Resynchronization=not supported
|Repl Recovery URL=http://docs.mongodb.org/manual/tutorial/resync-replica-set-member/
|Read repair URL=http://bbc.co.uk
}}
MongoDB's replication architecture is based on a master-slave architecture, where a master is called a primary, and a slave is called a secondary. Hidden replicas can be used for backup. 

While there is no explicit support for data center aware data distribution, there are features that can be used to approximate this, such as tag aware sharding and operational segmentation - see http://docs.mongodb.org/manual/data-center-awareness/

Replica sets provide high availability using automatic failover. Failover allows a secondary member to become primary if primary is unavailable. Failover, in most situations does not require manual intervention. Replica set members keep the same data set but are otherwise independent. If the primary becomes unavailable, the replica set holds an election to select a new primary. In some situations, the failover process may require a rollback.

A replica set member becomes “stale” when its replication process falls so far behind that the primary overwrites oplog entries the member has not yet replicated. The member cannot catch up and becomes “stale.” When this occurs, you must completely resynchronize the member by removing its data and performing an initial sync.

It may take 10-30 seconds for the members of a replica set to declare a primary inaccessible. This triggers an election. During the election, the cluster is unavailable for writes. The election itself may take another 10-30 seconds.</text>
      <sha1>2geojbx7a9jo7yux9i05cnk2ynrx86v</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Cassandra Data Replication Features</title>
    <ns>0</ns>
    <id>250</id>
    <revision>
      <id>2211</id>
      <parentid>2210</parentid>
      <timestamp>2014-12-29T15:24:20Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="3465">{{Data Replication
|SQLDatabase=Cassandra
|Replication Architecture=peer-to-peer
|Repl Arch URL=http://www.datastax.com/documentation/cassandra/2.0/cassandra/architecture/architectureIntro_c.html
|Replication for Backup=not suppported
|Replication across Data Centers=supported in enterprise version only (data center aware)
|Repl Data Centers URL=http://www.datastax.com/dev/blog/multi-datacenter-replication
|Replicas Writes=to any replica, to multiple replicas
|Repl Writes URL=http://www.datastax.com/documentation/cassandra/2.1/cassandra/dml/dml_config_consistency_c.html
|Replica Reads=from any replica, from multiple replicas
|Repl Reads URL=http://www.datastax.com/documentation/cassandra/2.1/cassandra/dml/dml_config_consistency_c.html
|Read Repair=background
|Read Repair URL=http://www.datastax.com/documentation/cassandra/2.1/cassandra/dml/dml_config_consistency_c.html
|Automatic Replica Failure Detection=supported
|Repl Fail Detect URL=http://www.datastax.com/documentation/cassandra/2.1/cassandra/architecture/architectureDataDistributeFailDetect_c.html
|Automatic Failover=supported
|Failover URL=http://www.datastax.com/documentation/cassandra/2.1/cassandra/architecture/architectureDataDistributeFailDetect_c.html
|Automatic New Master Election after Failure=not relevant
|Master Election URL=http://www.datastax.com/documentation/cassandra/2.1/cassandra/architecture/architectureDataDistributeReplication_c.html
|Replica Recovery and Resynchronization=supported- automatic
|Repl Recovery URL=http://www.datastax.com/documentation/cassandra/2.1/cassandra/architecture/architectureDataDistributeFailDetect_c.html
}}
Cassandra is designed to handle big data workloads across multiple nodes with no single point of failure. Its architecture is based on the understanding that system and hardware failures can and do occur. Cassandra addresses the problem of failures by employing a peer-to-peer distributed system across homogeneous nodes where data is distributed among all nodes in the cluster. Each node exchanges information across the cluster every second. A sequentially written commit log on each node captures write activity to ensure data durability.

Cassandra stores replicas on multiple nodes to ensure reliability and fault tolerance. A replication strategy determines the nodes where replicas are placed.

The total number of replicas across the cluster is referred to as the replication factor. A replication factor of 1 means that there is only one copy of each row on one node. A replication factor of 2 means two copies of each row, where each copy is on a different node. All replicas are equally important; there is no primary or master replica. As a general rule, the replication factor should not exceed the number of nodes in the cluster. However, you can increase the replication factor and then add the desired number of nodes later.

When a node comes back online after an outage, it may have missed writes for the replica data it maintains. Once the failure detector marks a node as down, missed writes are stored by other replicas for a period of time providing hinted handoff is enabled. If a node is down for longer than max_hint_window_in_ms (3 hours by default), hints are no longer saved. Nodes that die may have stored undelivered hints. Run a repair after recovering a node that has been down for an extended period. Moreover, you should routinely run nodetool repair on all nodes to ensure they have consistent data.</text>
      <sha1>cuh260elb7c1uu6nz0iyvzuqiik3k47</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>CouchDB Data Replication Features</title>
    <ns>0</ns>
    <id>265</id>
    <revision>
      <id>2242</id>
      <parentid>2223</parentid>
      <timestamp>2014-12-31T16:16:28Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="2167">{{Data Replication
|SQLDatabase=CouchDB
|Replication Architecture=master-slave
|Repl Arch URL=http://wiki.apache.org/couchdb/Replication#Overview
|Replication for Backup=supported
|Repl Backup URL=http://wiki.apache.org/couchdb/Replication#Continuous_replication
|Replication across Data Centers=supported only by standard replication mechanisms
|Repl Data Centers URL=http://guide.couchdb.org/draft/replication.html
|Replicas Writes=to specified replica (configurable)
|Replica Reads=from specified replica (configurable)
|Read Repair=not relevant
|Automatic Replica Failure Detection=not supported
|Automatic Failover=not supported
|Automatic New Master Election after Failure=not relevant
|Replica Recovery and Resynchronization=supported- automatic
|Repl Recovery URL=http://guide.couchdb.org/draft/conflicts.html
}}
Native replication is one-way peer-to-peer using a direct connection, but you can implement Master/Slave, Master/Master, and other types of replication modalities by configuring the basic one way replication mechanism for multiple nodes.

Replication is incremental. If a target node is down, when it recovers the replication mechanism will reconnect and resume replication.

CouchDB’s operations take place within the context of a single document. As CouchDB achieves eventual consistency between multiple databases by using incremental replication you no longer have to worry about your database servers being able to stay in constant communication. Incremental replication is a process where document changes are periodically copied between servers. We are able to build what’s known as a shared nothing cluster of databases where each node is independent and self-sufficient, leaving no single point of contention across the system.

BigCouch is an implementation of the aforementioned Dynamo paper by Amazon. Dynamo defines a cluster and data management system that allows any number of machines to behave as if it was one while handling magnitudes more data and requests than a single server could handle, and on top of that be very resilient against server faults. The features evaluated in this page do not include BigCouch capabilities.</text>
      <sha1>9wlgy3x9e4oqisnyzfj10s6pp36pvql</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Neo4j Data Replication Features</title>
    <ns>0</ns>
    <id>321</id>
    <revision>
      <id>2353</id>
      <parentid>2229</parentid>
      <timestamp>2015-01-27T15:31:05Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="1995">{{Data Replication
|SQLDatabase=Neo4j
|Replication Architecture=master-slave
|Repl Arch URL=http://neo4j.com/docs/stable/ha-architecture.html
|Replication for Backup=supported
|Repl Backup URL=http://neo4j.com/docs/stable/capabilities-availability.html
|Replication across Data Centers=supported only by standard replication mechanisms
|Replicas Writes=to any replica
|Repl Writes URL=http://neo4j.com/docs/stable/ha-how.html
|Replica Reads=from any replica
|Repl Reads URL=http://neo4j.com/docs/stable/ha-how.html
|Read Repair=not relevant
|Automatic Replica Failure Detection=supported
|Repl Fail Detect URL=http://neo4j.com/docs/stable/ha-how.html
|Automatic Failover=supported
|Failover URL=http://neo4j.com/docs/stable/ha-how.html
|Automatic New Master Election after Failure=supported
|Master Election URL=http://neo4j.com/docs/stable/ha-how.html
|Replica Recovery and Resynchronization=supported- automatic
|Repl Recovery URL=http://neo4j.com/docs/stable/ha-how.html
}}
Write transactions can be performed on any database instance in a cluster.

Neo4j HA is fault tolerant and can continue to operate from any number of machines down to a single machine.

Slaves will be automatically synchronized with the master on write operations. If the master fails a new master will be elected automatically.

The cluster automatically handles instances becoming unavailable (for example due to network issues), and also makes sure to accept them as members in the cluster when they are available again. 

Transactions are atomic, consistent and durable but eventually propagated out to other slaves.

Updates to slaves are eventual consistent by nature but can be configured to be pushed optimistically from master during commit.

If the master goes down any running write transaction will be rolled back and new transactions will block or fail until a new master has become available.
Reads are highly available and the ability to handle read load scales with more database instances in the cluster.</text>
      <sha1>d0y1o1rb6dwstrsrxzalh4fyvde4sn0</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>HBase Data Replication Features</title>
    <ns>0</ns>
    <id>329</id>
    <revision>
      <id>2419</id>
      <parentid>2203</parentid>
      <timestamp>2015-02-03T16:54:19Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="3707">{{Data Replication
|SQLDatabase=HBase
|Replication Architecture=master-slave
|Repl Arch URL=http://hbase.apache.org/book.html#_cluster_replication
|Replication for Backup=supported
|Repl Backup URL=http://hbase.apache.org/book/cluster_replication.html
|Replication across Data Centers=supported by data center aware features
|Repl Data Centers URL=http://hbase.apache.org/book/cluster_replication.html
|Replicas Writes=to master replica only
|Repl Writes URL=http://hbase.apache.org/book/arch.timelineconsistent.reads.html
|Replica Reads=from any replica
|Repl Reads URL=http://hbase.apache.org/book/arch.timelineconsistent.reads.html
|Read Repair=not relevant
|Read Repair URL=http://hbase.apache.org/book/arch.timelineconsistent.reads.html
|Automatic Replica Failure Detection=supported
|Repl Fail Detect URL=http://hbase.apache.org/book/cluster_replication.html
|Automatic Failover=not supported
|Failover URL=http://blog.cloudera.com/blog/2012/07/hbase-replication-overview-2/
|Automatic New Master Election after Failure=not supported
|Master Election URL=http://blog.cloudera.com/blog/2012/07/hbase-replication-overview-2/
|Replica Recovery and Resynchronization=performed by administrator
|Repl Recovery URL=http://blog.cloudera.com/blog/2012/07/hbase-replication-overview-2/
}}
HBase provides a cluster replication mechanism which allows you to keep one cluster's state synchronized with that of another cluster, using the write-ahead log (WAL) of the source cluster to propagate the changes.

HBase Replication is a way of copying data from one HBase cluster to a different and possibly distant HBase cluster. It works on the principle that the transactions from the originating cluster are pushed to another cluster. In HBase jargon, the cluster doing the push is called the master, and the one receiving the transactions is called the slave. This push of transactions is done asynchronously,  and these transactions are batched in a configurable size (default is 64MB).  Asynchronous mode incurs minimal overhead on the master, and shipping edits in a batch increases the overall throughput.

HBase replication is not intended for automatic failover, the act of switching from the master to the slave cluster in order to start serving traffic is done by the user. Afterwards, once the master cluster is up again, one can do a CopyTable job to copy the deltas to the master cluster (by providing the start/stop timestamps) as described in the CopyTable blogpost

Cluster replication uses a source-push methodology. An HBase cluster can be a source (also called master or active, meaning that it is the originator of new data), a destination (also called slave or passive, meaning that it receives data via replication), or can fulfill both roles at once. Replication is asynchronous, and the goal of replication is eventual consistency. When the source receives an edit to a column family with replication enabled, that edit is propagated to all destination clusters using the WAL for that for that column family on the RegionServer managing the relevant region.

Each of the master cluster region servers keeps a watcher on every other region server, in order to be notified when one dies (just as the master does). When a failure happens, they all race to create a znode called lock inside the dead region server's znode that contains its queues. The region server that creates it successfully then transfers all the queues to its own znode, one at a time since ZooKeeper does not support renaming queues. After queues are all transferred, they are deleted from the old location. The znodes that were recovered are renamed with the ID of the slave cluster appended with the name of the dead server.</text>
      <sha1>a3wxey7ebmqdual43z1hzvfnn6ke3wb</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Accumulo Data Replication Features</title>
    <ns>0</ns>
    <id>337</id>
    <revision>
      <id>2219</id>
      <parentid>2062</parentid>
      <timestamp>2014-12-29T18:13:34Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="2475">{{Data Replication
|SQLDatabase=Accumulo
|Replication Architecture=master-slave
|Repl Arch URL=http://people.apache.org/~elserj/accumulo_user_manual.html#_replication
|Replication for Backup=not suppported
|Replication across Data Centers=supported by data center aware features
|Repl Data Centers URL=http://people.apache.org/~elserj/accumulo_user_manual.html#_replication
|Replicas Writes=to master replica only
|Repl Writes URL=https://accumulo.apache.org/1.6/accumulo_user_manual.html#_tablet_server
|Replica Reads=from master replica only
|Repl Reads URL=https://accumulo.apache.org/1.6/accumulo_user_manual.html#_tablet_server
|Read Repair=not relevant
|Automatic Replica Failure Detection=supported
|Repl Fail Detect URL=https://accumulo.apache.org/1.6/accumulo_user_manual.html
|Automatic Failover=supported
|Failover URL=https://accumulo.apache.org/1.6/accumulo_user_manual.html
|Automatic New Master Election after Failure=supported
|Master Election URL=https://accumulo.apache.org/1.6/accumulo_user_manual.html
|Replica Recovery and Resynchronization=supported- automatic
|Repl Recovery URL=https://accumulo.apache.org/1.6/accumulo_user_manual.html#_tablet_server
}}
In addition to versioning policies, Accumulo tables can be snapshotted to preserve the state of a table at a particular point in time. Snapshots are very efficient as Accumulo stores the original data and tracks changes separately, enabling snapshots to be created very quickly and without using a lot of additional storage.

TabletServers also perform recovery of a tablet that was previously on a server that failed, reapplying any writes found in the write-ahead log to the tablet.

This replication framework makes two Accumulo instances, where one instance replicates to another, eventually consistent between one another, as opposed to the strong consistency that each single Accumulo instance still holds. That is to say, attempts to read data from a table on a peer which has pending replication from the primary will not wait for that data to be replicated before running the scan. 

Data is replicated by using the Write-Ahead logs (WAL) that each TabletServer is already maintaining. TabletServers records which WALs have data that need to be replicated to the accumulo.metadata table. The Master uses these records, combined with the local Accumulo table that the WAL was used with, to create records in the replication table which track which peers the given WAL should be replicated to.</text>
      <sha1>i5w1isot4dwbhsia2vcg7vbxu7m45x7</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>FoundationDB Data Replication Features</title>
    <ns>0</ns>
    <id>344</id>
    <revision>
      <id>2232</id>
      <parentid>2072</parentid>
      <timestamp>2014-12-30T19:22:23Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="2720">{{Data Replication
|SQLDatabase=FoundationDB
|Replication Architecture=peer-to-peer
|Repl Arch URL=https://foundationdb.com/key-value-store/white-papers/fault-tolerance
|Replication for Backup=supported
|Repl Backup URL=https://foundationdb.com/key-value-store/documentation/backups.html
|Replication across Data Centers=supported by data center aware features
|Repl Data Centers URL=https://foundationdb.com/key-value-store/documentation/administration.html#datacenters
|Replicas Writes=to multiple replicas
|Repl Writes URL=https://foundationdb.com/key-value-store/documentation/configuration.html#choosing-a-redundancy-mode
|Replica Reads=from any replica
|Read Repair=not relevant
|Automatic Replica Failure Detection=supported
|Repl Fail Detect URL=https://foundationdb.com/key-value-store/white-papers/the-cap-theorem
|Automatic Failover=supported
|Failover URL=https://foundationdb.com/key-value-store/white-papers/the-cap-theorem
|Automatic New Master Election after Failure=not relevant
|Replica Recovery and Resynchronization=supported- automatic
|Repl Recovery URL=https://foundationdb.com/key-value-store/white-papers/the-cap-theorem
}}
The Key-Value Store is built on a distributed shared-nothing architecture. 

FoundationDB’s backup tool makes a consistent, point-in-time backup of a FoundationDB database without downtime. Like FoundationDB itself, the backup software is distributed, with multiple backup agents cooperating to perform a backup faster than a single machine can send or receive data and to continue the backup process seamlessly even when some backup agents fail.

FoundationDB is datacenter aware and supports operation across datacenters. 

The coordination servers use the Paxos algorithm to maintain a small amount of shared state that itself is Consistent and Partition-tolerant. Like the database as a whole, the shared state is not Available but is available for reads and writes in the partition containing a majority of the coordination servers.

FoundationDB uses this shared state to maintain and update a replication topology. When a failure occurs, the coordination servers are used to change the replication topology. It's worth noting that the coordination servers aren't involved at all in committing transactions.

When the partition ends, a machine will again be able to communicate with the majority of coordination servers and will rejoin the database. Depending on how long the communications failure lasted, A will rejoin by either receiving transactions that occurred in its absence or, in the worst case, transferring the contents of the database. After A has rejoined the database, all machines will again be able to handle transactions in a fault tolerant manner.</text>
      <sha1>dcshmbp47mha5lnrrjlm1txij7yttnz</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>VoltDB Data Replication Features</title>
    <ns>0</ns>
    <id>357</id>
    <revision>
      <id>2269</id>
      <timestamp>2015-01-06T19:52:06Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <comment>Created page with &quot;{{Data Replication |SQLDatabase=VoltDB |Replication Architecture=peer-to-peer |Repl Arch URL=http://voltdb.com/blog/scaling-voltdb-clustered-database |Replication for Backup=supp...&quot;</comment>
      <text xml:space="preserve" bytes="3639">{{Data Replication
|SQLDatabase=VoltDB
|Replication Architecture=peer-to-peer
|Repl Arch URL=http://voltdb.com/blog/scaling-voltdb-clustered-database
|Replication for Backup=supported
|Repl Backup URL=http://docs.voltdb.com/UsingVoltDB/ChapReplication.php
|Replication across Data Centers=supported by data center aware features
|Repl Data Centers URL=http://docs.voltdb.com/UsingVoltDB/ChapReplication.php
|Replicas Writes=to multiple replicas
|Repl Writes URL=http://docs.voltdb.com/UsingVoltDB/ChapKSafety.php
|Replica Reads=from any replica
|Repl Reads URL=http://docs.voltdb.com/UsingVoltDB/ChapKSafety.php
|Read Repair=not relevant
|Automatic Replica Failure Detection=supported
|Repl Fail Detect URL=http://docs.voltdb.com/UsingVoltDB/KSafeRecover.php
|Automatic Failover=supported
|Failover URL=http://docs.voltdb.com/UsingVoltDB/KSafeRecover.php
|Automatic New Master Election after Failure=not relevant
|Replica Recovery and Resynchronization=performed by administrator
|Repl Recovery URL=http://docs.voltdb.com/UsingVoltDB/clivoltdb.php
}}
Small, mostly read-only tables can be replicated across all of the partitions of a VoltDB database. This is particularly useful when a table is not accessed by a single column primarily. Tables where all the records appear in all the partitions are called replicated tables. Note that tables are replicated by default. The benefits of having the data replicated in all partitions is that it can be read from any individual partition. However, the deficit is that any updates or inserts to a replicated table must be executed in all partitions at once. This sort of multi-partition procedure reduces the benefits of parallel processing and impacts throughput. Which is why you should not replicate tables that are frequently updated.

K-Safety replicates partitions to provide redundancy as a protection against server failure. Note that when you enable K-Safety, you are replicating the unique partitions across the available hardware. By specifying a k-safe value greater than zero, you are telling VoltDB to create and maintain that many additional copies of each partition. These partition copies will be carefully distributed among the nodes in the cluster such that you can lose at least k nodes and still maintain a complete set of data. In other words, if you specify a k-safety value of 2, that means VoltDB will maintain 3 copies of each partition within the cluster, the original partition and 2 additional copies. It also means that your cluster can continue to operate and return correct (and complete) data if two nodes happen to drop out of the cluster. - 

When running with K-safety on, if a node goes down, the remaining nodes of the database cluster log an error indicating that a node has failed. If a node on a K-safe cluster fails, you can use the rejoin start action to have the node (or a replacement node) rejoin the cluster

SQLDatabase replication involves duplicating the contents of one database cluster (known as the master) to another database cluster (known as the replica). The contents of the replica cluster are completely controlled by the master, which is why this arrangement is sometimes referred to as a master/slave relationship. The replica database can be in the rack next to the master, in the next room, the next building, or another city entirely. The location depends upon your goals for replication. For example, if you are using replication for disaster recovery, geographic separation of the master and replica is required. If you are using replication for hot standby or offloading read-only queries, the physical location may not be important.</text>
      <sha1>gxtr6njba9lj11xxcj9ddmoguwduqeg</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>OrientDB Data Replication Features</title>
    <ns>0</ns>
    <id>546</id>
    <revision>
      <id>3324</id>
      <parentid>3240</parentid>
      <timestamp>2016-05-02T21:20:56Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="2454">{{Data Replication
|SQLDatabase=OrientDB
|Replication Architecture=peer-to-peer
|Repl Arch URL=http://orientdb.com/docs/last/Replication.html#replication
|Replication for Backup=not suppported
|Replication across Data Centers=supported only by standard replication mechanisms
|Repl Data Centers URL=http://orientdb.com/docs/last/Replication.html#sharing-of-database
|Replicas Writes=to multiple replicas
|Repl Writes URL=http://orientdb.com/docs/last/Distributed-Sharding.html#update-and-delete-of-records
|Replica Reads=from any replica
|Repl Reads URL=http://orientdb.com/docs/last/Distributed-Sharding.html#read-records
|Read Repair=not supported
|Automatic Replica Failure Detection=supported
|Repl Fail Detect URL=http://orientdb.com/docs/2.1/Distributed-Architecture-Lifecycle.html#distribute-the-configuration-to-the-clients
|Automatic Failover=supported
|Failover URL=http://orientdb.com/docs/2.1/Distributed-Architecture-Lifecycle.html#fail-over-management
|Automatic New Master Election after Failure=not relevant
|Replica Recovery and Resynchronization=supported- automatic
|Repl Recovery URL=http://orientdb.com/docs/2.1/Replication.html#server-unreachable
}}
OrientDB supports multi-master replication:
http://orientdb.com/docs/last/Replication.html#replication

All members are responsive to client data queries are responsible for propagating the data modifications made by each member to the rest of the group, and resolving any conflicts that might arise between concurrent changes made by different members.

Backup doesn't work on distributed nodes yet, so doing a backup of all the nodes to get all the shards is a manual operation in charge to the user
http://orientdb.com/docs/last/Distributed-Sharding.html#limitation

Pluggable Conflict Resolution Strategy: OrientDB supports injection of custom logic by writing a Java class
http://orientdb.com/docs/2.0/orientdb.wiki/SQL-Alter-SQLDatabase.html

Automatic failure detection: Every time a new Server Node joins or leaves the Cluster, the new Cluster configuration is broadcasted to all the connected clients
http://orientdb.com/docs/2.1/Distributed-Architecture-Lifecycle.html#distribute-the-configuration-to-the-clients

When a Server Node becomes unreachable (because it’s crashed, network problems, high load, etc.) the Cluster treats this event as if the Server Node left the cluster.
http://orientdb.com/docs/2.1/Distributed-Architecture-Lifecycle.html#when-a-node-is-unreachable</text>
      <sha1>ftqw8xkwwwbnyq4axfva8kaho2wkp4v</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Couchbase Data Replication Features</title>
    <ns>0</ns>
    <id>555</id>
    <revision>
      <id>3308</id>
      <parentid>3278</parentid>
      <timestamp>2016-04-25T20:16:19Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="2637">{{Data Replication
|SQLDatabase=Couchbase
|Replication Architecture=master-slave
|Repl Arch URL=http://docs.couchbase.com/admin/admin/Tasks/tasks-manage-replication.html
|Replication for Backup=not suppported
|Repl Backup URL=http://docs.couchbase.com/admin/admin/Tasks/tasks-backup-restore.html
|Replication across Data Centers=supported by data center aware features
|Repl Data Centers URL=http://docs.couchbase.com/admin/admin/XDCR/xdcr-intro.html
|Replicas Writes=to master replica only, to multiple replicas
|Repl Writes URL=http://developer.couchbase.com/documentation/server/4.0/sdks/java-2.2/documents-creating.html
|Replica Reads=from master replica only, from any replica, from multiple replicas
|Repl Reads URL=http://developer.couchbase.com/documentation/server/4.0/sdks/java-2.2/documents-retrieving.html
|Read Repair=not supported
|Read Repair URL=http://docs.couchbase.com/developer/dev-guide-3.0/replica-read-functions.html
|Automatic Replica Failure Detection=supported
|Repl Fail Detect URL=http://developer.couchbase.com/documentation/server/4.0/ui/automatic-failover.html
|Automatic Failover=supported
|Failover URL=http://developer.couchbase.com/documentation/server/4.0/ui/automatic-failover.html
|Automatic New Master Election after Failure=supported
|Master Election URL=Http://www.couchbase.com/struggling-with-mongodb
|Replica Recovery and Resynchronization=performed by administrator
|Repl Recovery URL=http://docs.couchbase.com/admin/admin/Tasks/recovery-full-recovery.html
}}
Within a Couchbase cluster, you have active data and replica data on each node. Active data is data that was written by a client on that node. Replica data is a copy of an item from another node.

After writing an item to Couchbase Server, it makes a copy of this data from the RAM of one node to another node. Distribution of replica data is handled in the same way as active data: portions of replica data is distributed around the Couchbase cluster to different nodes to prevent a single point of failure.

If you use replica read, it will introduce the possibility that a client gets inconsistent data from the cluster; for this reason we generally recommend you have your application logic handle shorts periods of unavailability.

Automatic failover will only fail over one node before requiring human intervention to prevent a chain reaction failure of all nodes in the cluster.

Replica Server: Couchbase Server replicates object data (the number of Replicants is user-defined) to Replica Servers. Replica Servers can rapidly (within 100 msec) become the Master Server for a given key in case of original Master Server failure.</text>
      <sha1>7810fm6gquhjuaexc742ozo7mp371y2</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Redis Data Replication Features</title>
    <ns>0</ns>
    <id>564</id>
    <revision>
      <id>3302</id>
      <parentid>3274</parentid>
      <timestamp>2016-04-22T20:43:11Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="2857">{{Data Replication
|SQLDatabase=Redis
|Replication Architecture=master-slave
|Repl Arch URL=http://redis.io/topics/replication
|Replication for Backup=not suppported
|Repl Backup URL=https://www.digitalocean.com/community/tutorials/how-to-back-up-and-restore-your-redis-data-on-ubuntu-14-04
|Replication across Data Centers=supported only by standard replication mechanisms
|Repl Data Centers URL=http://tech.3scale.net/2012/07/25/fun-with-redis-replication/
|Replicas Writes=to master replica only, to any replica
|Repl Writes URL=http://redis.io/topics/replication#read-only-slave
|Replica Reads=from any replica
|Repl Reads URL=http://redis.io/topics/replication
|Read Repair=not relevant
|Read Repair URL=http://redis.io/topics/replication
|Automatic Replica Failure Detection=supported
|Repl Fail Detect URL=http://redis.io/topics/sentinel
|Automatic Failover=supported
|Failover URL=http://redis.io/topics/sentinel
|Automatic New Master Election after Failure=supported
|Master Election URL=http://redis.io/topics/sentinel
|Replica Recovery and Resynchronization=supported- automatic
|Repl Recovery URL=http://redis.io/topics/replication#how-redis-replication-works
}}
Redis Sentinel provides high availability for Redis. In practical terms this means that using Sentinel you can create a Redis deployment that resists without human intervention to certain kind of failures.
Redis Sentinel also provides other collateral tasks such as monitoring, notifications and acts as a configuration provider for clients.

Although Redis allowed chaining slaves together([http://redis.io/topics/replication document]), it's still very rare to enable writes to any replica([http://stackoverflow.com/questions/4719346/redis-master-slave-replication-single-point-of-failure link])

Since Redis 2.6, slaves support a read-only mode that is enabled by default. This behavior is controlled by the slave-read-only option in the redis.conf file, and can be enabled and disabled at runtime using CONFIG SET.
Read-only slaves will reject all write commands, so that it is not possible to write to a slave because of a mistake. This does not mean that the feature is intended to expose a slave instance to the internet or more generally to a network where untrusted clients exist, because administrative commands like DEBUG or CONFIG are still enabled. However, security of read-only instances can be improved by disabling commands in redis.conf using the rename-command directive.
You may wonder why it is possible to revert the read-only setting and have slave instances that can be target of write operations. While those writes will be discarded if the slave and the master resynchronize or if the slave is restarted, there are a few legitimate use case for storing ephemeral data in writable slaves. However in the future it is possible that this feature will be dropped.</text>
      <sha1>jimwgaeseedoul7sd48zsndzho2zvxw</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Amazon DynamoDB Data Replication Features</title>
    <ns>0</ns>
    <id>573</id>
    <revision>
      <id>3315</id>
      <parentid>3176</parentid>
      <timestamp>2016-04-28T21:42:42Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="3816">{{Data Replication
|SQLDatabase=Amazon DynamoDB
|Replication Architecture=peer-to-peer
|Repl Arch URL=http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf
|Replication for Backup=supported
|Repl Backup URL=http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf
|Replication across Data Centers=supported by data center aware features
|Repl Data Centers URL=http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Streams.CrossRegionRepl.html
|Replicas Writes=to multiple replicas
|Repl Writes URL=http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf
|Replica Reads=from any replica
|Repl Reads URL=http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf
|Read Repair=per query
|Read Repair URL=http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf
|Automatic Replica Failure Detection=supported
|Repl Fail Detect URL=http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf
|Automatic Failover=supported
|Failover URL=http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf
|Automatic New Master Election after Failure=not relevant
|Master Election URL=http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf
|Replica Recovery and Resynchronization=supported- automatic
|Repl Recovery URL=http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf
}}
Replication Architecture: Master Slave (Mentioned in 4.3 : each key is assigned to a coordinator node which is responsible for replicating data)

Replication for Backup/ Automatic Failover: (Section 4.6 : 2nd Para) this example, if node A is temporarily down or unreachable during a write operation then a replica that would normally have lived on A will now be sent to node D. This is done to maintain the desired availability and durability guarantees. The replica sent to D will have a hint in its metadata that suggests which node was the intended recipient of the replica (in this case A). Nodes that receive hinted replicas will keep them in a separate local database that is scanned periodically. Upon detecting that A has recovered, D will attempt to deliver the replica to A.

Replicas Writes/Reads (4.3 Replication): Dynamo DB allows users to configure values Of N,R,W. depending on the values of R and W it would decide how many replicas it would need to complete the read/write operation 

Read Repair: (Section 5 ) 
After the read response has been returned to the caller the state machine waits for a small period of time to receive any
outstanding responses. If stale versions were returned in any of
the responses, the coordinator updates those nodes with the latest
version. This process is called read repair because it repairs
replicas that have missed a recent update at an opportunistic time
and relieves the anti-entropy protocol from having to do it.

Automatic Replica Failure Detection: (Section 4.7)
To handle this and other threats to durability, Dynamo implements an anti-entropy (replica synchronization) protocol to keep the replicas synchronized.

Automatic New Master Election after Failure: (Section 4.5)
A node handling a read or write operation is known as the coordinator. Typically, this is the first among the top N nodes in
the preference list. If the requests are received through a load balancer, requests to access a key may be routed to any random
node in the ring. In this scenario, the node that receives the request will not coordinate it if the node is not in the top N of the
requested key’s preference list. Instead, that node will forward the request to the first among the top N nodes in the preference list. 

Replica Recovery and Resynchronization: (Section 4.6 and 4.7)
Dynamo uses Hinted handoff and anti-entropy (replica synchronization) protocol to keep the replicas synchronized</text>
      <sha1>3wcj18epf1qugsmf1ya374kdna2uj3r</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>CouchDB Scalability Features</title>
    <ns>0</ns>
    <id>266</id>
    <revision>
      <id>2475</id>
      <parentid>2397</parentid>
      <timestamp>2015-03-06T21:09:39Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="1630">{{Scalability
|Scale Out Architecture=horizontal partitioning of database, horizontal partitioning and replication
|Scale Out URL=http://guide.couchdb.org/draft/scaling.html
|SQLDatabase=CouchDB
|Client Request Load Balancing=uses HTTP-based load balancers
|Load Balancing URL=https://www.safaribooksonline.com/library/view/scaling-couchdb/9781449304942/ch04.html
|Scale Data Capacity=manual data rebalancing
|Scale Data URL=http://guide.couchdb.org/draft/clustering.html
|Data Object Based Locks on Writes=no locks - optimistic concurrency model
|Write Locks URL=http://docs.couchdb.org/en/1.6.1/intro/consistency.html
|Scalable Request Processing Architecture=based on an external load balancer
|Scale Architecture URL=https://www.safaribooksonline.com/library/view/scaling-couchdb/9781449304942/ch04.html
}}
==Notes==
CouchDB Lounge is an additional package needed to scale out a CouchDB database - see http://guide.couchdb.org/draft/clustering.html

Instead of locks, CouchDB uses Multi-Version Concurrency Control (MVCC) to manage concurrent access to the database

With CouchDB’s incremental replication, you can synchronize your data between any two databases however you like and whenever you like. After replication, each database is able to work independently.

You could use this feature to synchronize database servers within a cluster or between data centers using a job scheduler such as cron, or you could use it to synchronize data with your laptop for offline work as you travel. Each database can be used in the usual fashion, and changes between databases can be synchronized later in both directions.

==Notes==</text>
      <sha1>mu6gdw3lfkih40zchag9susabk3nty8</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>FoundationDB Scalability Features</title>
    <ns>0</ns>
    <id>345</id>
    <revision>
      <id>2476</id>
      <parentid>2473</parentid>
      <timestamp>2015-03-23T18:31:13Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="1602">{{Scalability
|Scale Out Architecture=horizontal partitioning of database, horizontal partitioning and replication
|Scale Out URL=https://foundationdb.com/key-value-store/features
|SQLDatabase=FoundationDB
|Client Request Load Balancing=client requests load balanced across coordinators
|Load Balancing URL=https://foundationdb.com/layers/sql/documentation/Concepts/architecture.html#recommended-architecture
|Scale Data Capacity=automatic data rebalancing
|Scale Data URL=https://foundationdb.com/key-value-store/white-papers/scalability
|Data Object Based Locks on Writes=no locks - optimistic concurrency model
|Write Locks URL=https://foundationdb.com/key-value-store/white-papers/transaction-processing
|Scalable Request Processing Architecture=not scalable (bottleneck)
|Scale Architecture URL=http://community.foundationdb.com/questions/4011/load-distribution-between-fdb-processes.html
}}
==Notes==
The FoundationDB client manages all load balancing between the FoundationDB client and the FoundationDB cluster. 

It is possible for the master or a tlog to become a bottleneck on the write path with enough write volume (see our known limitations). There is a mechanism to specify the desired machines for these roles to run on, which allows you to put them on better machines and to avoid splitting resources with other processes in the cluster.

In the upcoming 3.0 release, there will be a rearchitected scalable write path. The number of tlogs will be configurable, and the conflict resolution process will also become be distributed on a configurable number of resolution machines.

==Notes==</text>
      <sha1>7zwwkzbskcgtmjt9cjn5uj0tkch7ug2</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Accumulo Scalability Features</title>
    <ns>0</ns>
    <id>338</id>
    <revision>
      <id>2480</id>
      <parentid>2171</parentid>
      <timestamp>2015-03-25T19:53:40Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="1526">{{Scalability
|Scale Out Architecture=horizontal partitioning of database, horizontal partitioning and replication
|Scale Out URL=http://accumulo.apache.org/user_manual_1.3-incubating/Accumulo_Design.html
|SQLDatabase=Accumulo
|Client Request Load Balancing=fixed connections to a request coordinator
|Load Balancing URL=http://accumulo.apache.org/user_manual_1.3-incubating/Accumulo_Design.html
|Scale Data Capacity=automatic data rebalancing
|Scale Data URL=http://accumulo.apache.org/user_manual_1.3-incubating/Accumulo_Design.html
|Data Object Based Locks on Writes=locks on updated objects only
|Write Locks URL=http://accumulo.apache.org/user_manual_1.3-incubating/Accumulo_Design.html
|Scalable Request Processing Architecture=centralized coordinator, but can be replicated
|Scale Architecture URL=http://accumulo.apache.org/user_manual_1.3-incubating/Accumulo_Design.html
}}
==Notes==
Accumulo stores data in tables, which are partitioned into tablets. Tablets are partitioned on row boundaries so that all of the columns and values for a particular row are found together within the same tablet. 

The Master assigns Tablets to one TabletServer at a time. This enables row-level transactions to take place without using distributed locking or some other complicated synchronization mechanism. As clients insert and query data, and as machines are added and removed from the cluster, the Master migrates tablets to ensure they remain available and that the ingest and query load is balanced across the cluster.

==Notes==</text>
      <sha1>ly8k4yglv9a786nr5mewg2w9wgw9kf6</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>MongoDB Scalability Features</title>
    <ns>0</ns>
    <id>228</id>
    <revision>
      <id>2173</id>
      <parentid>2145</parentid>
      <timestamp>2014-12-16T17:16:54Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="2911">{{Scalability
|Scale Out Architecture=horizontal partitioning of database, horizontal partitioning and replication
|Scale Out URL=http://docs.mongodb.org/manual/sharding/
|SQLDatabase=MongoDB
|Client Request Load Balancing=fixed connections to a request coordinator
|Load Balancing URL=http://docs.mongodb.org/manual/core/sharded-cluster-architectures-production/
|Scale Data Capacity=automatic data rebalancing
|Scale Data URL=http://docs.mongodb.org/manual/core/sharding-balancing/
|Data Object Based Locks on Writes=locks on whole database
|Write Locks URL=http://docs.mongodb.org/manual/faq/concurrency/
|Scalable Request Processing Architecture=centralized coordinator, but can be replicated
|Scale Architecture URL=http://docs.mongodb.org/manual/core/sharding-introduction/
}}
==Notes==
MongoDB introduces an intermediary process called mongos that is responsible for resolving the query-supplied shard key and then issue the query to where the data resides. This process can (and should) be replicated but in a high transaction volume application it can potentially become a bottleneck.

mongos instances are the routers for the cluster. Typically, deployments have one mongos instance on each application server. You may deploy a group of mongos instances and use a proxy/load balancer between the application and the mongos. In these deployments, you must configure the load balancer for client affinity so that every connection from a single client reaches the same mongos. Because cursors and other resources are specific to an single mongos instance, each client must connect to only one mongos instance.

Balancing is the process MongoDB uses to distribute data of a sharded collection evenly across a sharded cluster. When a shard has too many of a sharded collection’s chunks compared to other shards, MongoDB automatically balances the chunks across the shards. The balancing procedure for sharded clusters is entirely transparent to the user and application layer.

Beginning with version 2.2, MongoDB implements locks on a per-database basis for most read and write operations. Some global operations, typically short lived operations involving multiple databases, still require a global “instance” wide lock. Before 2.2, there is only one “global” lock per mongod instance. For example, if you have six databases and one takes a database-level write lock, the other five are still available for read and write. A global lock makes all six databases unavailable during the operation.

Query Routers, or mongos instances, interface with client applications and direct operations to the appropriate shard or shards. The query router processes and targets operations to shards and then returns results to the clients. A sharded cluster can contain more than one mongos to divide the client request load. A client sends requests to one mongos. Most sharded clusters have many query routers.</text>
      <sha1>6d70encc4yodna9mf8yb71tk6955hsl</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Neo4j Scalability Features</title>
    <ns>0</ns>
    <id>229</id>
    <revision>
      <id>2477</id>
      <parentid>2396</parentid>
      <timestamp>2015-03-25T15:54:16Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="898">{{Scalability
|Scale Out Architecture=replicate complete database only
|Scale Out URL=http://docs.neo4j.org/chunked/stable/ha.html
|SQLDatabase=Neo4j
|Client Request Load Balancing=uses HTTP-based load balancers
|Load Balancing URL=http://neo4j.com/docs/stable/ha-haproxy.html
|Scale Data Capacity=N/A - single server only
|Scale Data URL=http://neo4j.com/docs/stable/introduction-highlights.html
|Data Object Based Locks on Writes=locks on updated objects only
|Write Locks URL=http://neo4j.com/docs/stable/transactions-locking.html
|Scalable Request Processing Architecture=based on an external load balancer
|Scale Architecture URL=http://neo4j.com/docs/stable/ha-haproxy.html
}}
==Notes==
Neo4j is scaled out by replicating the complete database and the feature is known as High Availability (HA).

In the Neo4j HA architecture, the cluster is typically fronted by a load balancer such as HAProxy.</text>
      <sha1>39ho8vjel0qjnkze8vmx1p0ibjs7rk4</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Riak Scalability Features</title>
    <ns>0</ns>
    <id>211</id>
    <revision>
      <id>2182</id>
      <parentid>2108</parentid>
      <timestamp>2014-12-18T21:00:45Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="1350">{{Scalability
|Scale Out Architecture=horizontal partitioning of database, horizontal partitioning and replication
|Scale Out URL=http://basho.com/riak/
|SQLDatabase=Riak
|Client Request Load Balancing=client requests load balanced across coordinators
|Load Balancing URL=http://128bitstudios.com/2013/05/08/setting-up-a-riak-cluster/
|Scale Data Capacity=automatic data rebalancing
|Scale Data URL=http://basho.com/riak/
|Data Object Based Locks on Writes=no locks - conflicts allowed
|Write Locks URL=http://docs.basho.com/riak/latest/theory/concepts/Vector-Clocks/
|Scalable Request Processing Architecture=fully distributed - any node acts as a coordinator
|Scale Architecture URL=http://docs.basho.com/riak/latest/theory/concepts/Clusters/
}}
==Notes==
Load balancing: Riak clients are able to connect to a list of nodes to perform their own load balancing.

Scalable request processing: When a value is being stored in the cluster, any node may participate as the coordinator for the request. The coordinating node consults the ring state to determine which vnode owns the partition in which the value's key belongs, then sends the “put” request to that vnode, as well as the vnodes responsible for the next N-1 partitions in the ring, where N is a bucket-configurable parameter that describes how many copies of the value to store.

==Notes==</text>
      <sha1>8azk6j2zyp0rul1b7np667swi3frao8</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Cassandra Scalability Features</title>
    <ns>0</ns>
    <id>227</id>
    <revision>
      <id>2478</id>
      <parentid>2172</parentid>
      <timestamp>2015-03-25T18:38:03Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="1595">{{Scalability
|Scale Out Architecture=horizontal partitioning of database, horizontal partitioning and replication
|Scale Out URL=http://www.datastax.com/documentation/cassandra/2.0/cassandra/architecture/architectureIntro_c.html
|SQLDatabase=Cassandra
|Client Request Load Balancing=client requests load balanced across coordinators
|Load Balancing URL=https://datastax.github.io/python-driver/api/cassandra/policies.html
|Scale Data Capacity=automatic data rebalancing
|Scale Data URL=http://www.datastax.com/documentation/cassandra/1.2/cassandra/architecture/architectureDataDistributeVnodesUsing_c.html
|Data Object Based Locks on Writes=locks on updated objects only
|Write Locks URL=http://www.datastax.com/documentation/cassandra/2.0/cassandra/dml/dml_isolation_c.html
|Scalable Request Processing Architecture=fully distributed - any node acts as a coordinator
|Scale Architecture URL=http://www.datastax.com/documentation/cassandra/2.0/cassandra/architecture/architectureIntro_c.html
}}
==Notes==
Cassandra scales horizontally with a request coordinator available at every shard to handle client requests.

Client read or write requests can be sent to any node in the cluster because all nodes in Cassandra are peers. When a client connects to a node and issues a read or write request, that node serves as the coordinator for that particular client operation.

Full row-level isolation is in place, which means that writes to a row are isolated to the client performing the write and are not visible to any other user until they are complete. Delete operations are performed in isolation.</text>
      <sha1>5qw677vyzrklvvlzt6rbjz8yyprmn2i</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>HBase Scalability Features</title>
    <ns>0</ns>
    <id>330</id>
    <revision>
      <id>2479</id>
      <parentid>2472</parentid>
      <timestamp>2015-03-25T19:52:39Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="1366">{{Scalability
|Scale Out Architecture=horizontal partitioning of database, horizontal partitioning and replication
|Scale Out URL=http://stackoverflow.com/questions/5417574/hbase-how-does-replication-work
|SQLDatabase=HBase
|Client Request Load Balancing=fixed connections to a request coordinator
|Load Balancing URL=https://support.pivotal.io/hc/en-us/articles/200950308-HBase-Basics
|Scale Data Capacity=automatic data rebalancing
|Scale Data URL=http://hbase.apache.org/book/node.management.html
|Data Object Based Locks on Writes=locks on updated objects only
|Write Locks URL=http://hbase.apache.org/acid-semantics.html
|Scalable Request Processing Architecture=centralized coordinator, but can be replicated
|Scale Architecture URL=http://hbase.apache.org/book/arch.timelineconsistent.reads.html#d4319e13447
}}
==Notes==
A RegionServer runs on a DataNode. Each Region Server is responsible to serve a set of regions, and one Region (i.e. range of rows) can be served only by one Region Server.. All reads and writes are routed through a single region server.

Once a client has looked up where a row resides (i.e., in what region), it caches this information and directly contacts the HRegionServer hosting that region. That way, the client has a pretty complete picture over time of where to get rows without needing to query the .META. server again.

==Notes==</text>
      <sha1>0trt5wu8syw4knxyatdxzhxffvgeh30</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>VoltDB Scalability Features</title>
    <ns>0</ns>
    <id>352</id>
    <revision>
      <id>2255</id>
      <parentid>2186</parentid>
      <timestamp>2015-01-06T17:58:48Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="3749">{{Scalability
|Scale Out Architecture=horizontal partitioning of database, horizontal partitioning and replication
|Scale Out URL=http://docs.voltdb.com/UsingVoltDB/IntroHowVoltDBWorks.php#IntroSerialize
|SQLDatabase=VoltDB
|Client Request Load Balancing=client requests load balanced across coordinators
|Load Balancing URL=https://forum.voltdb.com/showthread.php?49-Load-Balancing
|Scale Data Capacity=automatic data rebalancing
|Scale Data URL=http://docs.voltdb.com/UsingVoltDB/UpdateHw.php
|Data Object Based Locks on Writes=no locks - single threaded execution
|Write Locks URL=http://docs.voltdb.com/UsingVoltDB/IntroHowVoltDBWorks.php#IntroSerialize
|Scalable Request Processing Architecture=fully distributed - any node acts as a coordinator
|Scale Architecture URL=http://docs.voltdb.com/PerfGuide/Hello2Connect.php
}}
==Notes==
Tables are partitioned in VoltDB by hashing primary key values. Performance is optimized by choosing partitioning keys that match the way the data is most commonly accessed. To further optimize performance, VoltDB allows selected tables to be replicated on all partitions of the cluster. This strategy minimizes cross-partition join operations. 

There is one initiator for each unique partition, and a separate initiator for multi-partition transactions within the cluster. Once the initiator receives the transaction, it is responsible for (1) Scheduling the transaction with the other nodes in the cluster
(2) Distributing the work items for the transaction to the appropriate nodes and partitions and collecting responses when it is time to execute the transaction

When a database is configured for K-safety, VoltDB automatically (and transparently) replicates database partitions so that the database can withstand the loss of “K” nodes (due to hardware or software problems) without interrupting the database.

For a multi-node cluster, simply connect to all nodes and let the client library round-robin your requests (the client library will load balance requests to each node). Once the requests reaches a node, that node will communicate with the others to decide (based on K-safety and the partition target deduced from your partitioning key when you called the procedure), which specific sites will have to execute the transaction.

While the cluster is rebalancing after nodes have been added, the database continues to handle incoming requests. However, depending on the workload and amount of data in the database, rebalancing may take a significant amount of time. Rebalance tasks are fully transactional, meaning they operate within the database's ACID-compliant transactional model. Because they involve moving data between two or more partitions, they are also multi-partition transactions. This means that each rebalance work unit can incrementally add to the latency of pending client transactions.

You can control how quickly the rebalance operation completes versus how much rebalance work impacts ongoing client transactions using two attributes of the &lt;elastic&gt; element in the deployment file:
-The duration attribute sets a target value for the length of time each rebalance transaction will take, specified in milliseconds. The default is 50 milliseconds.
-The throughput attribute sets a target value for the number of megabytes per second that will be processed by the rebalance transactions. The default is 2 megabytes.

It is the application developer's responsibility to ensure that the queries in a single-partitioned stored procedure are truly single-partitioned. VoltDB does not warn you about SELECT or DELETE statements that will return incomplete results. VoltDB does generate a runtime error if you attempt to INSERT a row that does not belong in the current partition.</text>
      <sha1>tliy8wcvt2a113aiuux25qvllwj8p31</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>OrientDB Scalability Features</title>
    <ns>0</ns>
    <id>547</id>
    <revision>
      <id>3168</id>
      <parentid>3126</parentid>
      <timestamp>2016-04-10T04:14:23Z</timestamp>
      <contributor>
        <username>Ccis</username>
        <id>62</id>
      </contributor>
      <text xml:space="preserve" bytes="1814">{{Scalability
|Scale Out Architecture=horizontal partitioning and replication
|SQLDatabase=OrientDB
|Client Request Load Balancing=client-based load balancing, which uses round-robin approach to connect to the available server
|Scale Data Capacity=automatic data rebalancing
|Data Object Based Locks on Writes=no locks - optimistic concurrency model
|Scalable Request Processing Architecture=not supported
}}
==Notes==
THIS PAGE IS UNDER DEVELOPMENT AND THE INFORMATION HERE SHOULD NOT BE USED AS IT IS CURRENTLY NOT RELIABLE

OrientDB supports sharding of data at class level, by using multiple clusters per class, where each cluster has own list of server where data is replicated:
http://orientdb.com/docs/last/Distributed-Sharding.html

OrientDB uses client-side load balancing: ROUND_ROBIN_REQUEST provides strong consistency:
http://orientdb.com/docs/2.1/Distributed-Configuration.html#load-balancing

All the storages contained in the $ORIENT_HOME/databases are visible from the OrientDB Server instance without the need of configure them:
http://orientdb.com/docs/last/DB-Server.html#storages

OrientDB utilizes Paginated Local Storage, which is a disk based storage which works with data using page model:
http://orientdb.com/docs/last/Paginated-Local-Storage.html

Records per database (Documents, Vertices and Edges are stored as records): can be up to 302,231,454,903,000,000,000,000 (2^78-1), namely 302,231,454,903 Trillion records:
http://orientdb.com/docs/last/Limits.html#limits

OrientDB uses Optimistic concurrency control for both Atomic Operations and Transactions:
http://orientdb.com/docs/2.1/Concurrency.html#optimistic-concurrency-in-orientdb

OrientDB uses multiple server addresses to achieve efficient load balancing:
http://orientdb.com/docs/2.1/Distributed-Configuration.html#use-the-dns</text>
      <sha1>56w3rbqtyrfta6arnxo7lb63trhchaq</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Couchbase Scalability Features</title>
    <ns>0</ns>
    <id>556</id>
    <revision>
      <id>3290</id>
      <parentid>3279</parentid>
      <timestamp>2016-04-13T22:27:47Z</timestamp>
      <contributor>
        <username>Ccis</username>
        <id>62</id>
      </contributor>
      <text xml:space="preserve" bytes="1936">{{Scalability
|Scale Out Architecture=horizontal partitioning of database, horizontal partitioning and replication
|Scale Out URL=http://docs.couchbase.com/admin/admin/Concepts/concept-nodesCluster.html
|SQLDatabase=Couchbase
|Client Request Load Balancing=uses server-based load balancers
|Load Balancing URL=http://blog.couchbase.com/couchbase-101-q-and-a
|Scale Data Capacity= manually data rebalancing
|Scale Data URL=http://docs.couchbase.com/admin/admin/Tasks/tasks-rebalance.html
|Data Object Based Locks on Writes=either optimistic or pessimistic concurrency
|Write Locks URL=http://blog.couchbase.com/couchbase-101-q-and-a
|Scalable Request Processing Architecture=internal load balancer
|Scale Architecture URL=http://blog.couchbase.com/couchbase-101-q-and-a
}}
==Notes==
Rebalancing is a deliberate process that you need to initiate manually when the structure of your cluster changes. It changes the allocation of the vBuckets used to store the information and then physically moves the data between the nodes to match the new structure.

It's important to actually NOT put a load balancer between the application servers and Couchbase. Because of the key-hash partitioning, data is already automatically distributed across the Couchbase cluster. The app servers will connect and interact with the Couchbase cluster nodes directly and because of the partitioning be already &quot;load balanced&quot; in the sense that they will be doing CRUD operations across the cluster based on the hashing of the keys. The app servers and sdk clients will maintain open connections to each node in the Couchbase cluster, and generally, a single shared connection is all that is needed for each app server.

 Couchbase supports ACID &quot;transactions&quot; on a per-document level. You can use either CAS (Check and Set/Compare and Swap) for optimistic concurrency or use GetAndLock to actually lock a document for pessimistic concurrency scenarios. 
==Notes==</text>
      <sha1>aq8c39q4vnn18je9t9l7x4ql4knbxdn</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Redis Scalability Features</title>
    <ns>0</ns>
    <id>565</id>
    <revision>
      <id>3090</id>
      <parentid>3089</parentid>
      <timestamp>2016-04-07T00:13:27Z</timestamp>
      <contributor>
        <username>Ccis</username>
        <id>62</id>
      </contributor>
      <text xml:space="preserve" bytes="1214">{{Scalability
|Scale Out Architecture=horizontal partitioning of database, horizontal partitioning and replication
|Scale Out URL=http://redis.io/topics/partitioning
|SQLDatabase=Redis
|Client Request Load Balancing=uses HTTP-based load balancers
|Load Balancing URL=https://support.pivotal.io/hc/en-us/articles/205309388-How-to-setup-HAProxy-and-Redis-Sentinel-for-automatic-failover-between-Redis-Master-and-Slave-servers
|Scale Data Capacity=manual data rebalancing
|Scale Data URL=http://redis.io/topics/cluster-spec#cluster-live-reconfiguration
|Data Object Based Locks on Writes=no locks - single threaded execution
|Write Locks URL=http://stackoverflow.com/questions/10650232/locking-and-redis
|Scalable Request Processing Architecture=based on an external load balancer
|Scale Architecture URL=https://support.pivotal.io/hc/en-us/articles/205309388-How-to-setup-HAProxy-and-Redis-Sentinel-for-automatic-failover-between-Redis-Master-and-Slave-servers
}}
==Notes==
Horizontal partitioning is well supported by Redis cluster, [http://redis.io/topics/cluster-spec documentation can be found here]

For automatic data rebalancing, they are still working on it, [https://github.com/antirez/redis/issues/2460 links]</text>
      <sha1>6hwltouopqfz8pm8kc6j14ns8dmzcns</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Amazon DynamoDB Scalability Features</title>
    <ns>0</ns>
    <id>574</id>
    <revision>
      <id>3316</id>
      <parentid>3296</parentid>
      <timestamp>2016-04-28T21:44:24Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="1192">{{Scalability
|Scale Out Architecture= horizontal partitioning and replication
|SQLDatabase=Amazon DynamoDB
|Client Request Load Balancing= by request coordination component that uses a state machine to handle incoming requests [http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf For detailed information refer to section 6.4 Client-driven or Server-driven Coordination ]
|Scale Data Capacity=based on the principles of Consistent Hashing [http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf For detailed information refer to section 6.2 Ensuring Uniform Load distribution ]
|Data Object Based Locks on Writes=no locks - dynamo db locks at item level by using optimistic locking [http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBMapper.OptimisticLocking.html Detailed information]
|Scalable Request Processing Architecture= request processing is decentralized. Read request can be handled by any node, write requests are handled by nodes in the preference list.  [http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf For detailed information refer to section 6.4 Client-driven or Server-driven Coordination ]
}}
==Notes==</text>
      <sha1>isb6dq84ixyir9x3r66ajmc1hgfumw4</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Riak Security Features</title>
    <ns>0</ns>
    <id>224</id>
    <revision>
      <id>2435</id>
      <parentid>1377</parentid>
      <timestamp>2015-02-05T14:50:53Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="1406">{{Security
|SQLDatabase=Riak
|Client Authentication=custom user/password, SSL
|Sec Client Auth URL=http://basho.com/riak-security-2-0-not-just-a-firewall-anymore/
|Server authentication=SSL
|Sec Server Auth URL=http://docs.basho.com/riak/latest/ops/running/authz/
|Credential Store=in database
|Role Based Security=supported
|Sec Roles URL=http://docs.basho.com/riak/latest/ops/running/authz/
|Security Role Options=multiple roles per user, role inheritance, custom roles
|Sec Role Options URL=http://docs.basho.com/riak/latest/ops/running/authz/
|Scope of Roles=database, collection
|Sec Role Scope URL=http://docs.basho.com/riak/latest/ops/running/authz/
|SQLDatabase Encryption=not supported
|Sec Encrypt URL=http://docs.basho.com/riakcs/latest/cookbooks/faqs/riak-cs/#does-riak-cs-encrypt-data-at-rest
|Logging=configurable event logging
|Sec Logging URL=http://docs.basho.com/riak/latest/ops/running/logging/
}}
Riak Security in 2.0 provides four options for security sources:

trust — Any user accessing Riak from a specified IP may perform the permitted operations
password — Authenticate with username and password (works essentially like basic auth)
pam — Authenticate using a pluggable authentication module (PAM)
certificate – Authenticate using client-side certificates

For easier management of permissions across several users, it is possible to create groups to be assigned to those users.</text>
      <sha1>dv3vcy3sb1li2qcerfugy0zf29zgpnu</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>CouchDB Security Features</title>
    <ns>0</ns>
    <id>267</id>
    <revision>
      <id>2463</id>
      <parentid>2462</parentid>
      <timestamp>2015-02-11T17:06:22Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="1339">{{Security
|SQLDatabase=CouchDB
|Client Authentication=custom user/password
|Sec Client Auth URL=http://docs.couchdb.org/en/latest/intro/security.html#cookie-authentication
|Server authentication=shared keyfile, server account credentials
|Sec Server Auth URL=http://docs.couchdb.org/en/latest/replication/protocol.html
|Credential Store=in database
|Sec Credentials URL=http://docs.couchdb.org/en/latest/intro/security.html#authentication-database
|Role Based Security=supported
|Sec Roles URL=http://wiki.apache.org/couchdb/Security_Features_Overview
|Security Role Options=custom roles
|Sec Role Options URL=http://docs.couchdb.org/en/latest/intro/security.html#authentication-database
|Scope of Roles=cluster, database
|Sec Role Scope URL=http://docs.couchdb.org/en/latest/intro/security.html#authorization
|SQLDatabase Encryption=not supported
|Logging=configurable event logging
|Sec Logging URL=http://docs.couchdb.org/en/latest/config/logging.html#log/level
}}
CouchDB has a special authentication database, named _users by default, that stores all registered users as JSON documents.

CouchDB doesn’t provides any builtin roles, so you’re free to define your own depending on your needs. However, you cannot set system roles like _admin there. Also, only administrators may assign roles to users - by default all users have no roles</text>
      <sha1>6xccuftpk9lyakh5rutk7wmxpwgs4lg</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>HBase Security Features</title>
    <ns>0</ns>
    <id>331</id>
    <revision>
      <id>2420</id>
      <parentid>2418</parentid>
      <timestamp>2015-02-03T17:27:19Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="2508">{{Security
|SQLDatabase=HBase
|Client Authentication=Kerberos, SSL
|Sec Client Auth URL=http://hbase.apache.org/book.html#security
|Server authentication=shared keyfile
|Sec Server Auth URL=http://www.cloudera.com/content/cloudera/en/documentation/cdh4/v4-3-1/CDH4-Security-Guide/cdh4sg_topic_8_2.html
|Credential Store=external file
|Sec Credentials URL=http://www.cloudera.com/content/cloudera/en/documentation/cdh4/v4-3-1/CDH4-Security-Guide/cdh4sg_topic_8_2.html
|Role Based Security=supported
|Sec Roles URL=http://hbase.apache.org/book.html#_securing_access_to_your_data
|Security Role Options=default roles, custom roles
|Sec Role Options URL=http://hbase.apache.org/book.html#_securing_access_to_your_data
|Scope of Roles=cluster, database, collection, field
|Sec Role Scope URL=http://hbase.apache.org/book.html#_securing_access_to_your_data
|SQLDatabase Encryption=supported
|Sec Encrypt URL=http://hbase.apache.org/book.html#_securing_access_to_your_data
|Logging=configurable event logging, Fixed event logging
|Sec Logging URL=http://www-01.ibm.com/support/knowledgecenter/SSPT3X_3.0.0/com.ibm.swg.im.infosphere.biginsights.admin.doc/doc/bi_admin_hbase_audit_logs.html
}}
n order to run HBase on a secure HDFS cluster, HBase must authenticate itself to the HDFS services. HBase acts as a Kerberos principal and needs Kerberos credentials to interact with the Kerberos-enabled HDFS daemons. Authenticating a service can be done using a keytab file. 

Role-based Access Control (RBAC) controls which users or groups can read and write to a given HBase resource or execute a coprocessor endpoint, using the familiar paradigm of roles. HBase does not maintain a private group mapping, but relies on a Hadoop group mapper, which maps between entities in a directory such as LDAP or Active Directory, and HBase users. Any supported Hadoop group mapper will work. Users are then granted specific permissions (Read, Write, Execute, Create, Admin) against resources (global, namespaces, tables, cells, or endpoints).

Visibility Labels which allow you to label cells and control access to labelled cells, to further restrict who can read or write to certain subsets of your data. Visibility labels are stored as tags. See hbase.tags for more information.

Transparent encryption of data at rest on the underlying filesystem, both in HFiles and in the WAL. This protects your data at rest from an attacker who has access to the underlying filesystem, without the need to change the implementation of the client.</text>
      <sha1>ltnangf2pzgy3glbofqisx5ezomrlxn</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Accumulo Security Features</title>
    <ns>0</ns>
    <id>339</id>
    <revision>
      <id>2407</id>
      <parentid>2064</parentid>
      <timestamp>2015-01-29T17:56:24Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="2542">{{Security
|SQLDatabase=Accumulo
|Client Authentication=custom user/password
|Sec Client Auth URL=http://accumulo.apache.org/1.6/accumulo_user_manual.html#_pluggable_security
|Server authentication=shared keyfile
|Sec Server Auth URL=http://accumulo.apache.org/1.6/accumulo_user_manual.html#_accumulo_settings
|Credential Store=external file
|Sec Credentials URL=http://accumulo.apache.org/1.6/accumulo_user_manual.html#_pluggable_security
|Role Based Security=supported
|Sec Roles URL=http://www.pcworld.com/article/2060060/nsas-accumulo-nosql-store-offers-rolebased-data-access.html
|Security Role Options=custom roles
|Sec Role Options URL=http://accumulo.apache.org/1.6/accumulo_user_manual.html#_security_label_expression_syntax
|Scope of Roles=collection, field
|Sec Role Scope URL=http://accumulo.apache.org/1.6/accumulo_user_manual.html#_security
|SQLDatabase Encryption=supported
|Sec Encrypt URL=https://accumulo.apache.org/notable_features.html
|Logging=Fixed event logging
|Sec Logging URL=http://accumulo.apache.org/1.6/accumulo_user_manual.html#_logging
}}
Accumulo extends the BigTable data model to implement a security mechanism known as cell-level security. Every key-value pair has its own security label, stored under the column visibility element of the key, which is used to determine whether a given user meets the security requirements to read the value. To prevent users from writing data they can not read, add the visibility constraint to a table. Use the -evc option in the createtable shell command to enable this constraint. 

New in 1.5 of Accumulo is a pluggable security mechanism. It can be broken into three actions — authentication, authorization, and permission handling. By default all of these are handled in Zookeeper. This setup allows a variety of different mechanisms to be used for handling different aspects of Accumulo’s security. A system like Kerberos can be used for authentication, then a system like LDAP could be used to determine if a user has a specific permission

Still a work in progress, Accumulo 1.6.0 introduced encryption at rest (RFiles and WriteAheadLogs) and wire encryption (Thrift over SSL) to provide enhance the level of security that Accumulo provides. It is still a work in progress because the intermediate files created by Accumulo when recovering from a TabletServer failure are not encrypted.

Sqrrl Enterprise supports both encryption of data-at-rest and data-in-motion. - See more at: http://sqrrl.com/sqrrl-enterprise-accumulo-and-encryption/#sthash.50wXabST.dpuf</text>
      <sha1>1xau84deojwwsrw0pwv86stb7fyy0l4</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>FoundationDB Security Features</title>
    <ns>0</ns>
    <id>346</id>
    <revision>
      <id>2456</id>
      <parentid>2075</parentid>
      <timestamp>2015-02-09T20:05:30Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="2597">{{Security
|SQLDatabase=FoundationDB
|Client Authentication=custom user/password, LDAP, Kerberos, SSL
|Sec Client Auth URL=https://foundationdb.com/layers/sql/documentation/Admin/security.html
|Server authentication=shared keyfile
|Sec Server Auth URL=https://foundationdb.com/key-value-store/documentation/tls.html#converting-existing-cluster
|Credential Store=in database
|Sec Credentials URL=https://foundationdb.com/layers/sql/documentation/Admin/security.html
|Role Based Security=supported
|Sec Roles URL=https://foundationdb.com/layers/sql/documentation/Admin/security.html#authorization
|Security Role Options=default roles, custom roles
|Sec Role Options URL=https://foundationdb.com/layers/sql/documentation/Admin/security.html#authorization
|Scope of Roles=collection
|Sec Role Scope URL=https://foundationdb.com/layers/sql/documentation/Admin/security.html#authorization
|SQLDatabase Encryption=not supported
|Logging=configurable event logging
|Sec Logging URL=https://foundationdb.com/layers/sql/documentation/Admin/configuration.html#logging-options
}}
A FoundationDB cluster has the option of supporting Transport Layer Security (TLS).

Data about users is stored in the security_schema. In addition to the security schema, the SQL layer can authenticate users or users and roles from an LDAP server over the network.

Transport Layer Security (TLS) and its predecessor, Secure Sockets Layer (SSL), are protocols designed to provide communication security over public networks. By default, a FoundationDB Key-Value cluster and SQL Layer instances use unencrypted connections among client and server processes. It is possible to enable Transport Layer Security (TLS) security and authentication through a public/private key infrastructure. TLS can be enabled at two levels, first among the FoundationDB Key-Value cluster server and client processes, and second between the SQL Layer and its SQL clients.

Currently, the system has three different levels of authorizations. These are enabled by the role assigned to a user. Two role names will result in specific behavior, namely admin and rest-user. All other role names will result in a certain default behaviour which is active when authentication and authorization are enabled.

Authorization and permission support in the SQL Layer provides limited schema privileges, targeting a multi-tenant use case. If activated, each tenant with a username/password combination, owns exactly one schema named with the username. It is not currently possible to share a schema with another user, except by sharing the username/password combination.</text>
      <sha1>5eqvdtqta55k0qmvh5d4gppfz51ff37</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Cassandra Security Features</title>
    <ns>0</ns>
    <id>358</id>
    <revision>
      <id>2966</id>
      <parentid>2346</parentid>
      <timestamp>2015-08-25T16:48:19Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="2443">{{Security
|SQLDatabase=Cassandra
|Client Authentication=custom user/password, LDAP, Kerberos, SSL
|Sec Client Auth URL=http://www.datastax.com/documentation/cassandra/2.1/cassandra/security/secureSSLClientToNode_t.html
|Server authentication=SSL
|Sec Server Auth URL=http://www.datastax.com/documentation/cassandra/2.1/cassandra/security/secureSSLNodeToNode_t.html
|Credential Store=in database, external file
|Sec Credentials URL=http://www.datastax.com/documentation/opscenter/5.0/opsc/configure/opscAuthChangePasswordDatabase.html
|Role Based Security=supported
|Sec Roles URL=http://www.datastax.com/documentation/opscenter/5.0/opsc/configure/opscConfigureUserAccess_c.html
|Security Role Options=custom roles
|Sec Role Options URL=http://www.datastax.com/documentation/opscenter/5.0/opsc/configure/opscAboutAccessRoles_c.html
|Scope of Roles=cluster
|Sec Role Scope URL=http://www.datastax.com/documentation/opscenter/5.0/opsc/configure/opscAboutAccessRoles_c.html
|SQLDatabase Encryption=supported
|Sec Encrypt URL=http://www.datastax.com/documentation/datastax_enterprise/4.6/datastax_enterprise/sec/secTDE.html
|Logging=configurable event logging
|Sec Logging URL=http://www.datastax.com/documentation/datastax_enterprise/4.6/datastax_enterprise/sec/secAudit.html
}}
Client-to-node encryption protects data in flight from client machines to a database cluster using SSL (Secure Sockets Layer). It establishes a secure channel between the client and the coordinator node. Kerberos support is provided in OpsCenter (http://www.datastax.com/documentation/opscenter/5.0/opsc/configure/opscKerberosAuth.html). The Lightweight Directory Access Protocol (LDAP) is a standard way of authenticating users across applications. DataStax Enterprise 4.6 introduces LDAP authentication support for external LDAP services (http://www.datastax.com/documentation/datastax_enterprise/4.6/datastax_enterprise/sec/secLdapOverview.html?scroll=secLdapOverview)

Node-to-node encryption protects data transferred between nodes in a cluster, including gossip communications, using SSL (Secure Sockets Layer)

Internal authentication is based on Cassandra-controlled login accounts and passwords.

OpsCenter provides the ability to define custom, fine-grained access roles. This is only available in the Enterprise version (http://www.datastax.com/documentation/opscenter/5.0/opsc/features_c.html). Databsae encryption is also only available in DataStax Enterprise.</text>
      <sha1>8d0rp6e8rowvufzmtgkc8sz21w6iilc</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Neo4j Security Features</title>
    <ns>0</ns>
    <id>359</id>
    <revision>
      <id>2362</id>
      <parentid>2361</parentid>
      <timestamp>2015-01-27T16:03:05Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="1675">{{Security
|SQLDatabase=Neo4j
|Client Authentication=SSL
|Sec Client Auth URL=http://neo4j.com/docs/stable/security-server.html#_https_support
|Server authentication=Not secured
|Credential Store=certificates only
|Sec Credentials URL=http://neo4j.com/docs/stable/security-server.html#_server_authorization_rules
|Role Based Security=supported - requires programmatic extension
|Sec Roles URL=http://neo4j.com/docs/stable/security-server.html#_server_authorization_rules
|Security Role Options=not supported
|Scope of Roles=database
|Sec Role Scope URL=http://neo4j.com/docs/stable/security-server.html#_https_support
|SQLDatabase Encryption=not supported
|Sec Encrypt URL=http://neo4j.com/docs/stable/capabilities-data-security.html
|Logging=requires external components (eg Web Servers)
|Sec Logging URL=http://neo4j.com/docs/stable/security-server.html#_server_authorization_rules
}}
The Neo4j server includes built in support for SSL encrypted communication over HTTPS.

To facilitate domain-specific authorization policies in Neo4j Server, security rules can be implemented and registered with the server. This makes scenarios like user and role based security and authentication against external lookup services possible. With rulse registered, a production-quality implementation will likely lookup credentials/claims in a 3rd-party directory service (e.g. LDAP) or in a local database of authorized users.

Some data may need to be protected from unauthorized access (e.g., theft, modification). Neo4j does not deal with data encryption explicitly, but supports all means built into the Java programming language and the JVM to protect data by encrypting it before storing.</text>
      <sha1>lymbs420pxirzohjw8dl46zeu1r3d6o</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>MongoDB Security Features</title>
    <ns>0</ns>
    <id>360</id>
    <revision>
      <id>2427</id>
      <timestamp>2015-02-03T19:56:10Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <comment>Created page with &quot;{{Security |SQLDatabase=MongoDB |Client Authentication=custom user/password, X509 |Sec Client Auth URL=http://docs.mongodb.org/manual/core/security-introduction/ |Server authenti...&quot;</comment>
      <text xml:space="preserve" bytes="2971">{{Security
|SQLDatabase=MongoDB
|Client Authentication=custom user/password, X509
|Sec Client Auth URL=http://docs.mongodb.org/manual/core/security-introduction/
|Server authentication=shared keyfile
|Sec Server Auth URL=http://docs.mongodb.org/v2.6/MongoDB-security-guide.pdf
|Credential Store=in database
|Sec Credentials URL=http://docs.mongodb.org/v2.6/MongoDB-security-guide.pdf
|Role Based Security=supported
|Sec Roles URL=http://docs.mongodb.org/manual/core/authorization/
|Security Role Options=multiple roles per user, default roles, custom roles
|Sec Role Options URL=http://docs.mongodb.org/manual/core/authorization/
|Scope of Roles=cluster, database, collection
|Sec Role Scope URL=http://docs.mongodb.org/manual/core/authorization/
|SQLDatabase Encryption=not supported
|Sec Encrypt URL=http://stackoverflow.com/questions/8803332/mongodb-database-encryption
|Logging=configurable event logging
|Sec Logging URL=http://docs.mongodb.org/manual/core/auditing/
}}
MongoDB Enterprise also provides support for LDAP proxy authentication and Kerberos authentication.

MongoDB employs Role-Based Access Control (RBAC) to govern access to a MongoDB system. A user is granted one or more roles that determine the user’s access to database resources and operations. Outside of role assignments, the user has no access to the system.

A role’s privileges apply to the database where the role is created. A role created on the admin database can include privileges that apply to all databases or to the cluster.

A user assigned a role receives all the privileges of that role. The user can have multiple roles and can have different roles on different databases. Collection-level access control allows administrators to grant users privileges that are scoped to specific collections.

Administrators can implement collection-level access control through user-defined roles. By creating a role with privileges that are scoped to a specific collection in a particular database, administrators can provision users with roles that grant privileges on a collection levl - Collection-level access control allows administrators to grant users privileges that are scoped to specific collections.

Administrators can implement collection-level access control through user-defined roles. By creating a role with privileges that are scoped to a specific collection in a particular database, administrators can provision users with roles that grant privileges on a collection level (http://docs.mongodb.org/manual/core/collection-level-access-control/)

You can authenticate members of replica sets and sharded clusters. To authenticate members of a single MongoDB deployment to each other, MongoDB can use the keyFile and x.509 (page 7) mechanisms. Using keyFile authentication for members also enables authorization.

MongoDB stores all user information, including name, password (page 97), and the user’s database, in the system.users (page 96) collection in the admin database</text>
      <sha1>5lwz81okr0bh4h9o8zo7o0d59144ttd</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>VoltDB Security Features</title>
    <ns>0</ns>
    <id>368</id>
    <revision>
      <id>2452</id>
      <timestamp>2015-02-09T16:18:26Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <comment>Created page with &quot;{{Security |SQLDatabase=VoltDB |Client Authentication=custom user/password, Kerberos |Sec Client Auth URL=http://docs.voltdb.com/UsingVoltDB/ChapSecurity.php |Server authenticati...&quot;</comment>
      <text xml:space="preserve" bytes="1128">{{Security
|SQLDatabase=VoltDB
|Client Authentication=custom user/password, Kerberos
|Sec Client Auth URL=http://docs.voltdb.com/UsingVoltDB/ChapSecurity.php
|Server authentication=Not secured
|Credential Store=external file
|Sec Credentials URL=http://docs.voltdb.com/UsingVoltDB/ChapSecurity.php
|Role Based Security=supported
|Sec Roles URL=http://docs.voltdb.com/UsingVoltDB/SecurityUsersGroups.php
|Security Role Options=multiple roles per user, default roles, custom roles
|Sec Role Options URL=http://docs.voltdb.com/UsingVoltDB/SecurityDefaultRoles.php
|Scope of Roles=cluster, database, collection
|Sec Role Scope URL=http://docs.voltdb.com/UsingVoltDB/SecurityUsersGroups.php
|SQLDatabase Encryption=not supported
|Logging=configurable event logging
|Sec Logging URL=http://docs.voltdb.com/AdminGuide/LogConfig.php
}}
VoltDB uses SHA-1 hashing rather than encryption when passing the username and password between the client and the server. The passwords are also hashed within the database. For an encrypted solution, you can consider implementing Kerberos security - http://docs.voltdb.com/UsingVoltDB/SecurityKerberos.php</text>
      <sha1>pan1uue95sr472oimfs3jxbbtjkp21e</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Oracle NoSQL Security Features</title>
    <ns>0</ns>
    <id>535</id>
    <revision>
      <id>2961</id>
      <parentid>2957</parentid>
      <timestamp>2015-08-25T03:22:26Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="1239">{{Security
|SQLDatabase=Oracle NoSQL
|Client Authentication=custom user/password, SSL
|Sec Client Auth URL=http://docs.oracle.com/cd/NOSQL/html/SecurityGuide/security_command.html https://docs.oracle.com/cd/E57769_01/html/GettingStartedGuide/authentication.html
|Server authentication=SSL
|Sec Server Auth URL=http://www.slideshare.net/dsegleau/oracle-no-sql-r30-overview-slideshare-april-2014
|Credential Store=external file, certificates only
|Sec Credentials URL=https://docs.oracle.com/cd/E57769_01/html/GettingStartedGuide/authentication.html
|Role Based Security=supported
|Sec Roles URL=http://docs.oracle.com/cd/NOSQL/html/SecurityGuide/roles.html#user_defined_roles
|Security Role Options=multiple roles per user, default roles, custom roles
|Sec Role Options URL=http://docs.oracle.com/cd/NOSQL/html/SecurityGuide/roles.html#user_defined_roles
|Scope of Roles=database, collection
|Sec Role Scope URL=http://docs.oracle.com/cd/NOSQL/html/SecurityGuide/roles.html#user_defined_roles
|SQLDatabase Encryption=not supported
|Sec Encrypt URL=http://www.oracle.com/technetwork/topics/bigdata/learnmore/online-forum-qa-1536383.html
|Logging=Fixed event logging
|Sec Logging URL=http://docs.oracle.com/cd/NOSQL/html/SecurityGuide/audit.html
}}</text>
      <sha1>7h07oer0dbrd87naoxl997axbbml06k</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>OrientDB Security Features</title>
    <ns>0</ns>
    <id>548</id>
    <revision>
      <id>3325</id>
      <parentid>3241</parentid>
      <timestamp>2016-05-02T21:30:53Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="1628">{{Security
|SQLDatabase=OrientDB
|Client Authentication=custom user/password, SSL
|Sec Client Auth URL=http://orientdb.com/docs/last/Using-SSL-with-OrientDB.html#client-configuration
|Server authentication=shared keyfile, SSL
|Sec Server Auth URL=http://orientdb.com/docs/last/Using-SSL-with-OrientDB.html#server-configuration
|Credential Store=in database
|Sec Credentials URL=http://orientdb.com/docs/last/SQLDatabase-Security.html#database-security
|Role Based Security=supported
|Sec Roles URL=http://orientdb.com/docs/last/SQLDatabase-Security.html#roles
|Security Role Options=multiple roles per user, role inheritance, default roles, custom roles
|Sec Role Options URL=http://orientdb.com/docs/last/SQLDatabase-Security.html#working-with-roles
|Scope of Roles=cluster, database, collection, object, field
|Sec Role Scope URL=http://orientdb.com/docs/last/SQLDatabase-Security.html#resources
|SQLDatabase Encryption=supported
|Sec Encrypt URL=http://orientdb.com/docs/last/SQLDatabase-Encryption.html
|Logging=configurable event logging
|Sec Logging URL=http://orientdb.com/docs/last/Logging.html#setting-the-log-level
}}
In OrientDB, each user has its own credentials and permissions:
http://orientdb.com/docs/last/SQLDatabase-Security.html#users

OrientDB stores user passwords in the OUser records using the PBKDF2 HASH algorithm with a 24-bit length Salt per user for a configurable number of iterations:
http://orientdb.com/docs/last/SQLDatabase-Security.html#password-management

In OrientDB, you can also manage security in a horizontal fashion, that is: per record :
http://orientdb.com/docs/last/SQLDatabase-Security.html#record-level-security</text>
      <sha1>nkvdigstrdscif8j3492m1lepuwe7w1</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Couchbase Security Features</title>
    <ns>0</ns>
    <id>557</id>
    <revision>
      <id>3309</id>
      <parentid>3267</parentid>
      <timestamp>2016-04-25T20:54:43Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="1134">{{Security
|SQLDatabase=Couchbase
|Client Authentication=custom user/password
|Sec Client Auth URL=http://developer.couchbase.com/documentation/server/4.1/security/security-authentication.html
|Server authentication=SSL, server account credentials
|Sec Server Auth URL=http://developer.couchbase.com/documentation/server/4.1/security/security-best-practices.html
|Credential Store=external file
|Sec Credentials URL=http://developer.couchbase.com/documentation/server/4.1/security/security-iptables.html#concept_h5v_5jc_bq
|Role Based Security=not supported
|Security Role Options=custom roles, not supported
|Scope of Roles=cluster, field
|SQLDatabase Encryption=supported
|Sec Encrypt URL=http://developer.couchbase.com/documentation/server/4.1/security/security-encryption.html
|Logging=Fixed event logging
|Sec Logging URL=http://developer.couchbase.com/documentation/server/4.1/clustersetup/ui-logs.html
}}
Encrypted administrative access enables HTTPS access for the Couchbase Web Console and the REST API using SSL/TLS.

CouchBase stores password files at /opt/couchbase/var/lib/couchbase/isasl.pw and /opt/couchbase/var/lib/config/.</text>
      <sha1>2jxttnbubv2u9ycdbc3b5pirwmnm252</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Redis Security Features</title>
    <ns>0</ns>
    <id>566</id>
    <revision>
      <id>3100</id>
      <parentid>3099</parentid>
      <timestamp>2016-04-07T19:39:31Z</timestamp>
      <contributor>
        <username>Ccis</username>
        <id>62</id>
      </contributor>
      <text xml:space="preserve" bytes="932">{{Security
|SQLDatabase=Redis
|Client Authentication=custom user/password
|Sec Client Auth URL=http://redis.io/commands/AUTH
|Server authentication=shared keyfile
|Sec Server Auth URL=http://redis.io/topics/security
|Credential Store=external file
|Sec Credentials URL=http://redis.io/topics/security#gpg-key
|Role Based Security=not supported
|Sec Roles URL=http://redis.io/topics/security
|Security Role Options=not supported
|Sec Role Options URL=http://redis.io/topics/security
|Scope of Roles=database
|Sec Role Scope URL=http://redis.io/topics/security
|SQLDatabase Encryption=not supported
|Sec Encrypt URL=http://redis.io/topics/security
|Logging=no logging
|Sec Logging URL=http://redis.io/topics/security
}}
Redis does not support SSL natively, but can be achieved through proxy([http://redis.io/topics/security#data-encryption-support link])

Redis has added protected mode in v3.2 test build([http://antirez.com/news/96 link])</text>
      <sha1>22x01ej13o3hmnsgqljwmhal08svrps</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Amazon DynamoDB Security Features</title>
    <ns>0</ns>
    <id>575</id>
    <revision>
      <id>3317</id>
      <parentid>3182</parentid>
      <timestamp>2016-04-28T21:58:24Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="1638">{{Security
|SQLDatabase=Amazon DynamoDB
|Client Authentication=custom user/password
|Sec Client Auth URL=http://docs.aws.amazon.com/general/latest/gr/signing_aws_api_requests.html
|Server authentication=Not secured
|Sec Server Auth URL=http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf
|Credential Store=external file
|Sec Credentials URL=http://docs.aws.amazon.com/general/latest/gr/getting-aws-sec-creds.html
|Role Based Security=supported
|Sec Roles URL=http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html
|Security Role Options=multiple roles per user, custom roles
|Sec Role Options URL=http://docs.aws.amazon.com/IAM/latest/UserGuide/introduction_access-management.html#intro-access-users
|Scope of Roles=database, collection, object, field
|Sec Role Scope URL=http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/FGAC_DDB.html?icmpid=docs_ddb_console
|SQLDatabase Encryption=not supported
|Sec Encrypt URL=http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf
|Logging=configurable event logging
|Sec Logging URL=http://docs.aws.amazon.com/IAM/latest/UserGuide/cloudtrail-integration.html
}}
Server Authentication/SQLDatabase Encryption: (Section 2.1: last para) Dynamo is used only by Amazon’s internal services. Its operation environment is assumed to be non-hostile and there are no security related requirements such as authentication and authorization.

Credential Store: : Security is handled by IAM, which is a separate service which is not a part of dynamodb

Role Based Security/Security Role Options/Scope of Roles: Is supported via AWS IAM, but not a part of AWS dynamo db</text>
      <sha1>ab5vnirtx21vyxlaxwfuu9qxpb00crt</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Cassandra Admin Features</title>
    <ns>0</ns>
    <id>479</id>
    <revision>
      <id>2862</id>
      <parentid>2852</parentid>
      <timestamp>2015-05-27T14:23:56Z</timestamp>
      <contributor>
        <username>Jklein</username>
        <id>2</id>
      </contributor>
      <text xml:space="preserve" bytes="1040">{{Admin
|SQLDatabase=Cassandra
|Configuration Files=multiple
|Admin Config Files URL=http://docs.datastax.com/en/cassandra/2.0/cassandra/reference/referenceInstallLocatePkg_r.html
|Node command line access=non-authenticated
|Admin Command Line URL=http://docs.datastax.com/en/cassandra/2.0/cassandra/tools/toolsNodetool_r.html
|Node add/remove=centralized tool, multiple files
|Admin Node Add URL=http://docs.datastax.com/en/cassandra/2.0/cassandra/operations/ops_add_node_to_cluster_t.html
|Cluster monitoring=snapshot, enterprise version only
|Admin Cluster Monitoring URL=http://docs.datastax.com/en/cassandra/2.0/cassandra/operations/ops_monitoring_c.html
|Dump database configuration=not supported
|SQLDatabase object count=not supported
|Physical storage usage=supported
|Admin Storage Size URL=http://docs.datastax.com/en/cassandra/2.0/cassandra/operations/ops_table_statistics_c.html
}}
Refers to Cassandra 2.0 (27 May 2015).

Monitoring: nodetool provides basic snapshot monitoring. More extensive capabilities in the enterprise version.</text>
      <sha1>c7zambiuh845szdk8m81ybfifjnky6g</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>HBase Admin Features</title>
    <ns>0</ns>
    <id>480</id>
    <revision>
      <id>2863</id>
      <parentid>2853</parentid>
      <timestamp>2015-05-27T14:42:19Z</timestamp>
      <contributor>
        <username>Jklein</username>
        <id>2</id>
      </contributor>
      <text xml:space="preserve" bytes="815">{{Admin
|SQLDatabase=HBase
|Configuration Files=multiple
|Admin Config Files URL=http://hbase.apache.org/book.html#_configuration_files
|Node command line access=non-authenticated
|Admin Command Line URL=http://hbase.apache.org/book.html#shell
|Node add/remove=single file
|Admin Node Add URL=http://hbase.apache.org/book.html#node.management
|Cluster monitoring=real-time
|Admin Cluster Monitoring URL=http://hbase.apache.org/book.html#ops.monitoring
|Dump database configuration=not supported
|SQLDatabase object count=not supported
|Physical storage usage=supported
|Admin Storage Size URL=http://hbase.apache.org/book.html#_hbase_metrics
}}
HBase version 2.0.0 (27 May 2015)

HBase does not provide a monitoring tool, but relies on an external system to capture and display the time series metrics that HBase outputs.</text>
      <sha1>nipowj43rwurpify5o7cy2swr4qo1ga</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Accumulo Admin Features</title>
    <ns>0</ns>
    <id>481</id>
    <revision>
      <id>2864</id>
      <parentid>2854</parentid>
      <timestamp>2015-05-27T14:54:44Z</timestamp>
      <contributor>
        <username>Jklein</username>
        <id>2</id>
      </contributor>
      <text xml:space="preserve" bytes="1073">{{Admin
|SQLDatabase=Accumulo
|Configuration Files=multiple
|Admin Config Files URL=https://accumulo.apache.org/1.7/accumulo_user_manual.html#_configuration_4
|Node command line access=authenticated
|Admin Command Line URL=https://accumulo.apache.org/1.7/accumulo_user_manual.html#_accumulo_shell
|Node add/remove=centralized tool
|Admin Node Add URL=https://accumulo.apache.org/1.7/accumulo_user_manual.html#_adding_a_node
|Cluster monitoring=snapshot
|Admin Cluster Monitoring URL=https://accumulo.apache.org/1.7/accumulo_user_manual.html#_accumulo_monitor
|Dump database configuration=supported
|Admin Dump Config URL=https://accumulo.apache.org/1.7/accumulo_user_manual.html#metadata
|SQLDatabase object count=supported
|Admin Object Count URL=https://accumulo.apache.org/1.7/accumulo_user_manual.html#_tools
|Physical storage usage=supported
|Admin Storage Size URL=https://accumulo.apache.org/1.7/accumulo_user_manual.html#_tools
}}
Accumulo 1.7 (27 May 2015)

Accumulo shows object count and storage use at each node in the cluster, but not for an entire table or cluster.</text>
      <sha1>nhibancukgznem22wdur0fts6wfdlyf</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>MongoDB Admin Features</title>
    <ns>0</ns>
    <id>482</id>
    <revision>
      <id>2865</id>
      <parentid>2855</parentid>
      <timestamp>2015-05-27T15:11:59Z</timestamp>
      <contributor>
        <username>Jklein</username>
        <id>2</id>
      </contributor>
      <text xml:space="preserve" bytes="1087">{{Admin
|SQLDatabase=MongoDB
|Configuration Files=single
|Admin Config Files URL=http://docs.mongodb.org/manual/reference/configuration-options/
|Node command line access=non-authenticated
|Admin Command Line URL=http://docs.mongodb.org/getting-started/shell/client/
|Node add/remove=centralized tool
|Admin Node Add URL=http://docs.mongodb.org/manual/reference/method/rs.add/
|Cluster monitoring=snapshot
|Admin Cluster Monitoring URL=http://docs.mongodb.org/manual/reference/method/
|Dump database configuration=supported
|Admin Dump Config URL=http://docs.mongodb.org/manual/reference/method/
|SQLDatabase object count=supported
|Admin Object Count URL=http://docs.mongodb.org/manual/reference/method/db.collection.count/#db.collection.count
|Physical storage usage=supported
|Admin Storage Size URL=http://docs.mongodb.org/manual/reference/method/db.collection.dataSize/#db.collection.dataSize
}}
MongoDB 3.0 (27 May 2015)

Cluster monitoring is provided by the shell db.serverStatus() command.
Object count and physical storage info is provided by the shell db.collection.stats() command.</text>
      <sha1>c5txs1t2si87o2cng2191zgajfeqltw</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>CouchDB Admin Features</title>
    <ns>0</ns>
    <id>483</id>
    <revision>
      <id>2889</id>
      <parentid>2869</parentid>
      <timestamp>2015-05-28T17:09:56Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="1179">{{Admin
|SQLDatabase=CouchDB
|Configuration Files=multiple
|Admin Config Files URL=http://docs.couchdb.org/en/1.6.1/config/intro.html#configuration-files
|Node command line access=authenticated
|Admin Command Line URL=http://docs.couchdb.org/en/1.6.1/config/auth.html
|Node add/remove=multiple files
|Cluster monitoring=snapshot
|Admin Cluster Monitoring URL=http://docs.couchdb.org/en/1.6.1/intro/futon.html#managing-databases-and-documents
|Dump database configuration=supported
|Admin Dump Config URL=http://docs.couchdb.org/en/1.6.1/intro/futon.html#managing-databases-and-documents
|SQLDatabase object count=supported
|Admin Object Count URL=http://docs.couchdb.org/en/1.6.1/intro/futon.html#managing-databases-and-documents
|Physical storage usage=supported
|Admin Storage Size URL=http://docs.couchdb.org/en/1.6.1/intro/futon.html#managing-databases-and-documents
}}
CouchDB 1.6.1 (27 May 2015)

CouchDB clustering is very different. Replication is on-demand. Each node has a full copy of the database. Clustering is achieved by load-balancing the http connections from clients, so the node add/remove  depends on the load balancing technology (e.g., nginx, Apache httpd, etc.).</text>
      <sha1>f39nsuc4f1z7lfc8pegq4efyu7rj8bp</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Neo4j Admin Features</title>
    <ns>0</ns>
    <id>484</id>
    <revision>
      <id>2870</id>
      <parentid>2857</parentid>
      <timestamp>2015-05-27T16:49:03Z</timestamp>
      <contributor>
        <username>Jklein</username>
        <id>2</id>
      </contributor>
      <text xml:space="preserve" bytes="833">{{Admin
|SQLDatabase=Neo4j
|Configuration Files=multiple
|Admin Config Files URL=http://neo4j.com/docs/stable/server-configuration.html
|Node command line access=non-authenticated
|Admin Command Line URL=http://neo4j.com/docs/stable/shell-starting.html
|Node add/remove=single file
|Admin Node Add URL=http://neo4j.com/docs/stable/ha-configuration.html
|Cluster monitoring=snapshot, enterprise version only
|Admin Cluster Monitoring URL=http://neo4j.com/docs/stable/operations-monitoring.html
|Dump database configuration=supported
|Admin Dump Config URL=http://neo4j.com/docs/stable/jmx-mxbeans.html
|SQLDatabase object count=supported
|Admin Object Count URL=http://neo4j.com/docs/stable/jmx-mxbeans.html
|Physical storage usage=supported
|Admin Storage Size URL=http://neo4j.com/docs/stable/jmx-mxbeans.html
}}
Neo4J 2.2.2 (27 May 2015)</text>
      <sha1>3bt15bh1tbvp49wit0q73jqdmfbo2uu</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>FoundationDB Admin Features</title>
    <ns>0</ns>
    <id>485</id>
    <revision>
      <id>2858</id>
      <timestamp>2015-05-26T17:11:53Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <comment>Created page with &quot;{{Admin |SQLDatabase=FoundationDB |Configuration Files=single |Node command line access=non-authenticated |Node add/remove=centralized tool |Cluster monitoring=real-time |Dump da...&quot;</comment>
      <text xml:space="preserve" bytes="372">{{Admin
|SQLDatabase=FoundationDB
|Configuration Files=single
|Node command line access=non-authenticated
|Node add/remove=centralized tool
|Cluster monitoring=real-time
|Dump database configuration=supported
|SQLDatabase object count=supported
|Physical storage usage=supported
}}
The above is default selections and this page has not been curated. Please disregard it for now.</text>
      <sha1>ov1uqm3wtb0tq7hwhr30zzjvv59sdt3</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Riak Admin Features</title>
    <ns>0</ns>
    <id>486</id>
    <revision>
      <id>2871</id>
      <parentid>2859</parentid>
      <timestamp>2015-05-27T17:53:01Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="1229">{{Admin
|SQLDatabase=Riak
|Configuration Files=multiple
|Admin Config Files URL=http://docs.basho.com/riak/latest/ops/advanced/configs/configuration-files/
|Node command line access=non-authenticated
|Node add/remove=centralized tool, multiple files
|Admin Node Add URL=http://docs.basho.com/riak/latest/ops/building/basic-cluster-setup/#Add-a-Second-Node-to-Your-Cluster
|Cluster monitoring=snapshot
|Admin Cluster Monitoring URL=http://docs.basho.com/riak/latest/ops/running/stats-and-monitoring/
|Dump database configuration=supported
|Admin Dump Config URL=http://docs.basho.com/riak/latest/ops/advanced/configs/configuration-files/#Retrieving-a-Configuration-Listing
|SQLDatabase object count=not supported
|Physical storage usage=not supported
}}
At any time, you can get a snapshot of currently applied configurations through the command line.

Riak Control is a web-based administrative console for inspecting and manipulating Riak clusters.

Riak provides data related to current operating status, which includes statistics in the form of counters and histograms. These statistics are made available through the HTTP API via the /stats endpoint, or through the riak-admin interface, in particular the stat and status commands.</text>
      <sha1>h9b18xisr1wv71vcrij01tdsgsbbroa</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>VoltDB Admin Features</title>
    <ns>0</ns>
    <id>487</id>
    <revision>
      <id>2867</id>
      <parentid>2866</parentid>
      <timestamp>2015-05-27T15:21:54Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="2457">{{Admin
|SQLDatabase=VoltDB
|Configuration Files=single
|Admin Config Files URL=http://docs.voltdb.com/UsingVoltDB/ConfigStructure.php
|Node command line access=non-authenticated
|Node add/remove=centralized tool
|Admin Node Add URL=http://docs.voltdb.com/UsingVoltDB/clivoltdb.php
|Cluster monitoring=real-time
|Admin Cluster Monitoring URL=http://docs.voltdb.com/MgtGuide/IntroChap.php
|Dump database configuration=supported
|Admin Dump Config URL=http://docs.voltdb.com/UsingVoltDB/ConfigStructure.php
|SQLDatabase object count=supported
|Admin Object Count URL=http://docs.voltdb.com/AdminGuide/MonitorChap.php#MonitorMgtCenter
|Physical storage usage=supported
|Admin Storage Size URL=http://docs.voltdb.com/AdminGuide/MonitorChap.php#MonitorMgtCenter
}}
VoltDB Enterprise Manager is a VoltDB Enterprise Edition feature. However, it is possible to perform the same tasks manually or through scripts and other open source tools and technology.

You specify the cluster configuration and what features to use in the deployment file, which is an XML file that you can create and edit manually. In the simplest case, the deployment file specifies how many servers the cluster has initially, how many partitions to create on each server, and what level of availability (K-safety) to use.

If you want to add servers to a VoltDB cluster — usually to increase performance and/or capacity — you can do this without having to restart the database. You add servers to the cluster with the voltdb add command, specifying one of the existing nodes with the --host flag.

The VoltDB Management Center provides a graphical display of key aspects of database performance, including throughput, memory usage, query latency, and partition usage.

MEMORY - Provides statistics about memory usage for each node in the cluster. Information includes the resident set size (RSS) for the server process, the Java heap size, heap usage, available heap memory, and more. This selector provides the type of information displayed by the Process Memory Report, except that it returns information for all nodes of the cluster in a single call.

TABLE ​— Provides information about the size, in number of tuples and amount of memory consumed, for each table in the database. The information is segmented by server and partition, so you can use it to report the total size of the database contents or to evaluate the relative distribution of data across the servers in the cluster.</text>
      <sha1>432hdd7ve7w0sf169ova6l4b7n3yr93</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>OrientDB Admin Features</title>
    <ns>0</ns>
    <id>549</id>
    <revision>
      <id>3243</id>
      <parentid>3242</parentid>
      <timestamp>2016-04-11T23:46:34Z</timestamp>
      <contributor>
        <username>Ccis</username>
        <id>62</id>
      </contributor>
      <text xml:space="preserve" bytes="1277">{{Admin
|SQLDatabase=OrientDB
|Configuration Files=multiple
|Admin Config Files URL=http://orientdb.com/docs/2.1/Distributed-Configuration.html#distributed-configuration
|Node command line access=authenticated
|Admin Command Line URL=http://orientdb.com/docs/last/Tutorial-Run-the-console.html#connecting-to-server-instances
|Node add/remove=single file
|Admin Node Add URL=http://orientdb.com/docs/2.1/Distributed-Architecture-Lifecycle.html#joining-a-cluster
|Cluster monitoring=real-time
|Admin Cluster Monitoring URL=http://orientdb.com/docs/last/Server-Management.html#server-management
|Dump database configuration=supported
|Admin Dump Config URL=http://orientdb.com/docs/2.1/Configuration.html#dump-the-configuration
|SQLDatabase object count=supported
|Admin Object Count URL=http://orientdb.com/docs/2.0/orientdb.wiki/Object-SQLDatabase.html#count-records-of-a-class
|Physical storage usage=supported
|Admin Storage Size URL=http://orientdb.com/docs/2.1/Server-Management.html#statistics
}}
THIS PAGE IS UNDER DEVELOPMENT AND THE INFORMATION HERE SHOULD NOT BE USED AS IT IS CURRENTLY NOT RELIABLE

In OrientDB, the distributed configuration consists of 3 files under the config/ directory:
http://orientdb.com/docs/2.1/Distributed-Configuration.html#distributed-configuration</text>
      <sha1>6s0az92kdzn0mbhddvea4y8yfgflooh</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Couchbase Admin Features</title>
    <ns>0</ns>
    <id>558</id>
    <revision>
      <id>3310</id>
      <parentid>3284</parentid>
      <timestamp>2016-04-25T21:27:22Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="881">{{Admin
|SQLDatabase=Couchbase
|Configuration Files=multiple
|Admin Config Files URL=http://docs.couchbase.com/admin/admin/Install/user-defined-ports.html
|Node command line access=authenticated
|Admin Command Line URL=http://developer.couchbase.com/documentation/server/4.0/cli/cbcli-intro.html
|Node add/remove=centralized tool
|Admin Node Add URL=http://developer.couchbase.com/documentation/server/4.0/clustersetup/adding-nodes.html
|Cluster monitoring=real-time
|Admin Cluster Monitoring URL=http://developer.couchbase.com/documentation/server/4.1/admin/ui-intro.html
|Dump database configuration=supported
|Admin Dump Config URL=http://developer.couchbase.com/documentation/server/4.1/admin/ui-intro.html
|SQLDatabase object count=not supported
|Physical storage usage=supported
|Admin Storage Size URL=http://developer.couchbase.com/documentation/server/4.1/admin/ui-intro.html
}}</text>
      <sha1>2c7o04b5jvdu9t1xx1v0dq4hqn5o6qz</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Redis Admin Features</title>
    <ns>0</ns>
    <id>567</id>
    <revision>
      <id>3303</id>
      <parentid>3273</parentid>
      <timestamp>2016-04-22T21:06:01Z</timestamp>
      <contributor>
        <username>Igorton</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve" bytes="863">{{Admin
|SQLDatabase=Redis
|Configuration Files=single
|Admin Config Files URL=http://redis.io/topics/config
|Node command line access=non-authenticated
|Admin Command Line URL=http://redis.io/commands
|Node add/remove=centralized tool
|Admin Node Add URL=http://redis.io/topics/cluster-tutorial
|Cluster monitoring=real-time
|Admin Cluster Monitoring URL=http://redis.io/topics/sentinel
|Dump database configuration=supported
|Admin Dump Config URL=http://redis.io/commands/cluster-info
|SQLDatabase object count=supported
|Admin Object Count URL=http://redis.io/commands/info
|Physical storage usage=supported
|Admin Storage Size URL=http://redis.io/commands/info
}}
redis-trib is an utility written in Ruby

redis-rdb-tools is available if you need to analyze RDB files(binary dump file of in-memory store): [https://github.com/sripathikrishnan/redis-rdb-tools link]</text>
      <sha1>qywq31j3uzgzil2aohniwor4uh0jnyj</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
  <page>
    <title>Amazon DynamoDB Admin Features</title>
    <ns>0</ns>
    <id>576</id>
    <revision>
      <id>3250</id>
      <parentid>3183</parentid>
      <timestamp>2016-04-12T22:56:52Z</timestamp>
      <contributor>
        <username>Ccis</username>
        <id>62</id>
      </contributor>
      <text xml:space="preserve" bytes="1515">{{Admin
|SQLDatabase=Amazon DynamoDB
|Configuration Files=single
|Admin Config Files URL=http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ConsoleDynamoDB.html
|Node command line access=not supported
|Node add/remove=centralized tool
|Admin Node Add URL=http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf
|Cluster monitoring=real-time
|Admin Cluster Monitoring URL=http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ConsoleDynamoDB.html
|Dump database configuration=not supported
|Admin Dump Config URL=http://docs.aws.amazon.com/cli/latest/reference/dynamodb/index.html#cli-aws-dynamodb
|SQLDatabase object count=supported
|Admin Object Count URL=http://docs.aws.amazon.com/cli/latest/reference/dynamodb/describe-table.html
|Physical storage usage=supported
|Admin Storage Size URL=http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ConsoleDynamoDB.html
}}
Configuration Files: Not Supported. Dynamodb is configured from the AWS console, 

Node command line access/Node add/remove:
Dynamodb is managed by amazon completely. The Client has no control over specifying the number of nodes to be used/added/removed.  
However section 4.8.1 talks a little about manually adding and removing nodes. 

Dump database configuration: Not supported. All the commands that are supported are listed in the link provided, as claimed, it does not
include any command for dumping configurations.

Physical storage usage: Is supported via DynamoDB console, under the metrics tab.</text>
      <sha1>mnzo6jxb4kko2crkzrkqo6xtqsimhrb</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>
</mediawiki>
